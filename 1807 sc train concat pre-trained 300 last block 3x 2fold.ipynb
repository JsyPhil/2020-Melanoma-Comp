{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "import efficientnet_pytorch\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load CSV's\n",
    "df_train = pd.read_csv('/home/malmason/datasets/siim-isic-melanoma-classification/cleaned_csv/train_pp.csv')\n",
    "df_test = pd.read_csv('/home/malmason/datasets/siim-isic-melanoma-classification/cleaned_csv/test_pp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point to image folders\n",
    "img_train_folder = '/home/malmason/datasets/siim-isic-melanoma-classification/rgb300/train/'\n",
    "img_test_folder = '/home/malmason/datasets/siim-isic-melanoma-classification/rgb300/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for looping through image columns\n",
    "X_img = df_train['image_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_csv = df_train.drop(['target', 'image_name'], axis=1).values\n",
    "y_csv = df_train['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_csv.shape, y_csv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.base_model = efficientnet_pytorch.EfficientNet.from_pretrained('efficientnet-b3')\n",
    "        self.base_model._fc = nn.Linear(1536, 16)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ANN, self).__init__()\n",
    "\n",
    "        self.data1 = nn.Linear(15, 128)\n",
    "        self.data2 = nn.Linear(128, 16)\n",
    "        \n",
    "    def forward(self, xd):\n",
    "            \n",
    "        xd = F.leaky_relu(self.data1(xd))\n",
    "        xd = F.dropout(xd, p=0.3)\n",
    "        xd = F.leaky_relu(self.data2(xd))\n",
    "            \n",
    "        return xd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_model = CNN()\n",
    "data_model = ANN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONCAT(nn.Module):\n",
    "    def __init__(self, image_model, data_model):\n",
    "        super(CONCAT, self).__init__()\n",
    "\n",
    "        self.data = data_model\n",
    "        self.images = image_model\n",
    "\n",
    "\n",
    "        self.concat  = nn.Linear(32,1)\n",
    "    \n",
    "    def forward(self, x, xd):\n",
    "\n",
    "        xd = self.data(xd)\n",
    "        xi = self.images(x)\n",
    "        \n",
    "        xc = torch.cat((xi, xd), dim=1)\n",
    "        x = self.concat(xc)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CONCAT(image_model, data_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in image_model.base_model.parameters(): param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_model.base_model._fc.weight.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "image_model.to(device)\n",
    "data_model.to(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_image = []\n",
    "for image_get in X_img:\n",
    "    img = cv2.imread(img_train_folder + '{}.jpg'.format(image_get))\n",
    "\n",
    "    X_image.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_csv = X_csv.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(y_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485,0.456,0.406), (0.229,0.224,0.225)),\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomRotation(25)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "n_epochs = 20\n",
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_images(X_train_image, X_val_image, X_train_csv, X_val_csv, Y_train, Y_val):\n",
    "\n",
    "    print('Train images')\n",
    "    train_images = []\n",
    "    \n",
    "    gc.collect()\n",
    "        \n",
    "    for image_get in tqdm(X_train_image):\n",
    "        image_trans = preprocess(image_get)\n",
    "        image_trans = np.array(image_trans)\n",
    "        train_images.append(image_trans)\n",
    "\n",
    " \n",
    "    train_images = np.array(train_images).astype(np.float32)\n",
    "  \n",
    "    X_train_image_t = np.transpose(train_images, (0,3,1,2))\n",
    "    input_train = torch.from_numpy(X_train_image_t)\n",
    "    \n",
    "    X_train_image_t = [] \n",
    "\n",
    "    input_train_data = torch.from_numpy(X_train_csv)\n",
    "\n",
    "    target_train = torch.from_numpy(Y_train).reshape(-1,1).float()\n",
    "        \n",
    "    print('Val images')\n",
    "    val_images = []\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    for image_get in tqdm(X_val_image):\n",
    "        image_trans = preprocess(image_get)\n",
    "        image_trans = np.array(image_trans)\n",
    "        val_images.append(image_trans)\n",
    "  \n",
    "    val_images = np.array(val_images).astype(np.float32)\n",
    " \n",
    "    X_val_image_t = np.transpose(val_images, (0,3,1,2))\n",
    "    input_val = torch.from_numpy(X_val_image_t)\n",
    "\n",
    "    X_val_image_t = []\n",
    "    \n",
    "    input_val_data   = torch.from_numpy(X_val_csv)\n",
    "    \n",
    "    target_val = torch.from_numpy(Y_val).reshape(-1,1).float()\n",
    "    \n",
    "    training_set = torch.utils.data.TensorDataset(input_train, input_train_data, target_train)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=training_set, \n",
    "                                               batch_size=batch_size,\n",
    "                                               num_workers=4,\n",
    "                                               shuffle=True)\n",
    "    val_set = torch.utils.data.TensorDataset(input_val, input_val_data, target_val)\n",
    "    val_loader = torch.utils.data.DataLoader(dataset=val_set, \n",
    "                                               batch_size=batch_size,\n",
    "                                             num_workers=4,\n",
    "                                             shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.00002)\n",
    "\n",
    "optimizer = torch.optim.Adam([{\"params\": filter(lambda p: p.requires_grad, data_model.parameters()), 'lr' : 0.00005},\n",
    "                             {\"params\": filter(lambda p: p.requires_grad, image_model.parameters()), 'lr' : 0.00001},\n",
    "                            {\"params\": filter(lambda p: p.requires_grad, model.concat.parameters()), 'lr' : 0.00005, \"weight_decay\" : 0.9}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(output_pred, target):\n",
    "    output_pred_tag = torch.round(torch.sigmoid(output_pred))\n",
    "\n",
    "    correct_results_sum = (output_pred_tag == target).sum().float()\n",
    "    acc = correct_results_sum/target.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gd(model, criterion, optimizer, X_image, X_csv, Y, n_epochs):\n",
    "    train_losses = np.zeros(n_epochs)\n",
    "    val_losses = np.zeros(n_epochs)\n",
    "    train_accuracy = np.zeros(n_epochs)\n",
    "    val_accuracy = np.zeros(n_epochs)\n",
    "        \n",
    "    for it in range(n_epochs):\n",
    "        t0 = datetime.now()\n",
    "        \n",
    "        for count in range(2):\n",
    "\n",
    "            train_loss = []\n",
    "            train_acc = []\n",
    "            \n",
    "            if count == 0:\n",
    "                X_train_image = X_image[:27126]\n",
    "                X_train_csv = X_csv[:27126]\n",
    "                Y_train = Y[:27126]\n",
    "                X_val_image = X_image[27126:]\n",
    "                X_val_csv = X_csv[27126:]\n",
    "                Y_val = Y[27126:]\n",
    "            else:\n",
    "                X_train_image = X_image[6000:]\n",
    "                X_train_csv = X_csv[6000:]\n",
    "                Y_train = Y[6000:]\n",
    "                X_val_image = X_image[:6000]\n",
    "                X_val_csv = X_csv[:6000]\n",
    "                Y_val = Y[:6000]\n",
    "\n",
    "            train_loader, val_loader = transform_images(X_train_image, X_val_image, X_train_csv, X_val_csv, Y_train, Y_val)\n",
    "\n",
    "            print('Training')\n",
    "\n",
    "            for inputs, inputs_data, targets in tqdm(train_loader):\n",
    "                inputs, inputs_data, targets = inputs.to(device), inputs_data.to(device), targets.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs, inputs_data)\n",
    "\n",
    "                loss = criterion(outputs, targets)\n",
    "                acc = binary_acc(outputs, targets)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss.append(loss.item())\n",
    "                train_acc.append(acc.item())\n",
    "\n",
    "            train_loss = np.mean(train_loss)\n",
    "            train_acc = np.mean(train_acc)\n",
    "\n",
    "            val_loss = []\n",
    "            val_acc = []\n",
    "            \n",
    "            for inputs, inputs_data, targets in tqdm(val_loader):\n",
    "                inputs, inputs_data, targets = inputs.to(device), inputs_data.to(device), targets.to(device)\n",
    "                outputs = model(inputs, inputs_data)\n",
    "\n",
    "                loss = criterion(outputs, targets)\n",
    "                acc = binary_acc(outputs, targets)\n",
    "\n",
    "                val_loss.append(loss.item())\n",
    "                val_acc.append(acc.item())\n",
    "\n",
    "            val_loss = np.mean(val_loss)\n",
    "            val_acc = np.mean(val_acc)\n",
    "        \n",
    "        train_losses[it] = train_loss\n",
    "        val_losses[it] = val_loss\n",
    "        train_accuracy[it] = train_acc\n",
    "        val_accuracy[it] = val_acc\n",
    "\n",
    "        dt = datetime.now() -t0\n",
    "        \n",
    "        torch.save(image_model.state_dict(), '/home/malmason/datasets/siim-isic-melanoma-classification/skin_train_concat_rgb_eff_net_b3_image' + str(it) + '.pt')\n",
    "        torch.save(data_model.state_dict(), '/home/malmason/datasets/siim-isic-melanoma-classification/skin_train_concat_rgb_eff_net_b3_data' + str(it) + '.pt')\n",
    "        torch.save(model.state_dict(), '/home/malmason/datasets/siim-isic-melanoma-classification/skin_train_concat_rgb_eff_net_b3_model' + str(it) + '.pt')\n",
    "\n",
    "        print(f'Epoch {it+1}/{n_epochs}, Time: {dt}, Train Loss: {train_loss:.4f}, Train_acc: {train_acc}, Val Loss: {val_loss:.4f}, Val acc: {val_acc}')\n",
    "    \n",
    "    return train_losses, val_losses, train_accuracy, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses, train_accuracy, val_accuracy = batch_gd(\n",
    "    model, criterion, optimizer, X_image, X_csv, Y, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(val_losses, label='val loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_accuracy, label='train accuracy')\n",
    "plt.plot(val_accuracy, label='val accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "image_model.to(device)\n",
    "data_model.to(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_model.load_state_dict(torch.load('/home/malmason/datasets/siim-isic-melanoma-classification/skin_train_concat_rgb_eff_net_b3_image7.pt'))\n",
    "data_model.load_state_dict(torch.load('/home/malmason/datasets/siim-isic-melanoma-classification/skin_train_concat_rgb_eff_net_b3_data7.pt'))\n",
    "model.load_state_dict(torch.load('/home/malmason/datasets/siim-isic-melanoma-classification/skin_train_concat_rgb_eff_net_b3_model7.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_val = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485,0.456,0.406), (0.229,0.224,0.225)),\n",
    "    transforms.ToPILImage()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(X_val_image, X_val_csv, Y_val):\n",
    "    \n",
    "    val_images = []\n",
    "    for image_get in X_val_image:\n",
    "        image_trans = preprocess_val(image_get)\n",
    "        image_trans = np.array(image_trans)\n",
    "        val_images.append(image_trans)\n",
    "    \n",
    "    val_images = np.array(val_images)\n",
    "    val_images = val_images.astype(np.float32)\n",
    "\n",
    "    X_val_image_t = np.transpose(val_images, (0,3,1,2))\n",
    "    input_val = torch.from_numpy(X_val_image_t)\n",
    "    \n",
    "    input_val_data = torch.from_numpy(X_val_csv)\n",
    "    \n",
    "    target_val = torch.from_numpy(Y_val).reshape(-1,1).float()\n",
    "    \n",
    "\n",
    "    val_set = torch.utils.data.TensorDataset(input_val, input_val_data, target_val)\n",
    "    val_loader = torch.utils.data.DataLoader(dataset=val_set, \n",
    "                                               batch_size=64,\n",
    "                                             num_workers=2,\n",
    "                                             shuffle=False)\n",
    "    \n",
    "    return val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.eval()\n",
    "n_correct_val = 0.\n",
    "n_total_val = 0.\n",
    "val_predictions_all = []\n",
    "val_predictions_all_value = []\n",
    "val_targets_all = []\n",
    "\n",
    "X_val_image = X_image[27126:]\n",
    "X_val_csv = X_csv[27126:]\n",
    "Y_val = Y[27126:]\n",
    "\n",
    "val_loader = get_images(X_val_image, X_val_csv, Y_val)\n",
    "\n",
    "for inputs, inputs_data, targets in val_loader:\n",
    "    \n",
    "    val_targets_np = targets.numpy()\n",
    "    val_targets_all.append(val_targets_np)\n",
    "    \n",
    "    inputs, inputs_data, targets = inputs.to(device), inputs_data.to(device), targets.to(device)\n",
    "    val_outputs = model(inputs, inputs_data)\n",
    "    val_outputs = torch.sigmoid(val_outputs)\n",
    "    _, val_predictions = torch.max(val_outputs, 1)\n",
    "    val_predictions_np = val_predictions.cpu().numpy()\n",
    "    val_predictions_all.append(val_predictions_np)\n",
    "\n",
    "    val_predictions_np_value = val_outputs.cpu().detach().numpy()\n",
    "    val_predictions_all_value.append(val_predictions_np_value)\n",
    " \n",
    "val_predictions_np_out = []\n",
    "val_predictions_np_out_value = []\n",
    "val_targets_np_out = []\n",
    "val_count = len(val_predictions_all)\n",
    "\n",
    "for z in range(val_count):\n",
    "    \n",
    "    for a in val_predictions_all[z]:\n",
    "        val_predictions_np_out.append(a)\n",
    "\n",
    "    for a in val_predictions_all_value[z]:\n",
    "        val_predictions_np_out_value.append(a)\n",
    "        \n",
    "    for a in val_targets_all[z]:\n",
    "        val_targets_np_out.append(a)\n",
    "\n",
    "val_predictions_np_out = np.asarray(val_predictions_np_out)\n",
    "val_targets_np_out = np.asarray(val_targets_np_out)\n",
    "\n",
    "val_count = len(val_predictions_np_out)\n",
    "\n",
    "for z in range(val_count):\n",
    "    if val_predictions_np_out[z] == np.int(val_targets_np_out[z]):\n",
    "        n_correct_val += 1\n",
    "\n",
    "val_acc = n_correct_val / val_count\n",
    "      \n",
    "print(f\"Val acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_val, tpr_val, _ = roc_curve(val_targets_np_out, val_predictions_np_out_value)\n",
    "auc_pred_val = auc(fpr_val, tpr_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr_val, tpr_val, label = auc_pred_val)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_csv = df_test\n",
    "X_test_img = df_test_csv['image_name']\n",
    "X_test_csv = df_test_csv.drop(['image_name'], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_image = []\n",
    "for image_get in X_test_img:\n",
    "    img_test = cv2.imread(img_test_folder + '{}.jpg'.format(image_get))\n",
    "\n",
    "    X_test_image.append(img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_csv = X_test_csv.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485,0.456,0.406), (0.229,0.224,0.225)),\n",
    "    transforms.ToPILImage()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(X_test_image, X_test_csv):\n",
    "    \n",
    "    test_images = []\n",
    "    for image_get in X_test_image:\n",
    "        image_trans = preprocess_test(image_get)\n",
    "        image_trans = np.array(image_trans)\n",
    "        test_images.append(image_trans)\n",
    "    \n",
    "    test_images = np.array(test_images)\n",
    "    test_images = test_images.astype(np.float32)\n",
    "\n",
    "    X_test_image_t = np.transpose(test_images, (0,3,1,2))\n",
    "    input_test = torch.from_numpy(X_test_image_t)\n",
    "    \n",
    "    input_test_data = torch.from_numpy(X_test_csv)    \n",
    "\n",
    "    test_set = torch.utils.data.TensorDataset(input_test, input_test_data)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_set, \n",
    "                                               batch_size=batch_size,\n",
    "                                             num_workers=2,\n",
    "                                             shuffle=False)\n",
    "    \n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_outputs = []\n",
    "test_loader = get_images(X_test_image, X_test_csv)\n",
    "\n",
    "for inputs, inputs_data in test_loader:\n",
    "    \n",
    "    inputs, inputs_data = inputs.to(device), inputs_data.to(device)\n",
    "    test_outputs = model(inputs, inputs_data)\n",
    "    test_outputs = torch.sigmoid(test_outputs)\n",
    "    outputs_sigmoid_numpy = test_outputs.detach().cpu().numpy()\n",
    "    predicted_outputs.append(outputs_sigmoid_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_outputs = np.array(predicted_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_outputs_total = []\n",
    "for count in range(len(predicted_outputs)):\n",
    "    for test in predicted_outputs[count]:\n",
    "        predicted_outputs_total.append(test)\n",
    "predicted_outputs_total = np.array(predicted_outputs_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_outputs_total.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_image_submission = np.array(X_test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_image_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_outputs_total_submission = predicted_outputs_total.reshape(len(predicted_outputs_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted_outputs_total_submission.shape, X_test_image_submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submission = pd.DataFrame({'image_name':X_test_img, 'target':predicted_outputs_total_submission})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submission.to_csv('/home/malmason/datasets/siim-isic-melanoma-classification/predictions_2f.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
