{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.initializers import he_uniform\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load, convert and check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "# csv_train_file = pd.read_csv('./siim-isic-melanoma-classification/train.csv')\n",
    "# csv_test_file = pd.read_csv('./siim-isic-melanoma-classification/test.csv')\n",
    "\n",
    "# Pre-processed data files\n",
    "X_train_load = pd.read_csv('./cleaned_csvs/train_pp.csv')\n",
    "X_test_load = pd.read_csv('./cleaned_csvs/test_pp.csv')\n",
    "\n",
    "X_train_pp = X_train_load.copy()\n",
    "X_test_pp = X_test_load.copy()\n",
    "\n",
    "# Drop the image names from the tabular data\n",
    "X_train_pp.drop(['image_name'], axis=1, inplace=True)\n",
    "X_test_pp.drop(['image_name'], axis=1, inplace=True)\n",
    "\n",
    "# Separate target from predictors\n",
    "y_train = X_train_pp.target\n",
    "X_train_pp.drop(['target'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Examples = 33126\n",
      "Number of Test Examples = 10982\n",
      "\n",
      "X_train_pp.shape: (33126, 15)\n",
      "X_test_pp.shape: (10982, 15)\n",
      "y_train.shape: (33126,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of Training Examples = {X_train_pp.shape[0]}')\n",
    "print(f'Number of Test Examples = {X_test_pp.shape[0]}\\n')\n",
    "\n",
    "print(\"X_train_pp.shape:\", X_train_pp.shape)\n",
    "print(\"X_test_pp.shape:\", X_test_pp.shape)\n",
    "print(\"y_train.shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_approx</th>\n",
       "      <th>age_id_min</th>\n",
       "      <th>age_id_max</th>\n",
       "      <th>n_images</th>\n",
       "      <th>image_size_scaled</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>sex_missing_value</th>\n",
       "      <th>anatom_site_general_challenge_head/neck</th>\n",
       "      <th>anatom_site_general_challenge_lower extremity</th>\n",
       "      <th>anatom_site_general_challenge_missing_value</th>\n",
       "      <th>anatom_site_general_challenge_oral/genital</th>\n",
       "      <th>anatom_site_general_challenge_palms/soles</th>\n",
       "      <th>anatom_site_general_challenge_torso</th>\n",
       "      <th>anatom_site_general_challenge_upper extremity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.259359</td>\n",
       "      <td>-0.093567</td>\n",
       "      <td>-0.422722</td>\n",
       "      <td>3.433045</td>\n",
       "      <td>1.760172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.259359</td>\n",
       "      <td>-0.093567</td>\n",
       "      <td>-0.422722</td>\n",
       "      <td>-0.301802</td>\n",
       "      <td>1.877304</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.084646</td>\n",
       "      <td>0.239713</td>\n",
       "      <td>0.280969</td>\n",
       "      <td>-1.081605</td>\n",
       "      <td>-1.058326</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.259359</td>\n",
       "      <td>-0.426847</td>\n",
       "      <td>-0.422722</td>\n",
       "      <td>-0.383886</td>\n",
       "      <td>-0.930443</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.428651</td>\n",
       "      <td>0.572993</td>\n",
       "      <td>0.280969</td>\n",
       "      <td>-0.465971</td>\n",
       "      <td>1.444067</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.603364</td>\n",
       "      <td>-0.426847</td>\n",
       "      <td>-0.774568</td>\n",
       "      <td>1.134678</td>\n",
       "      <td>0.778175</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.635380</td>\n",
       "      <td>-1.426688</td>\n",
       "      <td>-1.478259</td>\n",
       "      <td>-0.383886</td>\n",
       "      <td>0.739172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.947369</td>\n",
       "      <td>-0.760128</td>\n",
       "      <td>-0.774568</td>\n",
       "      <td>-0.096590</td>\n",
       "      <td>-0.688747</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.291374</td>\n",
       "      <td>-1.093408</td>\n",
       "      <td>-1.478259</td>\n",
       "      <td>0.149663</td>\n",
       "      <td>0.461915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.084646</td>\n",
       "      <td>0.239713</td>\n",
       "      <td>-0.070877</td>\n",
       "      <td>-0.342844</td>\n",
       "      <td>0.716244</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age_approx  age_id_min  age_id_max  n_images  image_size_scaled  \\\n",
       "0   -0.259359   -0.093567   -0.422722  3.433045           1.760172   \n",
       "1   -0.259359   -0.093567   -0.422722 -0.301802           1.877304   \n",
       "2    0.084646    0.239713    0.280969 -1.081605          -1.058326   \n",
       "3   -0.259359   -0.426847   -0.422722 -0.383886          -0.930443   \n",
       "4    0.428651    0.572993    0.280969 -0.465971           1.444067   \n",
       "5   -0.603364   -0.426847   -0.774568  1.134678           0.778175   \n",
       "6   -1.635380   -1.426688   -1.478259 -0.383886           0.739172   \n",
       "7   -0.947369   -0.760128   -0.774568 -0.096590          -0.688747   \n",
       "8   -1.291374   -1.093408   -1.478259  0.149663           0.461915   \n",
       "9    0.084646    0.239713   -0.070877 -0.342844           0.716244   \n",
       "\n",
       "   sex_female  sex_male  sex_missing_value  \\\n",
       "0         0.0       1.0                0.0   \n",
       "1         1.0       0.0                0.0   \n",
       "2         1.0       0.0                0.0   \n",
       "3         1.0       0.0                0.0   \n",
       "4         1.0       0.0                0.0   \n",
       "5         1.0       0.0                0.0   \n",
       "6         0.0       1.0                0.0   \n",
       "7         1.0       0.0                0.0   \n",
       "8         0.0       1.0                0.0   \n",
       "9         1.0       0.0                0.0   \n",
       "\n",
       "   anatom_site_general_challenge_head/neck  \\\n",
       "0                                      1.0   \n",
       "1                                      0.0   \n",
       "2                                      0.0   \n",
       "3                                      1.0   \n",
       "4                                      0.0   \n",
       "5                                      0.0   \n",
       "6                                      0.0   \n",
       "7                                      0.0   \n",
       "8                                      0.0   \n",
       "9                                      0.0   \n",
       "\n",
       "   anatom_site_general_challenge_lower extremity  \\\n",
       "0                                            0.0   \n",
       "1                                            0.0   \n",
       "2                                            1.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "5                                            1.0   \n",
       "6                                            1.0   \n",
       "7                                            0.0   \n",
       "8                                            0.0   \n",
       "9                                            1.0   \n",
       "\n",
       "   anatom_site_general_challenge_missing_value  \\\n",
       "0                                          0.0   \n",
       "1                                          0.0   \n",
       "2                                          0.0   \n",
       "3                                          0.0   \n",
       "4                                          0.0   \n",
       "5                                          0.0   \n",
       "6                                          0.0   \n",
       "7                                          0.0   \n",
       "8                                          0.0   \n",
       "9                                          0.0   \n",
       "\n",
       "   anatom_site_general_challenge_oral/genital  \\\n",
       "0                                         0.0   \n",
       "1                                         0.0   \n",
       "2                                         0.0   \n",
       "3                                         0.0   \n",
       "4                                         0.0   \n",
       "5                                         0.0   \n",
       "6                                         0.0   \n",
       "7                                         0.0   \n",
       "8                                         0.0   \n",
       "9                                         0.0   \n",
       "\n",
       "   anatom_site_general_challenge_palms/soles  \\\n",
       "0                                        0.0   \n",
       "1                                        0.0   \n",
       "2                                        0.0   \n",
       "3                                        0.0   \n",
       "4                                        0.0   \n",
       "5                                        0.0   \n",
       "6                                        0.0   \n",
       "7                                        0.0   \n",
       "8                                        0.0   \n",
       "9                                        0.0   \n",
       "\n",
       "   anatom_site_general_challenge_torso  \\\n",
       "0                                  0.0   \n",
       "1                                  0.0   \n",
       "2                                  0.0   \n",
       "3                                  0.0   \n",
       "4                                  0.0   \n",
       "5                                  0.0   \n",
       "6                                  0.0   \n",
       "7                                  1.0   \n",
       "8                                  1.0   \n",
       "9                                  0.0   \n",
       "\n",
       "   anatom_site_general_challenge_upper extremity  \n",
       "0                                            0.0  \n",
       "1                                            1.0  \n",
       "2                                            0.0  \n",
       "3                                            0.0  \n",
       "4                                            1.0  \n",
       "5                                            0.0  \n",
       "6                                            0.0  \n",
       "7                                            0.0  \n",
       "8                                            0.0  \n",
       "9                                            0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_train_pp.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabular Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert training and test tabular data to numpy arrays\n",
    "X_train_pp_np = np.array(X_train_pp, dtype=\"float32\")\n",
    "X_test_pp_np = np.array(X_test_pp, dtype=\"float32\")\n",
    "targets = np.array(y_train, dtype=\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_pp_np.shape: (33126, 15)\n",
      "X_test_pp_np.shape: (10982, 15)\n",
      "targets.shape: (33126,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train_pp_np.shape:\", X_train_pp_np.shape)\n",
    "print(\"X_test_pp_np.shape:\", X_test_pp_np.shape)\n",
    "print(\"targets.shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build The Tabular Data ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 26501\n",
      "Number of validation samples: 6625\n",
      "Number of training targets: 26501\n",
      "Number of validation targets: 6625\n"
     ]
    }
   ],
   "source": [
    "# Prepare Validation Set (Using 20% held back for validation)\n",
    "num_val_samples = int(len(X_train_pp_np) * 0.20)\n",
    "train_features = X_train_pp_np[:-num_val_samples]\n",
    "train_targets = targets[:-num_val_samples]\n",
    "val_features = X_train_pp_np[-num_val_samples:]\n",
    "val_targets = targets[-num_val_samples:]\n",
    "\n",
    "print(\"Number of training samples:\", len(train_features))\n",
    "print(\"Number of validation samples:\", len(val_features))\n",
    "print(\"Number of training targets:\", len(train_targets))\n",
    "print(\"Number of validation targets:\", len(val_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive samples in training data: 470 (1.77% of total)\n"
     ]
    }
   ],
   "source": [
    "# Analyze class imbalance in the targets\n",
    "counts = np.bincount(train_targets[:])\n",
    "print(\n",
    "    \"Number of positive samples in training data: {} ({:.2f}% of total)\".format(\n",
    "        counts[1], 100 * float(counts[1]) / len(train_targets)\n",
    "    )\n",
    ")\n",
    "\n",
    "weight_for_0 = 1.0 / counts[0]\n",
    "weight_for_1 = 1.0 / counts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               4096      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 135,937\n",
      "Trainable params: 135,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build a binary classification model\n",
    "relu_initializer = he_uniform(seed=1)\n",
    "\n",
    "ann_model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(\n",
    "            256, activation=\"relu\", input_shape=(train_features.shape[-1],), kernel_initializer=relu_initializer\n",
    "        ),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(256, activation=\"relu\", kernel_initializer=relu_initializer),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(256, activation=\"relu\", kernel_initializer=relu_initializer),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "ann_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26501 samples, validate on 6625 samples\n",
      "Epoch 1/100\n",
      "26501/26501 - 4s - loss: 7.7210e-05 - fn: 204.0000 - fp: 11645.0000 - tn: 14386.0000 - tp: 266.0000 - precision: 0.0223 - recall: 0.5660 - auc: 0.5951 - val_loss: 4.1799e-05 - val_fn: 33.0000 - val_fp: 2308.0000 - val_tn: 4203.0000 - val_tp: 81.0000 - val_precision: 0.0339 - val_recall: 0.7105 - val_auc: 0.7789\n",
      "Epoch 2/100\n",
      "26501/26501 - 1s - loss: 6.2609e-05 - fn: 187.0000 - fp: 9158.0000 - tn: 16873.0000 - tp: 283.0000 - precision: 0.0300 - recall: 0.6021 - auc: 0.6793 - val_loss: 4.4583e-05 - val_fn: 10.0000 - val_fp: 3429.0000 - val_tn: 3082.0000 - val_tp: 104.0000 - val_precision: 0.0294 - val_recall: 0.9123 - val_auc: 0.7883\n",
      "Epoch 3/100\n",
      "26501/26501 - 1s - loss: 5.1879e-05 - fn: 152.0000 - fp: 9189.0000 - tn: 16842.0000 - tp: 318.0000 - precision: 0.0334 - recall: 0.6766 - auc: 0.7221 - val_loss: 3.9985e-05 - val_fn: 19.0000 - val_fp: 2608.0000 - val_tn: 3903.0000 - val_tp: 95.0000 - val_precision: 0.0351 - val_recall: 0.8333 - val_auc: 0.7987\n",
      "Epoch 4/100\n",
      "26501/26501 - 1s - loss: 5.1597e-05 - fn: 149.0000 - fp: 10101.0000 - tn: 15930.0000 - tp: 321.0000 - precision: 0.0308 - recall: 0.6830 - auc: 0.7003 - val_loss: 4.0843e-05 - val_fn: 13.0000 - val_fp: 3136.0000 - val_tn: 3375.0000 - val_tp: 101.0000 - val_precision: 0.0312 - val_recall: 0.8860 - val_auc: 0.7966\n",
      "Epoch 5/100\n",
      "26501/26501 - 1s - loss: 4.8078e-05 - fn: 169.0000 - fp: 8638.0000 - tn: 17393.0000 - tp: 301.0000 - precision: 0.0337 - recall: 0.6404 - auc: 0.7232 - val_loss: 4.0242e-05 - val_fn: 24.0000 - val_fp: 2651.0000 - val_tn: 3860.0000 - val_tp: 90.0000 - val_precision: 0.0328 - val_recall: 0.7895 - val_auc: 0.7957\n",
      "Epoch 6/100\n",
      "26501/26501 - 1s - loss: 4.6695e-05 - fn: 131.0000 - fp: 10192.0000 - tn: 15839.0000 - tp: 339.0000 - precision: 0.0322 - recall: 0.7213 - auc: 0.7346 - val_loss: 4.0105e-05 - val_fn: 17.0000 - val_fp: 2783.0000 - val_tn: 3728.0000 - val_tp: 97.0000 - val_precision: 0.0337 - val_recall: 0.8509 - val_auc: 0.8017\n",
      "Epoch 7/100\n",
      "26501/26501 - 1s - loss: 4.4074e-05 - fn: 135.0000 - fp: 8737.0000 - tn: 17294.0000 - tp: 335.0000 - precision: 0.0369 - recall: 0.7128 - auc: 0.7574 - val_loss: 3.9638e-05 - val_fn: 27.0000 - val_fp: 2242.0000 - val_tn: 4269.0000 - val_tp: 87.0000 - val_precision: 0.0374 - val_recall: 0.7632 - val_auc: 0.8059\n",
      "Epoch 8/100\n",
      "26501/26501 - 1s - loss: 4.5795e-05 - fn: 156.0000 - fp: 8898.0000 - tn: 17133.0000 - tp: 314.0000 - precision: 0.0341 - recall: 0.6681 - auc: 0.7414 - val_loss: 3.9667e-05 - val_fn: 19.0000 - val_fp: 2819.0000 - val_tn: 3692.0000 - val_tp: 95.0000 - val_precision: 0.0326 - val_recall: 0.8333 - val_auc: 0.8045\n",
      "Epoch 9/100\n",
      "26501/26501 - 1s - loss: 4.4447e-05 - fn: 123.0000 - fp: 9993.0000 - tn: 16038.0000 - tp: 347.0000 - precision: 0.0336 - recall: 0.7383 - auc: 0.7523 - val_loss: 3.9657e-05 - val_fn: 25.0000 - val_fp: 2369.0000 - val_tn: 4142.0000 - val_tp: 89.0000 - val_precision: 0.0362 - val_recall: 0.7807 - val_auc: 0.8057\n",
      "Epoch 10/100\n",
      "26501/26501 - 1s - loss: 4.3702e-05 - fn: 137.0000 - fp: 8538.0000 - tn: 17493.0000 - tp: 333.0000 - precision: 0.0375 - recall: 0.7085 - auc: 0.7673 - val_loss: 3.9613e-05 - val_fn: 26.0000 - val_fp: 2307.0000 - val_tn: 4204.0000 - val_tp: 88.0000 - val_precision: 0.0367 - val_recall: 0.7719 - val_auc: 0.8053\n",
      "Epoch 11/100\n",
      "26501/26501 - 1s - loss: 4.3370e-05 - fn: 114.0000 - fp: 9493.0000 - tn: 16538.0000 - tp: 356.0000 - precision: 0.0361 - recall: 0.7574 - auc: 0.7687 - val_loss: 3.9404e-05 - val_fn: 27.0000 - val_fp: 2252.0000 - val_tn: 4259.0000 - val_tp: 87.0000 - val_precision: 0.0372 - val_recall: 0.7632 - val_auc: 0.8079\n",
      "Epoch 12/100\n",
      "26501/26501 - 1s - loss: 4.2207e-05 - fn: 121.0000 - fp: 9238.0000 - tn: 16793.0000 - tp: 349.0000 - precision: 0.0364 - recall: 0.7426 - auc: 0.7772 - val_loss: 3.9192e-05 - val_fn: 27.0000 - val_fp: 2283.0000 - val_tn: 4228.0000 - val_tp: 87.0000 - val_precision: 0.0367 - val_recall: 0.7632 - val_auc: 0.8096\n",
      "Epoch 13/100\n",
      "26501/26501 - 1s - loss: 4.3095e-05 - fn: 134.0000 - fp: 8950.0000 - tn: 17081.0000 - tp: 336.0000 - precision: 0.0362 - recall: 0.7149 - auc: 0.7693 - val_loss: 3.9253e-05 - val_fn: 26.0000 - val_fp: 2190.0000 - val_tn: 4321.0000 - val_tp: 88.0000 - val_precision: 0.0386 - val_recall: 0.7719 - val_auc: 0.8098\n",
      "Epoch 14/100\n",
      "26501/26501 - 1s - loss: 4.1726e-05 - fn: 121.0000 - fp: 9016.0000 - tn: 17015.0000 - tp: 349.0000 - precision: 0.0373 - recall: 0.7426 - auc: 0.7802 - val_loss: 3.9346e-05 - val_fn: 24.0000 - val_fp: 2323.0000 - val_tn: 4188.0000 - val_tp: 90.0000 - val_precision: 0.0373 - val_recall: 0.7895 - val_auc: 0.8090\n",
      "Epoch 15/100\n",
      "26501/26501 - 1s - loss: 4.2532e-05 - fn: 122.0000 - fp: 9174.0000 - tn: 16857.0000 - tp: 348.0000 - precision: 0.0365 - recall: 0.7404 - auc: 0.7794 - val_loss: 3.9225e-05 - val_fn: 24.0000 - val_fp: 2246.0000 - val_tn: 4265.0000 - val_tp: 90.0000 - val_precision: 0.0385 - val_recall: 0.7895 - val_auc: 0.8103\n",
      "Epoch 16/100\n",
      "26501/26501 - 1s - loss: 4.1746e-05 - fn: 120.0000 - fp: 9033.0000 - tn: 16998.0000 - tp: 350.0000 - precision: 0.0373 - recall: 0.7447 - auc: 0.7851 - val_loss: 3.9004e-05 - val_fn: 26.0000 - val_fp: 2259.0000 - val_tn: 4252.0000 - val_tp: 88.0000 - val_precision: 0.0375 - val_recall: 0.7719 - val_auc: 0.8105\n",
      "Epoch 17/100\n",
      "26501/26501 - 1s - loss: 4.2225e-05 - fn: 104.0000 - fp: 9452.0000 - tn: 16579.0000 - tp: 366.0000 - precision: 0.0373 - recall: 0.7787 - auc: 0.7851 - val_loss: 3.8879e-05 - val_fn: 26.0000 - val_fp: 2235.0000 - val_tn: 4276.0000 - val_tp: 88.0000 - val_precision: 0.0379 - val_recall: 0.7719 - val_auc: 0.8113\n",
      "Epoch 18/100\n",
      "26501/26501 - 1s - loss: 4.0672e-05 - fn: 113.0000 - fp: 8673.0000 - tn: 17358.0000 - tp: 357.0000 - precision: 0.0395 - recall: 0.7596 - auc: 0.7969 - val_loss: 3.8778e-05 - val_fn: 27.0000 - val_fp: 2105.0000 - val_tn: 4406.0000 - val_tp: 87.0000 - val_precision: 0.0397 - val_recall: 0.7632 - val_auc: 0.8114\n",
      "Epoch 19/100\n",
      "26501/26501 - 1s - loss: 4.1483e-05 - fn: 127.0000 - fp: 8462.0000 - tn: 17569.0000 - tp: 343.0000 - precision: 0.0390 - recall: 0.7298 - auc: 0.7883 - val_loss: 3.8591e-05 - val_fn: 25.0000 - val_fp: 2251.0000 - val_tn: 4260.0000 - val_tp: 89.0000 - val_precision: 0.0380 - val_recall: 0.7807 - val_auc: 0.8131\n",
      "Epoch 20/100\n",
      "26501/26501 - 1s - loss: 4.0601e-05 - fn: 98.0000 - fp: 9130.0000 - tn: 16901.0000 - tp: 372.0000 - precision: 0.0391 - recall: 0.7915 - auc: 0.7986 - val_loss: 3.8620e-05 - val_fn: 25.0000 - val_fp: 2459.0000 - val_tn: 4052.0000 - val_tp: 89.0000 - val_precision: 0.0349 - val_recall: 0.7807 - val_auc: 0.8135\n",
      "Epoch 21/100\n",
      "26501/26501 - 1s - loss: 4.2277e-05 - fn: 111.0000 - fp: 9315.0000 - tn: 16716.0000 - tp: 359.0000 - precision: 0.0371 - recall: 0.7638 - auc: 0.7836 - val_loss: 3.8862e-05 - val_fn: 25.0000 - val_fp: 2586.0000 - val_tn: 3925.0000 - val_tp: 89.0000 - val_precision: 0.0333 - val_recall: 0.7807 - val_auc: 0.8129\n",
      "Epoch 22/100\n",
      "26501/26501 - 1s - loss: 4.0681e-05 - fn: 105.0000 - fp: 9309.0000 - tn: 16722.0000 - tp: 365.0000 - precision: 0.0377 - recall: 0.7766 - auc: 0.7915 - val_loss: 3.8689e-05 - val_fn: 26.0000 - val_fp: 2350.0000 - val_tn: 4161.0000 - val_tp: 88.0000 - val_precision: 0.0361 - val_recall: 0.7719 - val_auc: 0.8146\n",
      "Epoch 23/100\n",
      "26501/26501 - 1s - loss: 4.0945e-05 - fn: 95.0000 - fp: 9460.0000 - tn: 16571.0000 - tp: 375.0000 - precision: 0.0381 - recall: 0.7979 - auc: 0.7944 - val_loss: 3.8572e-05 - val_fn: 23.0000 - val_fp: 2595.0000 - val_tn: 3916.0000 - val_tp: 91.0000 - val_precision: 0.0339 - val_recall: 0.7982 - val_auc: 0.8141\n",
      "Epoch 24/100\n",
      "26501/26501 - 1s - loss: 4.1432e-05 - fn: 102.0000 - fp: 9554.0000 - tn: 16477.0000 - tp: 368.0000 - precision: 0.0371 - recall: 0.7830 - auc: 0.7926 - val_loss: 3.8398e-05 - val_fn: 26.0000 - val_fp: 2461.0000 - val_tn: 4050.0000 - val_tp: 88.0000 - val_precision: 0.0345 - val_recall: 0.7719 - val_auc: 0.8152\n",
      "Epoch 25/100\n",
      "26501/26501 - 1s - loss: 4.0079e-05 - fn: 100.0000 - fp: 9129.0000 - tn: 16902.0000 - tp: 370.0000 - precision: 0.0390 - recall: 0.7872 - auc: 0.8002 - val_loss: 3.8295e-05 - val_fn: 30.0000 - val_fp: 2139.0000 - val_tn: 4372.0000 - val_tp: 84.0000 - val_precision: 0.0378 - val_recall: 0.7368 - val_auc: 0.8157\n",
      "Epoch 26/100\n",
      "26501/26501 - 1s - loss: 4.1069e-05 - fn: 110.0000 - fp: 9087.0000 - tn: 16944.0000 - tp: 360.0000 - precision: 0.0381 - recall: 0.7660 - auc: 0.7965 - val_loss: 3.8066e-05 - val_fn: 27.0000 - val_fp: 2404.0000 - val_tn: 4107.0000 - val_tp: 87.0000 - val_precision: 0.0349 - val_recall: 0.7632 - val_auc: 0.8157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100\n",
      "26501/26501 - 1s - loss: 4.0673e-05 - fn: 104.0000 - fp: 9564.0000 - tn: 16467.0000 - tp: 366.0000 - precision: 0.0369 - recall: 0.7787 - auc: 0.7948 - val_loss: 3.8159e-05 - val_fn: 29.0000 - val_fp: 2256.0000 - val_tn: 4255.0000 - val_tp: 85.0000 - val_precision: 0.0363 - val_recall: 0.7456 - val_auc: 0.8174\n",
      "Epoch 28/100\n",
      "26501/26501 - 1s - loss: 4.1145e-05 - fn: 106.0000 - fp: 9447.0000 - tn: 16584.0000 - tp: 364.0000 - precision: 0.0371 - recall: 0.7745 - auc: 0.7897 - val_loss: 3.8076e-05 - val_fn: 28.0000 - val_fp: 2260.0000 - val_tn: 4251.0000 - val_tp: 86.0000 - val_precision: 0.0367 - val_recall: 0.7544 - val_auc: 0.8181\n",
      "Epoch 29/100\n",
      "26501/26501 - 1s - loss: 4.0936e-05 - fn: 95.0000 - fp: 10170.0000 - tn: 15861.0000 - tp: 375.0000 - precision: 0.0356 - recall: 0.7979 - auc: 0.7963 - val_loss: 3.8149e-05 - val_fn: 27.0000 - val_fp: 2155.0000 - val_tn: 4356.0000 - val_tp: 87.0000 - val_precision: 0.0388 - val_recall: 0.7632 - val_auc: 0.8182\n",
      "Epoch 30/100\n",
      "26501/26501 - 1s - loss: 4.0495e-05 - fn: 101.0000 - fp: 9072.0000 - tn: 16959.0000 - tp: 369.0000 - precision: 0.0391 - recall: 0.7851 - auc: 0.8011 - val_loss: 3.8158e-05 - val_fn: 32.0000 - val_fp: 1740.0000 - val_tn: 4771.0000 - val_tp: 82.0000 - val_precision: 0.0450 - val_recall: 0.7193 - val_auc: 0.8195\n",
      "Epoch 31/100\n",
      "26501/26501 - 1s - loss: 3.9281e-05 - fn: 109.0000 - fp: 8728.0000 - tn: 17303.0000 - tp: 361.0000 - precision: 0.0397 - recall: 0.7681 - auc: 0.8087 - val_loss: 3.7864e-05 - val_fn: 30.0000 - val_fp: 1914.0000 - val_tn: 4597.0000 - val_tp: 84.0000 - val_precision: 0.0420 - val_recall: 0.7368 - val_auc: 0.8189\n",
      "Epoch 32/100\n",
      "26501/26501 - 1s - loss: 3.9570e-05 - fn: 105.0000 - fp: 9056.0000 - tn: 16975.0000 - tp: 365.0000 - precision: 0.0387 - recall: 0.7766 - auc: 0.8080 - val_loss: 3.7644e-05 - val_fn: 30.0000 - val_fp: 2001.0000 - val_tn: 4510.0000 - val_tp: 84.0000 - val_precision: 0.0403 - val_recall: 0.7368 - val_auc: 0.8187\n",
      "Epoch 33/100\n",
      "26501/26501 - 1s - loss: 4.0365e-05 - fn: 103.0000 - fp: 9040.0000 - tn: 16991.0000 - tp: 367.0000 - precision: 0.0390 - recall: 0.7809 - auc: 0.8028 - val_loss: 3.7440e-05 - val_fn: 30.0000 - val_fp: 1998.0000 - val_tn: 4513.0000 - val_tp: 84.0000 - val_precision: 0.0403 - val_recall: 0.7368 - val_auc: 0.8186\n",
      "Epoch 34/100\n",
      "26501/26501 - 1s - loss: 4.0063e-05 - fn: 100.0000 - fp: 9216.0000 - tn: 16815.0000 - tp: 370.0000 - precision: 0.0386 - recall: 0.7872 - auc: 0.7993 - val_loss: 3.7482e-05 - val_fn: 30.0000 - val_fp: 1883.0000 - val_tn: 4628.0000 - val_tp: 84.0000 - val_precision: 0.0427 - val_recall: 0.7368 - val_auc: 0.8190\n",
      "Epoch 35/100\n",
      "26501/26501 - 1s - loss: 3.9594e-05 - fn: 101.0000 - fp: 8822.0000 - tn: 17209.0000 - tp: 369.0000 - precision: 0.0401 - recall: 0.7851 - auc: 0.8069 - val_loss: 3.7539e-05 - val_fn: 31.0000 - val_fp: 1781.0000 - val_tn: 4730.0000 - val_tp: 83.0000 - val_precision: 0.0445 - val_recall: 0.7281 - val_auc: 0.8202\n",
      "Epoch 36/100\n",
      "26501/26501 - 1s - loss: 4.0044e-05 - fn: 92.0000 - fp: 9044.0000 - tn: 16987.0000 - tp: 378.0000 - precision: 0.0401 - recall: 0.8043 - auc: 0.8093 - val_loss: 3.7465e-05 - val_fn: 31.0000 - val_fp: 1822.0000 - val_tn: 4689.0000 - val_tp: 83.0000 - val_precision: 0.0436 - val_recall: 0.7281 - val_auc: 0.8207\n",
      "Epoch 37/100\n",
      "26501/26501 - 1s - loss: 3.9032e-05 - fn: 95.0000 - fp: 9298.0000 - tn: 16733.0000 - tp: 375.0000 - precision: 0.0388 - recall: 0.7979 - auc: 0.8122 - val_loss: 3.7509e-05 - val_fn: 33.0000 - val_fp: 1791.0000 - val_tn: 4720.0000 - val_tp: 81.0000 - val_precision: 0.0433 - val_recall: 0.7105 - val_auc: 0.8204\n",
      "Epoch 38/100\n",
      "26501/26501 - 1s - loss: 3.9345e-05 - fn: 105.0000 - fp: 8303.0000 - tn: 17728.0000 - tp: 365.0000 - precision: 0.0421 - recall: 0.7766 - auc: 0.8149 - val_loss: 3.7500e-05 - val_fn: 34.0000 - val_fp: 1719.0000 - val_tn: 4792.0000 - val_tp: 80.0000 - val_precision: 0.0445 - val_recall: 0.7018 - val_auc: 0.8206\n",
      "Epoch 39/100\n",
      "26501/26501 - 1s - loss: 3.9932e-05 - fn: 97.0000 - fp: 8724.0000 - tn: 17307.0000 - tp: 373.0000 - precision: 0.0410 - recall: 0.7936 - auc: 0.8173 - val_loss: 3.7525e-05 - val_fn: 33.0000 - val_fp: 1648.0000 - val_tn: 4863.0000 - val_tp: 81.0000 - val_precision: 0.0468 - val_recall: 0.7105 - val_auc: 0.8208\n",
      "Epoch 40/100\n",
      "26501/26501 - 1s - loss: 4.0026e-05 - fn: 101.0000 - fp: 8928.0000 - tn: 17103.0000 - tp: 369.0000 - precision: 0.0397 - recall: 0.7851 - auc: 0.8071 - val_loss: 3.7453e-05 - val_fn: 35.0000 - val_fp: 1684.0000 - val_tn: 4827.0000 - val_tp: 79.0000 - val_precision: 0.0448 - val_recall: 0.6930 - val_auc: 0.8214\n",
      "Epoch 41/100\n",
      "26501/26501 - 1s - loss: 3.9343e-05 - fn: 109.0000 - fp: 8534.0000 - tn: 17497.0000 - tp: 361.0000 - precision: 0.0406 - recall: 0.7681 - auc: 0.8161 - val_loss: 3.7452e-05 - val_fn: 38.0000 - val_fp: 1531.0000 - val_tn: 4980.0000 - val_tp: 76.0000 - val_precision: 0.0473 - val_recall: 0.6667 - val_auc: 0.8214\n",
      "Epoch 42/100\n",
      "26501/26501 - 1s - loss: 3.9389e-05 - fn: 95.0000 - fp: 8493.0000 - tn: 17538.0000 - tp: 375.0000 - precision: 0.0423 - recall: 0.7979 - auc: 0.8158 - val_loss: 3.7160e-05 - val_fn: 33.0000 - val_fp: 1690.0000 - val_tn: 4821.0000 - val_tp: 81.0000 - val_precision: 0.0457 - val_recall: 0.7105 - val_auc: 0.8209\n",
      "Epoch 43/100\n",
      "26501/26501 - 1s - loss: 3.9176e-05 - fn: 98.0000 - fp: 9092.0000 - tn: 16939.0000 - tp: 372.0000 - precision: 0.0393 - recall: 0.7915 - auc: 0.8091 - val_loss: 3.7452e-05 - val_fn: 35.0000 - val_fp: 1675.0000 - val_tn: 4836.0000 - val_tp: 79.0000 - val_precision: 0.0450 - val_recall: 0.6930 - val_auc: 0.8204\n",
      "Epoch 44/100\n",
      "26501/26501 - 1s - loss: 3.9268e-05 - fn: 96.0000 - fp: 8705.0000 - tn: 17326.0000 - tp: 374.0000 - precision: 0.0412 - recall: 0.7957 - auc: 0.8131 - val_loss: 3.7282e-05 - val_fn: 36.0000 - val_fp: 1564.0000 - val_tn: 4947.0000 - val_tp: 78.0000 - val_precision: 0.0475 - val_recall: 0.6842 - val_auc: 0.8234\n",
      "Epoch 45/100\n",
      "26501/26501 - 1s - loss: 3.9765e-05 - fn: 92.0000 - fp: 8908.0000 - tn: 17123.0000 - tp: 378.0000 - precision: 0.0407 - recall: 0.8043 - auc: 0.8114 - val_loss: 3.7099e-05 - val_fn: 35.0000 - val_fp: 1657.0000 - val_tn: 4854.0000 - val_tp: 79.0000 - val_precision: 0.0455 - val_recall: 0.6930 - val_auc: 0.8223\n",
      "Epoch 46/100\n",
      "26501/26501 - 1s - loss: 3.9022e-05 - fn: 101.0000 - fp: 8457.0000 - tn: 17574.0000 - tp: 369.0000 - precision: 0.0418 - recall: 0.7851 - auc: 0.8170 - val_loss: 3.7113e-05 - val_fn: 39.0000 - val_fp: 1447.0000 - val_tn: 5064.0000 - val_tp: 75.0000 - val_precision: 0.0493 - val_recall: 0.6579 - val_auc: 0.8224\n",
      "Epoch 47/100\n",
      "26501/26501 - 1s - loss: 3.8846e-05 - fn: 114.0000 - fp: 8585.0000 - tn: 17446.0000 - tp: 356.0000 - precision: 0.0398 - recall: 0.7574 - auc: 0.8159 - val_loss: 3.7107e-05 - val_fn: 34.0000 - val_fp: 1747.0000 - val_tn: 4764.0000 - val_tp: 80.0000 - val_precision: 0.0438 - val_recall: 0.7018 - val_auc: 0.8221\n",
      "Epoch 48/100\n",
      "26501/26501 - 1s - loss: 3.9677e-05 - fn: 103.0000 - fp: 8875.0000 - tn: 17156.0000 - tp: 367.0000 - precision: 0.0397 - recall: 0.7809 - auc: 0.8106 - val_loss: 3.7124e-05 - val_fn: 34.0000 - val_fp: 1714.0000 - val_tn: 4797.0000 - val_tp: 80.0000 - val_precision: 0.0446 - val_recall: 0.7018 - val_auc: 0.8231\n",
      "Epoch 49/100\n",
      "26501/26501 - 1s - loss: 3.9641e-05 - fn: 92.0000 - fp: 9367.0000 - tn: 16664.0000 - tp: 378.0000 - precision: 0.0388 - recall: 0.8043 - auc: 0.8120 - val_loss: 3.7120e-05 - val_fn: 31.0000 - val_fp: 1782.0000 - val_tn: 4729.0000 - val_tp: 83.0000 - val_precision: 0.0445 - val_recall: 0.7281 - val_auc: 0.8235\n",
      "Epoch 50/100\n",
      "26501/26501 - 1s - loss: 3.8958e-05 - fn: 89.0000 - fp: 8695.0000 - tn: 17336.0000 - tp: 381.0000 - precision: 0.0420 - recall: 0.8106 - auc: 0.8202 - val_loss: 3.7324e-05 - val_fn: 38.0000 - val_fp: 1407.0000 - val_tn: 5104.0000 - val_tp: 76.0000 - val_precision: 0.0512 - val_recall: 0.6667 - val_auc: 0.8244\n",
      "Epoch 51/100\n",
      "26501/26501 - 1s - loss: 4.0118e-05 - fn: 112.0000 - fp: 8184.0000 - tn: 17847.0000 - tp: 358.0000 - precision: 0.0419 - recall: 0.7617 - auc: 0.8136 - val_loss: 3.6875e-05 - val_fn: 34.0000 - val_fp: 1694.0000 - val_tn: 4817.0000 - val_tp: 80.0000 - val_precision: 0.0451 - val_recall: 0.7018 - val_auc: 0.8233\n",
      "Epoch 52/100\n",
      "26501/26501 - 1s - loss: 3.9218e-05 - fn: 92.0000 - fp: 9059.0000 - tn: 16972.0000 - tp: 378.0000 - precision: 0.0401 - recall: 0.8043 - auc: 0.8155 - val_loss: 3.7183e-05 - val_fn: 37.0000 - val_fp: 1459.0000 - val_tn: 5052.0000 - val_tp: 77.0000 - val_precision: 0.0501 - val_recall: 0.6754 - val_auc: 0.8246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100\n",
      "26501/26501 - 1s - loss: 3.9529e-05 - fn: 102.0000 - fp: 7851.0000 - tn: 18180.0000 - tp: 368.0000 - precision: 0.0448 - recall: 0.7830 - auc: 0.8215 - val_loss: 3.6904e-05 - val_fn: 36.0000 - val_fp: 1479.0000 - val_tn: 5032.0000 - val_tp: 78.0000 - val_precision: 0.0501 - val_recall: 0.6842 - val_auc: 0.8249\n",
      "Epoch 54/100\n",
      "26501/26501 - 1s - loss: 3.8849e-05 - fn: 100.0000 - fp: 8581.0000 - tn: 17450.0000 - tp: 370.0000 - precision: 0.0413 - recall: 0.7872 - auc: 0.8142 - val_loss: 3.6917e-05 - val_fn: 37.0000 - val_fp: 1632.0000 - val_tn: 4879.0000 - val_tp: 77.0000 - val_precision: 0.0451 - val_recall: 0.6754 - val_auc: 0.8277\n",
      "Epoch 55/100\n",
      "26501/26501 - 1s - loss: 3.8999e-05 - fn: 113.0000 - fp: 8364.0000 - tn: 17667.0000 - tp: 357.0000 - precision: 0.0409 - recall: 0.7596 - auc: 0.8158 - val_loss: 3.7042e-05 - val_fn: 38.0000 - val_fp: 1512.0000 - val_tn: 4999.0000 - val_tp: 76.0000 - val_precision: 0.0479 - val_recall: 0.6667 - val_auc: 0.8295\n",
      "Epoch 56/100\n",
      "26501/26501 - 1s - loss: 3.8186e-05 - fn: 97.0000 - fp: 8409.0000 - tn: 17622.0000 - tp: 373.0000 - precision: 0.0425 - recall: 0.7936 - auc: 0.8239 - val_loss: 3.6532e-05 - val_fn: 37.0000 - val_fp: 1623.0000 - val_tn: 4888.0000 - val_tp: 77.0000 - val_precision: 0.0453 - val_recall: 0.6754 - val_auc: 0.8302\n",
      "Epoch 57/100\n",
      "26501/26501 - 1s - loss: 3.8520e-05 - fn: 96.0000 - fp: 8595.0000 - tn: 17436.0000 - tp: 374.0000 - precision: 0.0417 - recall: 0.7957 - auc: 0.8236 - val_loss: 3.6582e-05 - val_fn: 38.0000 - val_fp: 1460.0000 - val_tn: 5051.0000 - val_tp: 76.0000 - val_precision: 0.0495 - val_recall: 0.6667 - val_auc: 0.8317\n",
      "Epoch 58/100\n",
      "26501/26501 - 1s - loss: 3.8796e-05 - fn: 111.0000 - fp: 7751.0000 - tn: 18280.0000 - tp: 359.0000 - precision: 0.0443 - recall: 0.7638 - auc: 0.8209 - val_loss: 3.6744e-05 - val_fn: 38.0000 - val_fp: 1348.0000 - val_tn: 5163.0000 - val_tp: 76.0000 - val_precision: 0.0534 - val_recall: 0.6667 - val_auc: 0.8303\n",
      "Epoch 59/100\n",
      "26501/26501 - 1s - loss: 3.8303e-05 - fn: 98.0000 - fp: 8570.0000 - tn: 17461.0000 - tp: 372.0000 - precision: 0.0416 - recall: 0.7915 - auc: 0.8240 - val_loss: 3.6577e-05 - val_fn: 35.0000 - val_fp: 1565.0000 - val_tn: 4946.0000 - val_tp: 79.0000 - val_precision: 0.0481 - val_recall: 0.6930 - val_auc: 0.8334\n",
      "Epoch 60/100\n",
      "26501/26501 - 1s - loss: 3.8234e-05 - fn: 96.0000 - fp: 7896.0000 - tn: 18135.0000 - tp: 374.0000 - precision: 0.0452 - recall: 0.7957 - auc: 0.8283 - val_loss: 3.6771e-05 - val_fn: 39.0000 - val_fp: 1222.0000 - val_tn: 5289.0000 - val_tp: 75.0000 - val_precision: 0.0578 - val_recall: 0.6579 - val_auc: 0.8325\n",
      "Epoch 61/100\n",
      "26501/26501 - 1s - loss: 3.8018e-05 - fn: 101.0000 - fp: 8006.0000 - tn: 18025.0000 - tp: 369.0000 - precision: 0.0441 - recall: 0.7851 - auc: 0.8240 - val_loss: 3.6392e-05 - val_fn: 39.0000 - val_fp: 1379.0000 - val_tn: 5132.0000 - val_tp: 75.0000 - val_precision: 0.0516 - val_recall: 0.6579 - val_auc: 0.8320\n",
      "Epoch 62/100\n",
      "26501/26501 - 1s - loss: 3.8846e-05 - fn: 96.0000 - fp: 8437.0000 - tn: 17594.0000 - tp: 374.0000 - precision: 0.0424 - recall: 0.7957 - auc: 0.8257 - val_loss: 3.6718e-05 - val_fn: 38.0000 - val_fp: 1378.0000 - val_tn: 5133.0000 - val_tp: 76.0000 - val_precision: 0.0523 - val_recall: 0.6667 - val_auc: 0.8325\n",
      "Epoch 63/100\n",
      "26501/26501 - 1s - loss: 3.8255e-05 - fn: 99.0000 - fp: 8058.0000 - tn: 17973.0000 - tp: 371.0000 - precision: 0.0440 - recall: 0.7894 - auc: 0.8239 - val_loss: 3.6673e-05 - val_fn: 39.0000 - val_fp: 1315.0000 - val_tn: 5196.0000 - val_tp: 75.0000 - val_precision: 0.0540 - val_recall: 0.6579 - val_auc: 0.8322\n",
      "Epoch 64/100\n",
      "26501/26501 - 1s - loss: 3.8756e-05 - fn: 105.0000 - fp: 8279.0000 - tn: 17752.0000 - tp: 365.0000 - precision: 0.0422 - recall: 0.7766 - auc: 0.8228 - val_loss: 3.6408e-05 - val_fn: 36.0000 - val_fp: 1470.0000 - val_tn: 5041.0000 - val_tp: 78.0000 - val_precision: 0.0504 - val_recall: 0.6842 - val_auc: 0.8330\n",
      "Epoch 65/100\n",
      "26501/26501 - 1s - loss: 3.7511e-05 - fn: 97.0000 - fp: 8326.0000 - tn: 17705.0000 - tp: 373.0000 - precision: 0.0429 - recall: 0.7936 - auc: 0.8295 - val_loss: 3.6622e-05 - val_fn: 37.0000 - val_fp: 1386.0000 - val_tn: 5125.0000 - val_tp: 77.0000 - val_precision: 0.0526 - val_recall: 0.6754 - val_auc: 0.8349\n",
      "Epoch 66/100\n",
      "26501/26501 - 1s - loss: 3.8014e-05 - fn: 100.0000 - fp: 8161.0000 - tn: 17870.0000 - tp: 370.0000 - precision: 0.0434 - recall: 0.7872 - auc: 0.8268 - val_loss: 3.6423e-05 - val_fn: 38.0000 - val_fp: 1400.0000 - val_tn: 5111.0000 - val_tp: 76.0000 - val_precision: 0.0515 - val_recall: 0.6667 - val_auc: 0.8348\n",
      "Epoch 67/100\n",
      "26501/26501 - 1s - loss: 3.8366e-05 - fn: 102.0000 - fp: 7955.0000 - tn: 18076.0000 - tp: 368.0000 - precision: 0.0442 - recall: 0.7830 - auc: 0.8264 - val_loss: 3.6330e-05 - val_fn: 37.0000 - val_fp: 1427.0000 - val_tn: 5084.0000 - val_tp: 77.0000 - val_precision: 0.0512 - val_recall: 0.6754 - val_auc: 0.8347\n",
      "Epoch 68/100\n",
      "26501/26501 - 1s - loss: 3.7690e-05 - fn: 86.0000 - fp: 8485.0000 - tn: 17546.0000 - tp: 384.0000 - precision: 0.0433 - recall: 0.8170 - auc: 0.8304 - val_loss: 3.6406e-05 - val_fn: 36.0000 - val_fp: 1449.0000 - val_tn: 5062.0000 - val_tp: 78.0000 - val_precision: 0.0511 - val_recall: 0.6842 - val_auc: 0.8345\n",
      "Epoch 69/100\n",
      "26501/26501 - 1s - loss: 3.8214e-05 - fn: 94.0000 - fp: 8197.0000 - tn: 17834.0000 - tp: 376.0000 - precision: 0.0439 - recall: 0.8000 - auc: 0.8280 - val_loss: 3.6496e-05 - val_fn: 39.0000 - val_fp: 1374.0000 - val_tn: 5137.0000 - val_tp: 75.0000 - val_precision: 0.0518 - val_recall: 0.6579 - val_auc: 0.8332\n",
      "Epoch 70/100\n",
      "26501/26501 - 1s - loss: 3.8542e-05 - fn: 102.0000 - fp: 8576.0000 - tn: 17455.0000 - tp: 368.0000 - precision: 0.0411 - recall: 0.7830 - auc: 0.8193 - val_loss: 3.6207e-05 - val_fn: 35.0000 - val_fp: 1519.0000 - val_tn: 4992.0000 - val_tp: 79.0000 - val_precision: 0.0494 - val_recall: 0.6930 - val_auc: 0.8338\n",
      "Epoch 71/100\n",
      "26501/26501 - 1s - loss: 3.8505e-05 - fn: 97.0000 - fp: 8228.0000 - tn: 17803.0000 - tp: 373.0000 - precision: 0.0434 - recall: 0.7936 - auc: 0.8218 - val_loss: 3.6317e-05 - val_fn: 37.0000 - val_fp: 1477.0000 - val_tn: 5034.0000 - val_tp: 77.0000 - val_precision: 0.0495 - val_recall: 0.6754 - val_auc: 0.8353\n",
      "Epoch 72/100\n",
      "26501/26501 - 1s - loss: 3.7912e-05 - fn: 99.0000 - fp: 8290.0000 - tn: 17741.0000 - tp: 371.0000 - precision: 0.0428 - recall: 0.7894 - auc: 0.8286 - val_loss: 3.6339e-05 - val_fn: 38.0000 - val_fp: 1391.0000 - val_tn: 5120.0000 - val_tp: 76.0000 - val_precision: 0.0518 - val_recall: 0.6667 - val_auc: 0.8356\n",
      "Epoch 73/100\n",
      "26501/26501 - 1s - loss: 3.7499e-05 - fn: 91.0000 - fp: 8210.0000 - tn: 17821.0000 - tp: 379.0000 - precision: 0.0441 - recall: 0.8064 - auc: 0.8329 - val_loss: 3.6335e-05 - val_fn: 40.0000 - val_fp: 1403.0000 - val_tn: 5108.0000 - val_tp: 74.0000 - val_precision: 0.0501 - val_recall: 0.6491 - val_auc: 0.8344\n",
      "Epoch 74/100\n",
      "26501/26501 - 1s - loss: 3.8120e-05 - fn: 122.0000 - fp: 7050.0000 - tn: 18981.0000 - tp: 348.0000 - precision: 0.0470 - recall: 0.7404 - auc: 0.8302 - val_loss: 3.6403e-05 - val_fn: 40.0000 - val_fp: 1304.0000 - val_tn: 5207.0000 - val_tp: 74.0000 - val_precision: 0.0537 - val_recall: 0.6491 - val_auc: 0.8348\n",
      "Epoch 75/100\n",
      "26501/26501 - 1s - loss: 3.8576e-05 - fn: 107.0000 - fp: 8018.0000 - tn: 18013.0000 - tp: 363.0000 - precision: 0.0433 - recall: 0.7723 - auc: 0.8249 - val_loss: 3.6422e-05 - val_fn: 36.0000 - val_fp: 1574.0000 - val_tn: 4937.0000 - val_tp: 78.0000 - val_precision: 0.0472 - val_recall: 0.6842 - val_auc: 0.8349\n",
      "Epoch 76/100\n",
      "26501/26501 - 1s - loss: 3.7540e-05 - fn: 94.0000 - fp: 8399.0000 - tn: 17632.0000 - tp: 376.0000 - precision: 0.0428 - recall: 0.8000 - auc: 0.8308 - val_loss: 3.6461e-05 - val_fn: 39.0000 - val_fp: 1426.0000 - val_tn: 5085.0000 - val_tp: 75.0000 - val_precision: 0.0500 - val_recall: 0.6579 - val_auc: 0.8345\n",
      "Epoch 77/100\n",
      "26501/26501 - 1s - loss: 3.8382e-05 - fn: 103.0000 - fp: 7977.0000 - tn: 18054.0000 - tp: 367.0000 - precision: 0.0440 - recall: 0.7809 - auc: 0.8259 - val_loss: 3.6250e-05 - val_fn: 39.0000 - val_fp: 1373.0000 - val_tn: 5138.0000 - val_tp: 75.0000 - val_precision: 0.0518 - val_recall: 0.6579 - val_auc: 0.8351\n",
      "Epoch 78/100\n",
      "26501/26501 - 1s - loss: 3.8532e-05 - fn: 106.0000 - fp: 7713.0000 - tn: 18318.0000 - tp: 364.0000 - precision: 0.0451 - recall: 0.7745 - auc: 0.8248 - val_loss: 3.6249e-05 - val_fn: 39.0000 - val_fp: 1339.0000 - val_tn: 5172.0000 - val_tp: 75.0000 - val_precision: 0.0530 - val_recall: 0.6579 - val_auc: 0.8356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100\n",
      "26501/26501 - 1s - loss: 3.8033e-05 - fn: 109.0000 - fp: 7824.0000 - tn: 18207.0000 - tp: 361.0000 - precision: 0.0441 - recall: 0.7681 - auc: 0.8258 - val_loss: 3.6288e-05 - val_fn: 36.0000 - val_fp: 1500.0000 - val_tn: 5011.0000 - val_tp: 78.0000 - val_precision: 0.0494 - val_recall: 0.6842 - val_auc: 0.8358\n",
      "Epoch 80/100\n",
      "26501/26501 - 1s - loss: 3.7371e-05 - fn: 101.0000 - fp: 8007.0000 - tn: 18024.0000 - tp: 369.0000 - precision: 0.0441 - recall: 0.7851 - auc: 0.8336 - val_loss: 3.6232e-05 - val_fn: 38.0000 - val_fp: 1418.0000 - val_tn: 5093.0000 - val_tp: 76.0000 - val_precision: 0.0509 - val_recall: 0.6667 - val_auc: 0.8370\n",
      "Epoch 81/100\n",
      "26501/26501 - 1s - loss: 3.8423e-05 - fn: 99.0000 - fp: 8076.0000 - tn: 17955.0000 - tp: 371.0000 - precision: 0.0439 - recall: 0.7894 - auc: 0.8272 - val_loss: 3.6258e-05 - val_fn: 35.0000 - val_fp: 1488.0000 - val_tn: 5023.0000 - val_tp: 79.0000 - val_precision: 0.0504 - val_recall: 0.6930 - val_auc: 0.8362\n",
      "Epoch 82/100\n",
      "26501/26501 - 1s - loss: 3.7086e-05 - fn: 97.0000 - fp: 7652.0000 - tn: 18379.0000 - tp: 373.0000 - precision: 0.0465 - recall: 0.7936 - auc: 0.8381 - val_loss: 3.6346e-05 - val_fn: 40.0000 - val_fp: 1295.0000 - val_tn: 5216.0000 - val_tp: 74.0000 - val_precision: 0.0541 - val_recall: 0.6491 - val_auc: 0.8351\n",
      "Epoch 83/100\n",
      "26501/26501 - 1s - loss: 3.7503e-05 - fn: 107.0000 - fp: 7368.0000 - tn: 18663.0000 - tp: 363.0000 - precision: 0.0470 - recall: 0.7723 - auc: 0.8354 - val_loss: 3.6164e-05 - val_fn: 40.0000 - val_fp: 1355.0000 - val_tn: 5156.0000 - val_tp: 74.0000 - val_precision: 0.0518 - val_recall: 0.6491 - val_auc: 0.8359\n",
      "Epoch 84/100\n",
      "26501/26501 - 1s - loss: 3.8035e-05 - fn: 93.0000 - fp: 7975.0000 - tn: 18056.0000 - tp: 377.0000 - precision: 0.0451 - recall: 0.8021 - auc: 0.8307 - val_loss: 3.6144e-05 - val_fn: 40.0000 - val_fp: 1369.0000 - val_tn: 5142.0000 - val_tp: 74.0000 - val_precision: 0.0513 - val_recall: 0.6491 - val_auc: 0.8360\n",
      "Epoch 85/100\n",
      "26501/26501 - 1s - loss: 3.7887e-05 - fn: 114.0000 - fp: 7258.0000 - tn: 18773.0000 - tp: 356.0000 - precision: 0.0468 - recall: 0.7574 - auc: 0.8281 - val_loss: 3.6479e-05 - val_fn: 41.0000 - val_fp: 1341.0000 - val_tn: 5170.0000 - val_tp: 73.0000 - val_precision: 0.0516 - val_recall: 0.6404 - val_auc: 0.8336\n",
      "Epoch 86/100\n",
      "26501/26501 - 1s - loss: 3.7126e-05 - fn: 100.0000 - fp: 8062.0000 - tn: 17969.0000 - tp: 370.0000 - precision: 0.0439 - recall: 0.7872 - auc: 0.8303 - val_loss: 3.6155e-05 - val_fn: 39.0000 - val_fp: 1501.0000 - val_tn: 5010.0000 - val_tp: 75.0000 - val_precision: 0.0476 - val_recall: 0.6579 - val_auc: 0.8315\n",
      "Epoch 87/100\n",
      "26501/26501 - 1s - loss: 3.7572e-05 - fn: 92.0000 - fp: 7782.0000 - tn: 18249.0000 - tp: 378.0000 - precision: 0.0463 - recall: 0.8043 - auc: 0.8318 - val_loss: 3.6250e-05 - val_fn: 41.0000 - val_fp: 1395.0000 - val_tn: 5116.0000 - val_tp: 73.0000 - val_precision: 0.0497 - val_recall: 0.6404 - val_auc: 0.8340\n",
      "Epoch 88/100\n",
      "26501/26501 - 1s - loss: 3.6716e-05 - fn: 86.0000 - fp: 8146.0000 - tn: 17885.0000 - tp: 384.0000 - precision: 0.0450 - recall: 0.8170 - auc: 0.8407 - val_loss: 3.6173e-05 - val_fn: 40.0000 - val_fp: 1406.0000 - val_tn: 5105.0000 - val_tp: 74.0000 - val_precision: 0.0500 - val_recall: 0.6491 - val_auc: 0.8363\n",
      "Epoch 89/100\n",
      "26501/26501 - 1s - loss: 3.7944e-05 - fn: 106.0000 - fp: 7529.0000 - tn: 18502.0000 - tp: 364.0000 - precision: 0.0461 - recall: 0.7745 - auc: 0.8317 - val_loss: 3.6062e-05 - val_fn: 41.0000 - val_fp: 1411.0000 - val_tn: 5100.0000 - val_tp: 73.0000 - val_precision: 0.0492 - val_recall: 0.6404 - val_auc: 0.8358\n",
      "Epoch 90/100\n",
      "26501/26501 - 1s - loss: 3.7797e-05 - fn: 108.0000 - fp: 7828.0000 - tn: 18203.0000 - tp: 362.0000 - precision: 0.0442 - recall: 0.7702 - auc: 0.8280 - val_loss: 3.6077e-05 - val_fn: 39.0000 - val_fp: 1497.0000 - val_tn: 5014.0000 - val_tp: 75.0000 - val_precision: 0.0477 - val_recall: 0.6579 - val_auc: 0.8346\n",
      "Epoch 91/100\n",
      "26501/26501 - 1s - loss: 3.8087e-05 - fn: 93.0000 - fp: 8205.0000 - tn: 17826.0000 - tp: 377.0000 - precision: 0.0439 - recall: 0.8021 - auc: 0.8293 - val_loss: 3.6148e-05 - val_fn: 39.0000 - val_fp: 1470.0000 - val_tn: 5041.0000 - val_tp: 75.0000 - val_precision: 0.0485 - val_recall: 0.6579 - val_auc: 0.8356\n",
      "Epoch 92/100\n",
      "26501/26501 - 1s - loss: 3.7585e-05 - fn: 106.0000 - fp: 7881.0000 - tn: 18150.0000 - tp: 364.0000 - precision: 0.0441 - recall: 0.7745 - auc: 0.8317 - val_loss: 3.6218e-05 - val_fn: 37.0000 - val_fp: 1489.0000 - val_tn: 5022.0000 - val_tp: 77.0000 - val_precision: 0.0492 - val_recall: 0.6754 - val_auc: 0.8347\n",
      "Epoch 93/100\n",
      "26501/26501 - 1s - loss: 3.6920e-05 - fn: 98.0000 - fp: 7600.0000 - tn: 18431.0000 - tp: 372.0000 - precision: 0.0467 - recall: 0.7915 - auc: 0.8383 - val_loss: 3.6109e-05 - val_fn: 39.0000 - val_fp: 1421.0000 - val_tn: 5090.0000 - val_tp: 75.0000 - val_precision: 0.0501 - val_recall: 0.6579 - val_auc: 0.8354\n",
      "Epoch 94/100\n",
      "26501/26501 - 1s - loss: 3.7149e-05 - fn: 93.0000 - fp: 8025.0000 - tn: 18006.0000 - tp: 377.0000 - precision: 0.0449 - recall: 0.8021 - auc: 0.8343 - val_loss: 3.6121e-05 - val_fn: 39.0000 - val_fp: 1501.0000 - val_tn: 5010.0000 - val_tp: 75.0000 - val_precision: 0.0476 - val_recall: 0.6579 - val_auc: 0.8338\n",
      "Epoch 95/100\n",
      "26501/26501 - 1s - loss: 3.8080e-05 - fn: 103.0000 - fp: 7741.0000 - tn: 18290.0000 - tp: 367.0000 - precision: 0.0453 - recall: 0.7809 - auc: 0.8308 - val_loss: 3.6206e-05 - val_fn: 39.0000 - val_fp: 1536.0000 - val_tn: 4975.0000 - val_tp: 75.0000 - val_precision: 0.0466 - val_recall: 0.6579 - val_auc: 0.8338\n",
      "Epoch 96/100\n",
      "26501/26501 - 1s - loss: 3.7720e-05 - fn: 95.0000 - fp: 8200.0000 - tn: 17831.0000 - tp: 375.0000 - precision: 0.0437 - recall: 0.7979 - auc: 0.8330 - val_loss: 3.6582e-05 - val_fn: 37.0000 - val_fp: 1499.0000 - val_tn: 5012.0000 - val_tp: 77.0000 - val_precision: 0.0489 - val_recall: 0.6754 - val_auc: 0.8355\n",
      "Epoch 97/100\n",
      "26501/26501 - 1s - loss: 3.6719e-05 - fn: 87.0000 - fp: 7624.0000 - tn: 18407.0000 - tp: 383.0000 - precision: 0.0478 - recall: 0.8149 - auc: 0.8411 - val_loss: 3.6291e-05 - val_fn: 39.0000 - val_fp: 1387.0000 - val_tn: 5124.0000 - val_tp: 75.0000 - val_precision: 0.0513 - val_recall: 0.6579 - val_auc: 0.8324\n",
      "Epoch 98/100\n",
      "26501/26501 - 1s - loss: 3.8030e-05 - fn: 104.0000 - fp: 7591.0000 - tn: 18440.0000 - tp: 366.0000 - precision: 0.0460 - recall: 0.7787 - auc: 0.8278 - val_loss: 3.6101e-05 - val_fn: 36.0000 - val_fp: 1604.0000 - val_tn: 4907.0000 - val_tp: 78.0000 - val_precision: 0.0464 - val_recall: 0.6842 - val_auc: 0.8332\n",
      "Epoch 99/100\n",
      "26501/26501 - 1s - loss: 3.8210e-05 - fn: 96.0000 - fp: 8001.0000 - tn: 18030.0000 - tp: 374.0000 - precision: 0.0447 - recall: 0.7957 - auc: 0.8321 - val_loss: 3.6512e-05 - val_fn: 38.0000 - val_fp: 1477.0000 - val_tn: 5034.0000 - val_tp: 76.0000 - val_precision: 0.0489 - val_recall: 0.6667 - val_auc: 0.8342\n",
      "Epoch 100/100\n",
      "26501/26501 - 1s - loss: 3.6960e-05 - fn: 90.0000 - fp: 7810.0000 - tn: 18221.0000 - tp: 380.0000 - precision: 0.0464 - recall: 0.8085 - auc: 0.8394 - val_loss: 3.6189e-05 - val_fn: 39.0000 - val_fp: 1480.0000 - val_tn: 5031.0000 - val_tp: 75.0000 - val_precision: 0.0482 - val_recall: 0.6579 - val_auc: 0.8344\n"
     ]
    }
   ],
   "source": [
    "# Train the model with class_weight argument\n",
    "ann_filepath = './trained_weights/ann/'\n",
    "\n",
    "metrics = [\n",
    "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    keras.metrics.TruePositives(name=\"tp\"),\n",
    "    keras.metrics.Precision(name=\"precision\"),\n",
    "    keras.metrics.Recall(name=\"recall\"),\n",
    "    keras.metrics.AUC(name=\"auc\")\n",
    "]\n",
    "\n",
    "ann_model.compile(\n",
    "    optimizer=Adam(0.002), loss=\"binary_crossentropy\", metrics=metrics\n",
    ")\n",
    "\n",
    "callbacks = [ModelCheckpoint(ann_filepath+\"identification_model_at_epoch_{epoch}.h5\")]\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "history_ann = ann_model.fit(\n",
    "    train_features,\n",
    "    train_targets,\n",
    "    batch_size=2048,\n",
    "    epochs=100,\n",
    "    verbose=2,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(val_features, val_targets),\n",
    "    class_weight=class_weight,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC:  0.8393627\n",
      "Test AUC:  0.83436996\n"
     ]
    }
   ],
   "source": [
    "# Determine AUC score\n",
    "# Pick out the history data that we want\n",
    "auc = history_ann.history['auc']\n",
    "val_auc = history_ann.history['val_auc']\n",
    "loss = history_ann.history['loss']\n",
    "val_loss = history_ann.history['val_loss']\n",
    "epochs = range(len(auc))\n",
    "\n",
    "train_auc = auc[-1]\n",
    "print(\"Train AUC: \",train_auc)\n",
    "\n",
    "test_auc = val_auc[-1]\n",
    "print(\"Test AUC: \",test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(epochs, auc, 'r')\n",
    "plt.plot(epochs, val_auc, 'b')\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('AUC')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test predictions to file\n",
    "preds_test = ann_model.predict(X_test_pp_np)\n",
    "\n",
    "# Use .ravel() to flatten from 10982,1 to 10982,\n",
    "output = pd.DataFrame({'image_name': X_test_load.image_name,\n",
    "                       'target': preds_test.ravel()})\n",
    "output.to_csv('./predictions/csv_only_submission_ann.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
