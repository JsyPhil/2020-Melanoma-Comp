{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import efficientnet_pytorch\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load CSV's\n",
    "df_train = pd.read_csv('/home/malmason/datasets/siim-isic-melanoma-classification/train.csv')\n",
    "df_test = pd.read_csv('/home/malmason/datasets/siim-isic-melanoma-classification/test.csv')\n",
    "\n",
    "df_train_ham = pd.read_csv('/home/malmason/datasets/siim-isic-melanoma-classification/ham_10000_mel_isic_add.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train  = df_train.append(df_train_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.append(df_train.loc[df_train['target'] == 1])\n",
    "df_train = df_train.append(df_train.loc[df_train['target'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['sex'] = df_train['sex'].fillna('na')\n",
    "df_train['age_approx'] = df_train['age_approx'].fillna(0)\n",
    "df_train['anatom_site_general_challenge'] = df_train['anatom_site_general_challenge'].fillna('na')\n",
    "\n",
    "df_test['sex'] = df_test['sex'].fillna('na')\n",
    "df_test['age_approx'] = df_test['age_approx'].fillna(0)\n",
    "df_test['anatom_site_general_challenge'] = df_test['anatom_site_general_challenge'].fillna('na')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_train), len(df_train.loc[df_train['target'] == 0]), len(df_train.loc[df_train['target'] == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_img = df_train['image_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_csv = df_train.drop(['target', 'image_name'], axis=1).values\n",
    "y_csv = df_train['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_csv.shape, y_csv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.base_model = efficientnet_pytorch.EfficientNet.from_pretrained('efficientnet-b4')\n",
    "        self.base_model._fc = nn.Linear(1792, 32)\n",
    "        self.last_layer = nn.Linear(32,2)\n",
    "        self.soft = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        x = self.last_layer(x)\n",
    "        x = self.soft(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.base_model.parameters(): param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.base_model._fc.weight.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_image = []\n",
    "for image_get in X_img:\n",
    "    img = cv2.imread(img_train_folder + '{}.jpg'.format(image_get))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    X_image.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(y_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(90),\n",
    "    transforms.RandomResizedCrop(380, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485,0.456,0.406), (0.229,0.224,0.225)),\n",
    "    transforms.RandomErasing(p=0.2, scale=(0.02, 0.33)),\n",
    "    transforms.ToPILImage()\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "n_epochs = 20\n",
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_images(X_train_image, X_val_image, Y_train, Y_val):\n",
    "    # Train images\n",
    "    train_images = []\n",
    "    \n",
    "    gc.collect()\n",
    "        \n",
    "    for image_get in X_train_image:\n",
    "        image_trans = preprocess(image_get)\n",
    "        image_trans = np.array(image_trans)\n",
    "        train_images.append(image_trans)         \n",
    "\n",
    "    train_images = np.array(train_images).astype(np.float32)\n",
    "  \n",
    "    X_train_image_t = np.transpose(train_images, (0,3,1,2))\n",
    "    input_train = torch.from_numpy(X_train_image_t)\n",
    "    \n",
    "    X_train_image_t = [] \n",
    "\n",
    "    target_train = torch.from_numpy(Y_train).reshape(-1,1).long()\n",
    "\n",
    "    # Val Images\n",
    "    val_images = []\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    for image_get in X_val_image:\n",
    "        image_trans = preprocess(image_get)\n",
    "        image_trans = np.array(image_trans)\n",
    "        val_images.append(image_trans)\n",
    "\n",
    "            \n",
    "    val_images = np.array(val_images).astype(np.float32)\n",
    " \n",
    "    X_val_image_t = np.transpose(val_images, (0,3,1,2))\n",
    "    input_val = torch.from_numpy(X_val_image_t)\n",
    "\n",
    "    X_val_image_t = []\n",
    "    \n",
    "    target_val = torch.from_numpy(Y_val).reshape(-1,1).long()\n",
    "    \n",
    "    training_set = torch.utils.data.TensorDataset(input_train,  target_train)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=training_set, \n",
    "                                               batch_size=batch_size,\n",
    "                                               num_workers=4,\n",
    "                                               shuffle=True)\n",
    "    val_set = torch.utils.data.TensorDataset(input_val, target_val)\n",
    "    val_loader = torch.utils.data.DataLoader(dataset=val_set, \n",
    "                                               batch_size=batch_size,\n",
    "                                             num_workers=4,\n",
    "                                             shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nSamples = [len(df_train.loc[df_train['target'] == 0]), len(df_train.loc[df_train['target'] == 1])]\n",
    "normedWeights = [1 - (x / sum(nSamples)) for x in nSamples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = torch.FloatTensor(normedWeights).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(weight = class_weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(output_pred, target):\n",
    "\n",
    "    correct_results_sum = (torch.argmax(output_pred, axis=1) == target).sum().float()\n",
    "    acc = correct_results_sum/target.shape[0] \n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_split = (X_img.shape[0]/6)\n",
    "XF = [0, round(X_split), round(X_split*2), round(X_split*3), round(X_split*4), round(X_split*5), round(X_split*6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gd(model, criterion, optimizer, X_image, Y, n_epochs, XF):\n",
    "    train_losses = np.zeros(n_epochs)\n",
    "    val_losses = np.zeros(n_epochs)\n",
    "    train_accuracy = np.zeros(n_epochs)\n",
    "    val_accuracy = np.zeros(n_epochs)\n",
    "        \n",
    "    for it in range (n_epochs):\n",
    "        t0 = datetime.now()\n",
    "        \n",
    "        for count in range(6):\n",
    "\n",
    "            train_loss = []\n",
    "            train_acc = []\n",
    "            \n",
    "            if count == 0:\n",
    "                X_train_image, Y_train = X_image[:XF[5]],                    Y[:XF[5]]\n",
    "                X_val_image,   Y_val   = X_image[XF[5]:],                    Y[XF[5]:]\n",
    "            elif count == 1:\n",
    "                X_train_image, Y_train = X_image[:XF[4]] + X_image[XF[5]:],  np.concatenate((Y[:XF[4]], Y[XF[5]:]),axis=0)\n",
    "                X_val_image,   Y_val   = X_image[XF[4]:XF[5]],               Y[XF[4]:XF[5]]\n",
    "            elif count == 2:\n",
    "                X_train_image, Y_train = X_image[:XF[3]] + X_image[XF[4]:],  np.concatenate((Y[:XF[3]], Y[XF[4]:]),axis=0)\n",
    "                X_val_image,   Y_val   = X_image[XF[3]:XF[4]],               Y[XF[3]:XF[4]]\n",
    "            elif count == 3:\n",
    "                X_train_image, Y_train = X_image[:XF[2]] + X_image[XF[3]:],  np.concatenate((Y[:XF[2]], Y[XF[3]:]),axis=0)\n",
    "                X_val_image,   Y_val   = X_image[XF[2]:XF[3]],               Y[XF[2]:XF[3]]\n",
    "            elif count == 4:\n",
    "                X_train_image, Y_train = X_image[:XF[1]] +  X_image[XF[2]:], np.concatenate((Y[:XF[1]], Y[XF[2]:]),axis=0)\n",
    "                X_val_image,   Y_val   = X_image[XF[1]:XF[2]],               Y[XF[1]:XF[2]]\n",
    "            else:\n",
    "                X_train_image, Y_train = X_image[XF[1]:],                    Y[XF[1]:]\n",
    "                X_val_image,   Y_val   = X_image[:XF[1]],                    Y[:XF[1]]\n",
    "\n",
    "            train_loader, val_loader = transform_images(X_train_image, X_val_image, Y_train, Y_val)\n",
    "\n",
    "            for inputs, targets in tqdm(train_loader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                targets = targets.squeeze_()\n",
    "\n",
    "                loss = criterion(outputs, targets)\n",
    "                acc = binary_acc(outputs, targets)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss.append(loss.item())\n",
    "                train_acc.append(acc.item())\n",
    "\n",
    "            train_loss = np.mean(train_loss)\n",
    "            train_acc = np.mean(train_acc)\n",
    "\n",
    "            val_loss = []\n",
    "            val_acc = []\n",
    "            val_auc = []\n",
    "            targets_auc = []\n",
    "            outputs_auc = []\n",
    "            outputs_auc_temp = []\n",
    "            auc_val_fold = []\n",
    "            \n",
    "            for inputs, targets in tqdm(val_loader):\n",
    "                inputs, targets = inputs.to(device),  targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                targets = targets.squeeze_()\n",
    "\n",
    "                loss = criterion(outputs, targets)\n",
    "                acc = binary_acc(outputs, targets)\n",
    "                \n",
    "                targets_auc.append(targets.detach().cpu().numpy())\n",
    "                outputs_auc_temp = outputs.detach().cpu().numpy()\n",
    "                outputs_auc_temp = np.squeeze(outputs_auc_temp[:,1:2])\n",
    "                outputs_auc.append(outputs_auc_temp)\n",
    "\n",
    "                val_loss.append(loss.item())\n",
    "                val_acc.append(acc.item())\n",
    "\n",
    "            val_loss = np.mean(val_loss)\n",
    "            val_acc = np.mean(val_acc)\n",
    "            targets_auc = np.array(targets_auc, dtype = object)\n",
    "            outputs_auc = np.array(outputs_auc, dtype = object)\n",
    "            targets_auc = np.hstack(targets_auc)\n",
    "            outputs_auc = np.hstack(outputs_auc)\n",
    "            #print(targets_auc, np.round(outputs_auc))\n",
    "            auc_val_fold.append(roc_auc_score(targets_auc, outputs_auc))\n",
    "        \n",
    "        auc_val = np.mean(auc_val_fold)\n",
    "            \n",
    "        train_losses[it] = train_loss\n",
    "        val_losses[it] = val_loss\n",
    "        train_accuracy[it] = train_acc\n",
    "        val_accuracy[it] = val_acc\n",
    "\n",
    "        scheduler.step()\n",
    "        dt = datetime.now() -t0\n",
    "        \n",
    "        torch.save(model.state_dict(), '/home/malmason/datasets/siim-isic-melanoma-classification/lr0-001 gamma0-05 300 rgb B4-1/skin_train_concat_rgb_eff_net_b4_train_all_model_all_preproc' + str(it) + '.pt')\n",
    "\n",
    "        print(f'Epoch {it+1}/{n_epochs}, Time: {dt}, Train Loss: {train_loss:.4f}, Train_acc: {train_acc}, Val Loss: {val_loss:.4f}, Val acc: {val_acc}, Val AUC: {auc_val}')\n",
    "    \n",
    "    return train_losses, val_losses, train_accuracy, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses, train_accuracy, val_accuracy = batch_gd(\n",
    "    model, criterion, optimizer, X_image, Y, n_epochs, XF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(val_losses, label='val loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_accuracy, label='train accuracy')\n",
    "plt.plot(val_accuracy, label='val accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_csv = df_test\n",
    "X_test_img = df_test_csv['image_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submission = pd.DataFrame({'image_name':X_test_img})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('/home/malmason/datasets/siim-isic-melanoma-classification/lr0-001 gamma0-05 300 rgb B4/skin_train_concat_rgb_eff_net_b4_train_all_model_all_preproc16.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_image = []\n",
    "for image_get in X_test_img:\n",
    "    img_test = cv2.imread(img_test_folder + '{}.jpg'.format(image_get))\n",
    "    img_test = cv2.cvtColor(img_test, cv2.COLOR_BGR2RGB)\n",
    "    X_test_image.append(img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_val = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(90),\n",
    "    transforms.RandomResizedCrop(380, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485,0.456,0.406), (0.229,0.224,0.225)),\n",
    "    transforms.ToPILImage()\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "Y_dummy = np.zeros(len(X_test_image)).astype(np.float32)\n",
    "print(Y_dummy.shape)\n",
    "Y_dummy = torch.from_numpy(Y_dummy).reshape(-1,1).long()\n",
    "\n",
    "for count in range(6):\n",
    "    outputs_auc = []\n",
    "    test_images = []\n",
    "    outputs_auc_temp = []\n",
    "\n",
    "    for image_get in tqdm(X_test_image):\n",
    "        image_trans = preprocess_val(image_get)\n",
    "        image_trans = np.array(image_trans)\n",
    "        test_images.append(image_trans)\n",
    "\n",
    "    test_images = np.asarray(test_images).astype(np.float32)\n",
    "\n",
    "    X_test_image_t = np.transpose(test_images, (0,3,1,2))\n",
    "\n",
    "    input_test = torch.from_numpy(X_test_image_t)\n",
    "\n",
    "    test_set = torch.utils.data.TensorDataset(input_test, Y_dummy)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=4,num_workers=0,shuffle=False)\n",
    "\n",
    "    outputs_auc = []\n",
    "    outputs_auc_temp = []\n",
    "\n",
    "    with torch.no_grad():    \n",
    "        for inputs, targets in tqdm(test_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            outputs_auc_temp = outputs.detach().cpu().numpy()\n",
    "            outputs_auc_temp = np.squeeze(outputs_auc_temp[:,1:2])\n",
    "            outputs_auc.append(outputs_auc_temp)\n",
    "\n",
    "    outputs_auc = np.array(outputs_auc, dtype = object)\n",
    "    outputs_auc = np.hstack(outputs_auc)\n",
    "\n",
    "    test_submission[count] = outputs_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submission['target'] = test_submission.apply((lambda x: (x[0] + x[1] + x[2] + x[3] + x[4] + x[5])/6), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_submission[0], test_submission[1],test_submission[2],test_submission[3],test_submission[4],test_submission[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submission[test_submission['target'] > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submission.to_csv('/home/malmason/datasets/siim-isic-melanoma-classification/tests/B4_preds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_auc = df_test_csv['target'].values\n",
    "outputs_auc = test_submission['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(targets_auc, outputs_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge using probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/home/malmason/datasets/siim-isic-melanoma-classification/train.csv')\n",
    "df_test = pd.read_csv('/home/malmason/datasets/siim-isic-melanoma-classification/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = ['sex','age_approx','anatom_site_general_challenge']\n",
    "M = df_train.target.mean()\n",
    "te = df_train.groupby(feat)['target'].agg(['mean','count']).reset_index()\n",
    "te['ll'] = ((te['mean']*te['count'])+(M))/(te['count'])\n",
    "del te['mean'], te['count']\n",
    "\n",
    "df_test = df_test.merge( te, on=feat, how='left' )\n",
    "df_test['ll'] = df_test['ll'].fillna(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_csv = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pred_csv['patient_id'], pred_csv['sex'], pred_csv['age_approx'], pred_csv['anatom_site_general_challenge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submission_csv = pred_csv['ll']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submission = test_submission.join(test_submission_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submission.rename(columns = {'target':'image_pred'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submission_comb = test_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submission_comb['target'] = (test_submission_comb['image_pred'] *0.9) + (test_submission_comb['ll'] *0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_submission_comb['image_pred'], test_submission_comb['ll']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submission_comb.rename(columns = {'image_pred':'target'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submission_comb[test_submission['target'] > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submission_comb.to_csv('/home/malmason/datasets/siim-isic-melanoma-classification/lr0-001 gamma0-05 300 rgb B4-1/test_submission_comb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
