{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "csv_train_file = pd.read_csv('./siim-isic-melanoma-classification/train.csv')\n",
    "csv_test_file = pd.read_csv('./siim-isic-melanoma-classification/test.csv')\n",
    "\n",
    "# Separate target from predictors\n",
    "y = csv_train_file.target\n",
    "csv_train_file.drop(['target', 'benign_malignant', 'diagnosis'], axis=1, inplace=True)\n",
    "\n",
    "X_train_load = csv_train_file\n",
    "X_test_load = csv_test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Examples = 33126\n",
      "Number of Test Examples = 10982\n",
      "\n",
      "Training X Shape = (33126, 5)\n",
      "Training y Shape = (33126,)\n",
      "\n",
      "Test X Shape = (10982, 5)\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of Training Examples = {X_train_load.shape[0]}')\n",
    "print(f'Number of Test Examples = {X_test_load.shape[0]}\\n')\n",
    "\n",
    "print(f'Training X Shape = {X_train_load.shape}')\n",
    "print(f'Training y Shape = {y.shape}\\n')\n",
    "\n",
    "print(f'Test X Shape = {X_test_load.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_df(X_train, X_test):\n",
    "    # Returns a concatenated df of training and test set\n",
    "    return pd.concat([X_train, X_test], sort=True).reset_index(drop=True)\n",
    "\n",
    "def divide_df(all_data):\n",
    "    # Returns divided dfs of training and test set\n",
    "    return all_data.loc[:33125], all_data.loc[33126:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Feature - Image Size\n",
    "\n",
    "Inspired by https://www.kaggle.com/awsaf49/xgboost-tabular-data-ml-cv-85-lb-787"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33126/33126 [00:00<00:00, 34182.02it/s]\n",
      "100%|██████████| 10982/10982 [00:00<00:00, 33425.84it/s]\n"
     ]
    }
   ],
   "source": [
    "train_images = X_train_load['image_name'].values\n",
    "train_sizes = np.zeros(train_images.shape[0])\n",
    "for i, img_path in enumerate(tqdm(train_images)):\n",
    "    train_sizes[i] = os.path.getsize(os.path.join('./siim-isic-melanoma-classification/jpeg/train/', f'{img_path}.jpg'))\n",
    "    \n",
    "X_train_load['image_size'] = train_sizes\n",
    "\n",
    "test_images = X_test_load['image_name'].values\n",
    "test_sizes = np.zeros(test_images.shape[0])\n",
    "for i, img_path in enumerate(tqdm(test_images)):\n",
    "    test_sizes[i] = os.path.getsize(os.path.join('./siim-isic-melanoma-classification/jpeg/test/', f'{img_path}.jpg'))\n",
    "    \n",
    "X_test_load['image_size'] = test_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44108, 6)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Aggregate the X data for further pre-processing\n",
    "X_all = concat_df(X_train_load, X_test_load)\n",
    "\n",
    "X_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Feature - No of images per patient\n",
    "\n",
    "Inspired by https://www.kaggle.com/awsaf49/xgboost-tabular-data-ml-cv-85-lb-787"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all['n_images'] = X_all.patient_id.map(X_all.groupby(['patient_id']).image_name.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    44108.000000\n",
       "mean        31.884647\n",
       "std         28.074315\n",
       "min          2.000000\n",
       "25%         14.000000\n",
       "50%         25.000000\n",
       "75%         40.000000\n",
       "max        240.000000\n",
       "Name: n_images, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all['n_images'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bin the image numbers into 10 bins\n",
    "categorize_im_num = KBinsDiscretizer(n_bins = 10, encode = 'ordinal', strategy = 'uniform')\n",
    "\n",
    "X_all['n_images_enc'] = categorize_im_num.fit_transform(X_all['n_images'].values.reshape(-1, 1)).astype(int).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale and bin image size\n",
    "scale = MinMaxScaler()\n",
    "X_all['image_size_scaled'] = scale.fit_transform(X_all['image_size'].values.reshape(-1, 1))\n",
    "\n",
    "categorize_im_size = KBinsDiscretizer(n_bins = 10, encode = 'ordinal', strategy = 'uniform')\n",
    "X_all['image_size_enc'] = categorize_im_size.fit_transform(X_all.image_size_scaled.values.reshape(-1, 1)).astype(int).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Feature - Age Min/Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all['age_id_min']  = X_all['patient_id'].map(X_all.groupby(['patient_id']).age_approx.min())\n",
    "X_all['age_id_max']  = X_all['patient_id'].map(X_all.groupby(['patient_id']).age_approx.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44108 entries, 0 to 44107\n",
      "Data columns (total 12 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   age_approx                     44040 non-null  float64\n",
      " 1   anatom_site_general_challenge  43230 non-null  object \n",
      " 2   image_name                     44108 non-null  object \n",
      " 3   image_size                     44108 non-null  float64\n",
      " 4   patient_id                     44108 non-null  object \n",
      " 5   sex                            44043 non-null  object \n",
      " 6   n_images                       44108 non-null  int64  \n",
      " 7   n_images_enc                   44108 non-null  int64  \n",
      " 8   image_size_scaled              44108 non-null  float64\n",
      " 9   image_size_enc                 44108 non-null  int64  \n",
      " 10  age_id_min                     44040 non-null  float64\n",
      " 11  age_id_max                     44040 non-null  float64\n",
      "dtypes: float64(5), int64(3), object(4)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "X_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44108, 7)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select categorical columns\n",
    "categorical_cols = ['sex', 'anatom_site_general_challenge']\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = ['age_approx','age_id_min','age_id_max', 'n_images', 'image_size_scaled']\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = categorical_cols + numerical_cols\n",
    "X_all_card = X_all[my_cols].copy()\n",
    "\n",
    "X_all_card.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Examples = 33126\n",
      "Number of Test Examples = 10982\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = divide_df(X_all_card)\n",
    "\n",
    "print(f'Number of Training Examples = {X_train.shape[0]}')\n",
    "print(f'Number of Test Examples = {X_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for numerical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "                                ('imputern', SimpleImputer(strategy='constant')),\n",
    "                                ('scaler', StandardScaler())\n",
    "                                 ])\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "                                ('imputerc', SimpleImputer(strategy='constant')),\n",
    "                                ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "                                ])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_gs = XGBRegressor(base_score=0.5, booster=None, colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=0.8, gamma=1, gpu_id=-1,\n",
    "             importance_type='gain', interaction_constraints=None,\n",
    "             learning_rate=0.002, max_delta_step=0, max_depth=10,\n",
    "             min_child_weight=1, missing=None, monotone_constraints=None,\n",
    "             n_estimators=700, n_jobs=-1, nthread=-1, num_parallel_tree=1,\n",
    "             objective='binary:logistic', random_state=0, reg_alpha=0,\n",
    "             reg_lambda=1, scale_pos_weight=1, silent=True, subsample=0.8,\n",
    "             tree_method=None, validate_parameters=False, verbosity=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(param_grid):\n",
    "\n",
    "    score_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', xgb_gs)])\n",
    "  \n",
    "    \n",
    "    search = GridSearchCV(score_pipeline, \n",
    "                          param_grid, \n",
    "                          #n_jobs=4,\n",
    "                          cv=5,\n",
    "                          verbose=3,\n",
    "                          scoring='roc_auc'\n",
    "                         )\n",
    "    \n",
    "    search.fit(X_train, y)\n",
    "    \n",
    "    print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "    print(search.best_params_)\n",
    "    return search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] model__learning_rate=0.01 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... model__learning_rate=0.01, score=0.857, total=  21.9s\n",
      "[CV] model__learning_rate=0.01 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   21.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... model__learning_rate=0.01, score=0.856, total=  21.5s\n",
      "[CV] model__learning_rate=0.01 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   43.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... model__learning_rate=0.01, score=0.840, total=  21.9s\n",
      "[CV] model__learning_rate=0.01 .......................................\n",
      "[CV] ........... model__learning_rate=0.01, score=0.828, total=  21.9s\n",
      "[CV] model__learning_rate=0.01 .......................................\n",
      "[CV] ........... model__learning_rate=0.01, score=0.850, total=  22.3s\n",
      "[CV] model__learning_rate=0.002 ......................................\n",
      "[CV] .......... model__learning_rate=0.002, score=0.846, total=  16.1s\n",
      "[CV] model__learning_rate=0.002 ......................................\n",
      "[CV] .......... model__learning_rate=0.002, score=0.837, total=  15.5s\n",
      "[CV] model__learning_rate=0.002 ......................................\n",
      "[CV] .......... model__learning_rate=0.002, score=0.833, total=  15.6s\n",
      "[CV] model__learning_rate=0.002 ......................................\n",
      "[CV] .......... model__learning_rate=0.002, score=0.823, total=  15.6s\n",
      "[CV] model__learning_rate=0.002 ......................................\n",
      "[CV] .......... model__learning_rate=0.002, score=0.844, total=  16.0s\n",
      "[CV] model__learning_rate=0.001 ......................................\n",
      "[CV] .......... model__learning_rate=0.001, score=0.840, total=  14.9s\n",
      "[CV] model__learning_rate=0.001 ......................................\n",
      "[CV] .......... model__learning_rate=0.001, score=0.823, total=  14.5s\n",
      "[CV] model__learning_rate=0.001 ......................................\n",
      "[CV] .......... model__learning_rate=0.001, score=0.832, total=  14.6s\n",
      "[CV] model__learning_rate=0.001 ......................................\n",
      "[CV] .......... model__learning_rate=0.001, score=0.815, total=  14.5s\n",
      "[CV] model__learning_rate=0.001 ......................................\n",
      "[CV] .......... model__learning_rate=0.001, score=0.832, total=  14.9s\n",
      "[CV] model__learning_rate=0.002 ......................................\n",
      "[CV] .......... model__learning_rate=0.002, score=0.846, total=  16.5s\n",
      "[CV] model__learning_rate=0.002 ......................................\n",
      "[CV] .......... model__learning_rate=0.002, score=0.837, total=  15.7s\n",
      "[CV] model__learning_rate=0.002 ......................................\n",
      "[CV] .......... model__learning_rate=0.002, score=0.833, total=  16.1s\n",
      "[CV] model__learning_rate=0.002 ......................................\n",
      "[CV] .......... model__learning_rate=0.002, score=0.823, total=  15.5s\n",
      "[CV] model__learning_rate=0.002 ......................................\n",
      "[CV] .......... model__learning_rate=0.002, score=0.844, total=  16.0s\n",
      "[CV] model__learning_rate=0.003 ......................................\n",
      "[CV] .......... model__learning_rate=0.003, score=0.851, total=  17.5s\n",
      "[CV] model__learning_rate=0.003 ......................................\n",
      "[CV] .......... model__learning_rate=0.003, score=0.857, total=  17.1s\n",
      "[CV] model__learning_rate=0.003 ......................................\n",
      "[CV] .......... model__learning_rate=0.003, score=0.838, total=  17.3s\n",
      "[CV] model__learning_rate=0.003 ......................................\n",
      "[CV] .......... model__learning_rate=0.003, score=0.827, total=  16.9s\n",
      "[CV] model__learning_rate=0.003 ......................................\n",
      "[CV] .......... model__learning_rate=0.003, score=0.853, total=  17.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  7.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.846):\n",
      "{'model__learning_rate': 0.01}\n",
      "Time taken:  454.9312767982483\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'model__learning_rate':[0.01,0.002,0.001,0.002,0.003]}\n",
    "\n",
    "start = time.time()\n",
    "grid = get_score(param_grid)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(\"Time taken: \", elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_final = XGBRegressor(base_score=0.5, booster=None, colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=0.8, gamma=1, \n",
    "             importance_type='gain', interaction_constraints=None,\n",
    "             learning_rate=0.01, max_delta_step=0, max_depth=10,\n",
    "             min_child_weight=1, missing=None, monotone_constraints=None,\n",
    "             n_estimators=700, num_parallel_tree=1,\n",
    "             objective='binary:logistic', random_state=0, reg_alpha=0,\n",
    "             reg_lambda=1, scale_pos_weight=1, silent=True, subsample=0.8,\n",
    "             tree_method=None, validate_parameters=False, verbosity=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  27.08568501472473\n"
     ]
    }
   ],
   "source": [
    "# Build final model based on best parameters\n",
    "\n",
    "start = time.time()\n",
    "submission_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', xgb_final)\n",
    "    ])\n",
    "\n",
    "submission_pipeline.fit(X_train, y)\n",
    "elapsed = time.time() - start\n",
    "print(\"Time taken: \", elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7faa9ab6aa90>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_important = xgb_final.get_booster().get_score(importance_type='weight')\n",
    "keys = list(feature_important.keys())\n",
    "values = list(feature_important.values())\n",
    "\n",
    "data = pd.DataFrame(data=values, index=keys, columns=[\"score\"]).sort_values(by = \"score\", ascending=False)\n",
    "plt.figure(figsize= (12,10))\n",
    "sns.barplot(x = data.score , y = data.index, orient = 'h', palette = 'Blues_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = submission_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test predictions to file\n",
    "output = pd.DataFrame({'image_name': X_test_load.image_name,\n",
    "                       'target': preds_test})\n",
    "output.to_csv('./cleaned_csvs/csv_only_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
