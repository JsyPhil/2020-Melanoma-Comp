{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "csv_train_file = pd.read_csv('./siim-isic-melanoma-classification/train.csv')\n",
    "csv_test_file = pd.read_csv('./siim-isic-melanoma-classification/test.csv')\n",
    "\n",
    "# Separate target from predictors\n",
    "y = csv_train_file.target\n",
    "csv_train_file.drop(['target', 'benign_malignant', 'diagnosis'], axis=1, inplace=True)\n",
    "\n",
    "X_train_load = csv_train_file\n",
    "X_test_load = csv_test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Examples = 33126\n",
      "Number of Test Examples = 10982\n",
      "\n",
      "Training X Shape = (33126, 5)\n",
      "Training y Shape = (33126,)\n",
      "\n",
      "Test X Shape = (10982, 5)\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of Training Examples = {X_train_load.shape[0]}')\n",
    "print(f'Number of Test Examples = {X_test_load.shape[0]}\\n')\n",
    "\n",
    "print(f'Training X Shape = {X_train_load.shape}')\n",
    "print(f'Training y Shape = {y.shape}\\n')\n",
    "\n",
    "print(f'Test X Shape = {X_test_load.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_df(X_train, X_test):\n",
    "    # Returns a concatenated df of training and test set\n",
    "    return pd.concat([X_train, X_test], sort=True).reset_index(drop=True)\n",
    "\n",
    "def divide_df(all_data):\n",
    "    # Returns divided dfs of training and test set\n",
    "    return all_data.loc[:33125], all_data.loc[33126:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Feature - Image Size\n",
    "\n",
    "Inspired by https://www.kaggle.com/awsaf49/xgboost-tabular-data-ml-cv-85-lb-787"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33126/33126 [00:00<00:00, 84721.69it/s]\n",
      "100%|██████████| 10982/10982 [00:00<00:00, 119025.32it/s]\n"
     ]
    }
   ],
   "source": [
    "train_images = X_train_load['image_name'].values\n",
    "train_sizes = np.zeros(train_images.shape[0])\n",
    "for i, img_path in enumerate(tqdm(train_images)):\n",
    "    train_sizes[i] = os.path.getsize(os.path.join('./siim-isic-melanoma-classification/jpeg/train/', f'{img_path}.jpg'))\n",
    "    \n",
    "X_train_load['image_size'] = train_sizes\n",
    "\n",
    "test_images = X_test_load['image_name'].values\n",
    "test_sizes = np.zeros(test_images.shape[0])\n",
    "for i, img_path in enumerate(tqdm(test_images)):\n",
    "    test_sizes[i] = os.path.getsize(os.path.join('./siim-isic-melanoma-classification/jpeg/test/', f'{img_path}.jpg'))\n",
    "    \n",
    "X_test_load['image_size'] = test_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44108, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Aggregate the X data for further pre-processing\n",
    "X_all = concat_df(X_train_load, X_test_load)\n",
    "\n",
    "X_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Feature - No of images per patient\n",
    "\n",
    "Inspired by https://www.kaggle.com/awsaf49/xgboost-tabular-data-ml-cv-85-lb-787"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all['n_images'] = X_all.patient_id.map(X_all.groupby(['patient_id']).image_name.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    44108.000000\n",
       "mean        31.884647\n",
       "std         28.074315\n",
       "min          2.000000\n",
       "25%         14.000000\n",
       "50%         25.000000\n",
       "75%         40.000000\n",
       "max        240.000000\n",
       "Name: n_images, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all['n_images'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bin the image numbers into 10 bins\n",
    "categorize_im_num = KBinsDiscretizer(n_bins = 10, encode = 'ordinal', strategy = 'uniform')\n",
    "\n",
    "X_all['n_images_enc'] = categorize_im_num.fit_transform(X_all['n_images'].values.reshape(-1, 1)).astype(int).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale and bin image size\n",
    "scale = MinMaxScaler()\n",
    "X_all['image_size_scaled'] = scale.fit_transform(X_all['image_size'].values.reshape(-1, 1))\n",
    "\n",
    "categorize_im_size = KBinsDiscretizer(n_bins = 10, encode = 'ordinal', strategy = 'uniform')\n",
    "X_all['image_size_enc'] = categorize_im_size.fit_transform(X_all.image_size_scaled.values.reshape(-1, 1)).astype(int).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Feature - Age Min/Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all['age_id_min']  = X_all['patient_id'].map(X_all.groupby(['patient_id']).age_approx.min())\n",
    "X_all['age_id_max']  = X_all['patient_id'].map(X_all.groupby(['patient_id']).age_approx.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44108 entries, 0 to 44107\n",
      "Data columns (total 12 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   age_approx                     44040 non-null  float64\n",
      " 1   anatom_site_general_challenge  43230 non-null  object \n",
      " 2   image_name                     44108 non-null  object \n",
      " 3   image_size                     44108 non-null  float64\n",
      " 4   patient_id                     44108 non-null  object \n",
      " 5   sex                            44043 non-null  object \n",
      " 6   n_images                       44108 non-null  int64  \n",
      " 7   n_images_enc                   44108 non-null  int64  \n",
      " 8   image_size_scaled              44108 non-null  float64\n",
      " 9   image_size_enc                 44108 non-null  int64  \n",
      " 10  age_id_min                     44040 non-null  float64\n",
      " 11  age_id_max                     44040 non-null  float64\n",
      "dtypes: float64(5), int64(3), object(4)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "X_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44108, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select categorical columns\n",
    "categorical_cols = ['sex', 'anatom_site_general_challenge']\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = ['age_approx','age_id_min','age_id_max', 'n_images', 'image_size_scaled']\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = categorical_cols + numerical_cols\n",
    "X_all_card = X_all[my_cols].copy()\n",
    "\n",
    "X_all_card.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Examples = 33126\n",
      "Number of Test Examples = 10982\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = divide_df(X_all_card)\n",
    "\n",
    "print(f'Number of Training Examples = {X_train.shape[0]}')\n",
    "print(f'Number of Test Examples = {X_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for numerical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "                                ('imputern', SimpleImputer(strategy='constant')),\n",
    "                                ('scaler', StandardScaler())\n",
    "                                 ])\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "                                ('imputerc', SimpleImputer(strategy='constant')),\n",
    "                                ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "                                ])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_gs = XGBRegressor(base_score=0.5, booster=None, colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=0.8, gamma=1, gpu_id=-1,\n",
    "             importance_type='gain', interaction_constraints=None,\n",
    "             learning_rate=0.002, max_delta_step=0, max_depth=10,\n",
    "             min_child_weight=1, missing=None, monotone_constraints=None,\n",
    "             n_estimators=700, n_jobs=-1, nthread=-1, num_parallel_tree=1,\n",
    "             objective='binary:logistic', random_state=0, reg_alpha=0,\n",
    "             reg_lambda=1, scale_pos_weight=1, silent=True, subsample=0.8,\n",
    "             tree_method=None, validate_parameters=False, verbosity=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(param_grid):\n",
    "\n",
    "    score_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', xgb_gs)])\n",
    "  \n",
    "    \n",
    "    search = GridSearchCV(score_pipeline, \n",
    "                          param_grid, \n",
    "                          #n_jobs=4,\n",
    "                          cv=5,\n",
    "                          verbose=3,\n",
    "                          scoring='roc_auc'\n",
    "                         )\n",
    "    \n",
    "    search.fit(X_train, y)\n",
    "    \n",
    "    print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "    print(search.best_params_)\n",
    "    return search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] model__learning_rate=0.01 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... model__learning_rate=0.01, score=0.857, total=  21.9s\n",
      "[CV] model__learning_rate=0.01 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   21.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... model__learning_rate=0.01, score=0.856, total=  21.5s\n",
      "[CV] model__learning_rate=0.01 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   43.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... model__learning_rate=0.01, score=0.840, total=  21.9s\n",
      "[CV] model__learning_rate=0.01 .......................................\n",
      "[CV] ........... model__learning_rate=0.01, score=0.828, total=  21.9s\n",
      "[CV] model__learning_rate=0.01 .......................................\n",
      "[CV] ........... model__learning_rate=0.01, score=0.850, total=  22.3s\n",
      "[CV] model__learning_rate=0.002 ......................................\n",
      "[CV] .......... model__learning_rate=0.002, score=0.846, total=  16.1s\n",
      "[CV] model__learning_rate=0.002 ......................................\n",
      "[CV] .......... model__learning_rate=0.002, score=0.837, total=  15.5s\n",
      "[CV] model__learning_rate=0.002 ......................................\n",
      "[CV] .......... model__learning_rate=0.002, score=0.833, total=  15.6s\n",
      "[CV] model__learning_rate=0.002 ......................................\n",
      "[CV] .......... model__learning_rate=0.002, score=0.823, total=  15.6s\n",
      "[CV] model__learning_rate=0.002 ......................................\n",
      "[CV] .......... model__learning_rate=0.002, score=0.844, total=  16.0s\n",
      "[CV] model__learning_rate=0.001 ......................................\n",
      "[CV] .......... model__learning_rate=0.001, score=0.840, total=  14.9s\n",
      "[CV] model__learning_rate=0.001 ......................................\n",
      "[CV] .......... model__learning_rate=0.001, score=0.823, total=  14.5s\n",
      "[CV] model__learning_rate=0.001 ......................................\n",
      "[CV] .......... model__learning_rate=0.001, score=0.832, total=  14.6s\n",
      "[CV] model__learning_rate=0.001 ......................................\n",
      "[CV] .......... model__learning_rate=0.001, score=0.815, total=  14.5s\n",
      "[CV] model__learning_rate=0.001 ......................................\n",
      "[CV] .......... model__learning_rate=0.001, score=0.832, total=  14.9s\n",
      "[CV] model__learning_rate=0.002 ......................................\n",
      "[CV] .......... model__learning_rate=0.002, score=0.846, total=  16.5s\n",
      "[CV] model__learning_rate=0.002 ......................................\n",
      "[CV] .......... model__learning_rate=0.002, score=0.837, total=  15.7s\n",
      "[CV] model__learning_rate=0.002 ......................................\n",
      "[CV] .......... model__learning_rate=0.002, score=0.833, total=  16.1s\n",
      "[CV] model__learning_rate=0.002 ......................................\n",
      "[CV] .......... model__learning_rate=0.002, score=0.823, total=  15.5s\n",
      "[CV] model__learning_rate=0.002 ......................................\n",
      "[CV] .......... model__learning_rate=0.002, score=0.844, total=  16.0s\n",
      "[CV] model__learning_rate=0.003 ......................................\n",
      "[CV] .......... model__learning_rate=0.003, score=0.851, total=  17.5s\n",
      "[CV] model__learning_rate=0.003 ......................................\n",
      "[CV] .......... model__learning_rate=0.003, score=0.857, total=  17.1s\n",
      "[CV] model__learning_rate=0.003 ......................................\n",
      "[CV] .......... model__learning_rate=0.003, score=0.838, total=  17.3s\n",
      "[CV] model__learning_rate=0.003 ......................................\n",
      "[CV] .......... model__learning_rate=0.003, score=0.827, total=  16.9s\n",
      "[CV] model__learning_rate=0.003 ......................................\n",
      "[CV] .......... model__learning_rate=0.003, score=0.853, total=  17.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  7.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.846):\n",
      "{'model__learning_rate': 0.01}\n",
      "Time taken:  454.9312767982483\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'model__learning_rate':[0.01,0.002,0.001,0.002,0.003]}\n",
    "\n",
    "start = time.time()\n",
    "grid = get_score(param_grid)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(\"Time taken: \", elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_final = XGBRegressor(base_score=0.5, booster=None, colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=0.8, gamma=1, \n",
    "             importance_type='gain', interaction_constraints=None,\n",
    "             learning_rate=0.002, max_delta_step=0, max_depth=10,\n",
    "             min_child_weight=1, missing=None, monotone_constraints=None,\n",
    "             n_estimators=700, num_parallel_tree=1,\n",
    "             objective='binary:logistic', random_state=0, reg_alpha=0,\n",
    "             reg_lambda=1, scale_pos_weight=1, silent=True, subsample=0.8,\n",
    "             tree_method=None, validate_parameters=False, verbosity=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  4.865492105484009\n"
     ]
    }
   ],
   "source": [
    "# Build final model based on best parameters\n",
    "\n",
    "start = time.time()\n",
    "submission_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', xgb_final)\n",
    "    ])\n",
    "\n",
    "submission_pipeline.fit(X_train, y)\n",
    "elapsed = time.time() - start\n",
    "print(\"Time taken: \", elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb4f0593e50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_important = xgb_final.get_booster().get_score(importance_type='weight')\n",
    "keys = list(feature_important.keys())\n",
    "values = list(feature_important.values())\n",
    "\n",
    "data = pd.DataFrame(data=values, index=keys, columns=[\"score\"]).sort_values(by = \"score\", ascending=False)\n",
    "plt.figure(figsize= (12,10))\n",
    "sns.barplot(x = data.score , y = data.index, orient = 'h', palette = 'Blues_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = submission_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test predictions to file\n",
    "output = pd.DataFrame({'image_name': X_test_load.image_name,\n",
    "                       'target': preds_test})\n",
    "output.to_csv('./cleaned_csvs/csv_only_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
