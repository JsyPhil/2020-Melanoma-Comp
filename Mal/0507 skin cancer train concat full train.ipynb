{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load CSV's\n",
    "df_train = pd.read_csv('/home/malmason/datasets/siim-isic-melanoma-classification/cleaned_csv/train_pp.csv')\n",
    "df_test = pd.read_csv('/home/malmason/datasets/siim-isic-melanoma-classification/cleaned_csv/test_pp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point to image folders\n",
    "img_train_folder = '/home/malmason/datasets/siim-isic-melanoma-classification/ycbcr/norm/train/'\n",
    "img_test_folder = '/home/malmason/datasets/siim-isic-melanoma-classification/ycbcr/norm/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_csv = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_csv = df_train_csv.append(df_train_csv.loc[df_train_csv['target'] == 1])\n",
    "df_train_csv = df_train_csv.append(df_train_csv.loc[df_train_csv['target'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_csv = df_train_csv.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34878, 17)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_csv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for looping through image columns\n",
    "X_train_img = df_train_csv['image_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_csv = df_train_csv.drop(['target', 'image_name'], axis=1).values\n",
    "y_train_csv = df_train_csv['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34878, 15) (34878,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_csv.shape, y_train_csv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8192\n"
     ]
    }
   ],
   "source": [
    "sizing = 224 - 2            # conv1\n",
    "sizing = (sizing - 2) / 2   # conv2  \n",
    "sizing = (sizing - 2)       # conv3\n",
    "sizing = (sizing - 2) / 2   # conv4\n",
    "sizing = (sizing - 2)       # conv5\n",
    "sizing = (sizing - 2) / 2   # conv6\n",
    "sizing = (sizing - 2)       # conv7\n",
    "sizing = (sizing - 2) / 2   # conv8\n",
    "sizing = (sizing - 2) /2    # conv9\n",
    "print(512*(int(sizing)*int(sizing)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4608\n"
     ]
    }
   ],
   "source": [
    "sizing = 224 - 4            # conv1\n",
    "sizing = (sizing - 4) / 2   # conv2  \n",
    "sizing = (sizing - 4) / 2   # conv4\n",
    "sizing = (sizing - 4) / 2   # conv6\n",
    "sizing = (sizing - 4) / 2   # conv8\n",
    "sizing = (sizing - 4) / 2   # conv9\n",
    "print(512*(int(sizing)*int(sizing)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "  def __init__(self, n_output_neurons):\n",
    "    super(CNN, self).__init__()\n",
    "\n",
    "    self.conv1 = nn.Conv2d(3 , 32,   kernel_size=3, stride=1)\n",
    "    self.conv2 = nn.Conv2d(32, 32,   kernel_size=3, stride=1)\n",
    "    self.bn1   = nn.BatchNorm2d(32)\n",
    "    self.conv3 = nn.Conv2d(32 , 64,  kernel_size=3, stride=1)\n",
    "    self.conv4 = nn.Conv2d(64 , 64,  kernel_size=3, stride=1)\n",
    "\n",
    "    self.conv5 = nn.Conv2d(64 , 128, kernel_size=3, stride=1)\n",
    "    self.conv6 = nn.Conv2d(128 ,128, kernel_size=3, stride=1)\n",
    "\n",
    "    self.conv7 = nn.Conv2d(128, 256, kernel_size=3, stride=1)\n",
    "    self.conv8 = nn.Conv2d(256 ,256, kernel_size=3, stride=1)\n",
    "    self.bn4   = nn.BatchNorm2d(256)\n",
    "    self.conv9 = nn.Conv2d(256, 512, kernel_size=3, stride=1)\n",
    "\n",
    "\n",
    "    self.conv11 = nn.Conv2d(3 , 32,   kernel_size=5, stride=1)\n",
    "    self.bn11   = nn.BatchNorm2d(32)\n",
    "    self.conv21 = nn.Conv2d(32 , 64,  kernel_size=5, stride=1)\n",
    "\n",
    "    self.conv31 = nn.Conv2d(64 , 128, kernel_size=5, stride=1)\n",
    "\n",
    "    self.conv41 = nn.Conv2d(128, 256, kernel_size=5, stride=1)\n",
    "\n",
    "    self.conv51 = nn.Conv2d(256, 512, kernel_size=5, stride=1)\n",
    "    self.bn51   = nn.BatchNorm2d(512)\n",
    "    \n",
    "    self.data1 = nn.Linear(15, 128)\n",
    "    self.data2 = nn.Linear(128, 16)\n",
    "    \n",
    "    self.img_fc1   = nn.Linear(8192+4608,128)\n",
    "    self.img_fc2   = nn.Linear(128,32)\n",
    "    self.img_fc3   = nn.Linear(32,16)\n",
    "    \n",
    "    self.fc1_conc  = nn.Linear(16,n_output_neurons)\n",
    "\n",
    "  def forward(self, x, xd):\n",
    "    \n",
    "    xa = F.relu(self.conv1(x),2)\n",
    "    xa = F.relu(F.max_pool2d(self.conv2(xa),2))\n",
    "    xa = self.bn1(xa)\n",
    "    xa = F.relu(self.conv3(xa),2)\n",
    "    xa = F.relu(F.max_pool2d(self.conv4(xa),2))\n",
    "\n",
    "    xa = F.relu(self.conv5(xa),2)\n",
    "    xa = F.relu(F.max_pool2d(self.conv6(xa),2))\n",
    "\n",
    "    xa = F.relu(self.conv7(xa),2)\n",
    "    xa = F.relu(F.max_pool2d(self.conv8(xa),2))\n",
    "    xa = self.bn4(xa)\n",
    "    xa = F.relu(F.max_pool2d(self.conv9(xa),2))\n",
    "\n",
    "\n",
    "    xb = F.relu(F.max_pool2d(self.conv11(x),2))\n",
    "    xb = self.bn11(xb)\n",
    "    xb = F.relu(F.max_pool2d(self.conv21(xb),2))\n",
    "\n",
    "    xb = F.relu(F.max_pool2d(self.conv31(xb),2))\n",
    "\n",
    "    xb = F.relu(F.max_pool2d(self.conv41(xb),2))\n",
    "\n",
    "    xb = F.relu(F.max_pool2d(self.conv51(xb),2))\n",
    "    xb = self.bn51(xb)\n",
    "    \n",
    "    xa = xa.view(xa.size(0), -1)\n",
    "    xb = xb.view(xb.size(0), -1)\n",
    "    \n",
    "    xi = torch.cat((xa, xb), dim=1)\n",
    "    \n",
    "    xi = F.leaky_relu(self.img_fc1(xi))\n",
    "    xi = F.dropout(xi, p=0.3)\n",
    "    \n",
    "    xi = F.leaky_relu(self.img_fc2(xi))\n",
    "    xi = F.dropout(xi, p=0.2)\n",
    "    xi = F.leaky_relu(self.img_fc3(xi))\n",
    "    \n",
    "    xd = F.leaky_relu(self.data1(xd))\n",
    "    xd = F.dropout(xd, p=0.2)\n",
    "    xd = F.leaky_relu(self.data2(xd))\n",
    "    \n",
    "    x = torch.cat((xi, xd), dim=1)\n",
    "    \n",
    "    x = self.fc1_conc(xd)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_output_neurons = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(n_output_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv9): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv11): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn11): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv21): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv31): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv41): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv51): Conv2d(256, 512, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn51): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (data1): Linear(in_features=15, out_features=128, bias=True)\n",
       "  (data2): Linear(in_features=128, out_features=16, bias=True)\n",
       "  (img_fc1): Linear(in_features=12800, out_features=128, bias=True)\n",
       "  (img_fc2): Linear(in_features=128, out_features=32, bias=True)\n",
       "  (img_fc3): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (fc1_conc): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_image = []\n",
    "for image_get in X_train_img:\n",
    "    img_train = cv2.imread(img_train_folder + '{}.jpg'.format(image_get))\n",
    "    '''\n",
    "    rand_num = np.random.uniform(low=1, high=1.2)\n",
    "    M = cv2.resize(img_train, None, fx= rand_num, fy= rand_num, interpolation= cv2.INTER_LINEAR)\n",
    "    \n",
    "    H_crop = ((224*rand_num)-224)/2\n",
    "    V_crop = ((224*rand_num)-224)/2\n",
    "    \n",
    "    C = M[np.int(H_crop):np.int(M.shape[0]-H_crop),np.int(V_crop):np.int(M.shape[1]-np.int(V_crop))]\n",
    "    img_train= cv2.resize(C,(224,224))\n",
    "    '''\n",
    "    X_train_image.append(img_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_image = np.array(X_train_image)\n",
    "X_train_image = X_train_image.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.array(y_train_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_image = X_train_image / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (34878, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f'Train shape: {X_train_image.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_image_t = np.transpose(X_train_image, (0,3,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train = torch.from_numpy(X_train_image_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train = torch.from_numpy(Y_train).reshape(-1,1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_csv = X_train_csv.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train_data = torch.from_numpy(X_train_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 2\n",
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "training_set = torch.utils.data.TensorDataset(input_train, input_train_data, target_train)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=training_set, \n",
    "                                           batch_size=batch_size,\n",
    "                                           num_workers=2,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(output_pred, target):\n",
    "    output_pred_tag = torch.round(torch.sigmoid(output_pred))\n",
    "\n",
    "    correct_results_sum = (output_pred_tag == target).sum().float()\n",
    "    acc = correct_results_sum/target.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gd(model, criterion, optimizer, train_loader, n_epochs):\n",
    "    train_losses = np.zeros(n_epochs)\n",
    "    train_accuracy = np.zeros(n_epochs)\n",
    "    \n",
    "    for it in range(n_epochs):\n",
    "        t0 = datetime.now()\n",
    "        \n",
    "        train_loss = []\n",
    "        train_acc = []\n",
    "        \n",
    "        for inputs, inputs_data, targets in tqdm(train_loader):\n",
    "            inputs, inputs_data, targets = inputs.to(device), inputs_data.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs, inputs_data)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            acc = binary_acc(outputs, targets)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "            train_acc.append(acc.item())\n",
    "            \n",
    "        train_loss = np.mean(train_loss)\n",
    "        train_acc = np.mean(train_acc)\n",
    "        \n",
    "        train_losses[it] = train_loss\n",
    "        train_accuracy[it] = train_acc\n",
    "\n",
    "        dt = datetime.now() -t0\n",
    "\n",
    "        print(f'Epoch {it+1}/{n_epochs}, Time: {dt}, Train Loss: {train_loss:.4f}, Train_acc: {train_acc}')\n",
    "    \n",
    "    return train_losses, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 273/273 [00:41<00:00,  6.50it/s]\n",
      "  0%|          | 0/273 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, Time: 0:00:41.983246, Train Loss: 0.3789, Train_acc: 93.10989010989012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 273/273 [00:42<00:00,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2, Time: 0:00:42.160823, Train Loss: 0.2251, Train_acc: 93.31868131868131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses, train_accuracy  = batch_gd(\n",
    "    model, criterion, optimizer, train_loader, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_csv = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_img = df_test_csv['image_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_csv = df_test_csv.drop(['image_name'], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_image = []\n",
    "for image_get in X_test_img:\n",
    "    img_test = cv2.imread(img_test_folder + '{}.jpg'.format(image_get))\n",
    "\n",
    "    X_test_image.append(img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_image = np.array(X_test_image)\n",
    "X_test_image = X_test_image.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_image = X_test_image / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_image_t = np.transpose(X_test_image, (0,3,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10982"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test_image_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test = torch.from_numpy(X_test_image_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_csv = X_test_csv.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test_data = torch.from_numpy(X_test_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "test_set = torch.utils.data.TensorDataset(input_test, input_test_data)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set, \n",
    "                                           batch_size=batch_size,\n",
    "                                           num_workers=0,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:13<00:00,  6.61it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted_outputs = []\n",
    "for inputs, inputs_data in tqdm(test_loader):\n",
    "    inputs, inputs_data = inputs.to(device), inputs_data.to(device)\n",
    "            \n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs, inputs_data)\n",
    "    outputs_sigmoid = torch.sigmoid(outputs)\n",
    "    outputs_sigmoid_numpy = outputs_sigmoid.detach().cpu().numpy()\n",
    "    predicted_outputs.append(outputs_sigmoid_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_outputs = np.array(predicted_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_outputs_total = []\n",
    "for count in range(len(predicted_outputs)):\n",
    "    for val in predicted_outputs[count]:\n",
    "        predicted_outputs_total.append(val)\n",
    "predicted_outputs_total = np.array(predicted_outputs_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.023782e-06]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_outputs_total[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(train_predictions_np_out, train_targets_np_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(val_predictions_np_out, val_targets_np_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(val_targets_np_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
