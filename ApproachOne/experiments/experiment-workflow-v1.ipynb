{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Workflow Notebook v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sources of information, code and discussions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. This notebook follows the 5 step process presented in the Chris Deotte \"How to compete with GPUs Workshop\" [here][1].\n",
    "2. Triple stratified KFold TFRecords used for image data is explained [here][2].\n",
    "3. Some code sections have been reused from AgentAuers' notebook [here][3]\n",
    "4. The advantage of using different input sizes is discussed [here][4]\n",
    "5. Use external data by changing the variables `INC2019` and `INC2018`.These variables respectively indicate whether to load last year 2019 data and/or year 2018 + 2017 data. These datasets are discussed [here][5]\n",
    "\n",
    "[1]: https://www.kaggle.com/cdeotte/how-to-compete-with-gpus-workshop\n",
    "[2]: https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/165526\n",
    "[3]: https://www.kaggle.com/agentauers/incredible-tpus-finetune-effnetb0-b6-at-once\n",
    "[4]: https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/160147\n",
    "[5]: https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/164910"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Experiments\n",
    "In this notebook we run 6 experiments.\n",
    "* Experiment 1 - baseline - no upsample or dropout but with class balance and 2018 data\n",
    "* Experiment 2 - upsample 2020 and 2018 malignant\n",
    "* Experiment 3 - upsample all\n",
    "* Experiment 4 - add minor dropout\n",
    "* Experiment 5 - add major dropout\n",
    "\n",
    "This note book will repeatedly run experiments on the same KFold fold. Each experiment will be trained for the number of EPOCHS you chose in the configuration above. Each experiment the model with lowest validation loss will be saved and used to predict OOF and test. Adjust the variables `VERBOSE` and `DISPLOY_PLOT` below to determine what output you want displayed. The variable `VERBOSE=1 or 2` will display the training and validation loss and auc for each epoch as text. The variable `DISPLAY_PLOT` shows this information as a plot. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Initiatialise environment and import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Use if running in Kaggle environment\n",
    "#!pip install -q efficientnet >> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import KaggleDatasets if running in Kaggle environment\n",
    "#from kaggle_datasets import KaggleDatasets\n",
    "\n",
    "import os, re, math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import efficientnet.tfkeras as efn\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "* DEVICE - is GPU or TPU\n",
    "* SEED - a different seed produces a different triple stratified kfold split.\n",
    "* FOLDS - number of folds. Best set to 3, 5, or 15 for conistent number of train and validation samples across folds\n",
    "* IMG_SIZES - These are the image sizes to use each fold\n",
    "* INC2019 - This includes the new half of the 2019 competition data. The second half of the 2019 data is the comp data from 2018 plus 2017\n",
    "* INC2018 - This includes the second half of the 2019 competition data which is the comp data from 2018 plus 2017\n",
    "* BATCH_SIZES - These are batch sizes for each fold. For maximum speed, it is best to use the largest batch size your GPU or TPU allows.\n",
    "* EPOCHS - These are maximum epochs. Note that each fold, the best epoch model is saved and used. So if epochs is too large, it won't matter. Consider early stopping in Callbacks.\n",
    "* EFF_NETS - These are the EfficientNets to use each fold. The number refers to the B. So a number of `0` refers to EfficientNetB0, and `1` refers to EfficientNetB1, etc.\n",
    "* WGTS - this should be `1/FOLDS` for each fold. This is the weight when ensembling the folds to predict the test set. If you want a weird ensemble, you can use different weights.\n",
    "* TTA - test time augmentation. Each test image is randomly augmented and predicted TTA times and the average prediction is used. TTA is also applied to OOF during validation.\n",
    "\n",
    "### New Variables\n",
    "* EXPERIMENTS - number of experiments to perform\n",
    "* FNUMBER - which of the KFolds to repeatedly perform experiments on. \n",
    "* M1 - is a list of length EXPERIMENTS. For each experiment, choose 0, 1, 2, 3, etc. Determines how many additional copies of malignant images from this years comp data to add\n",
    "* M2 - is a list. Adds copies of malignant images from ISIC archive that are not in 2020, 2019, 2018, 2017 comp data\n",
    "* M3 - is a list. Adds copies of malignant images from 2019 comp data. They have been filtered to include the ones that look like 2020 data\n",
    "* M4 - is a list. Adds copies of malignant images from 2018 2017 data.\n",
    "* DROP_FREQ - a list of floats between 0 and 1. Determines proportion of train images to apply coarse dropout to\n",
    "* DROP_CT - a list of ints. How many squares to remove from train images when applying dropout. (Note that if you use CT>16 with FREQ=1, it may slow down training when using small image resolutions like 128x128 if your CPU is slow).\n",
    "* DROP_SIZE - a list of floats between 0 and 1. The size of square side equals `IMG_SIZE * DROP_SIZE`\n",
    "* INFER_TEST - whether to predict test images each experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image sizes used in the Efficientnet model:\n",
    "\n",
    "- efficientnet-b0-224 -cv train with 192\n",
    "- efficientnet-b1-240 -cv train with 256\n",
    "- efficientnet-b2-260 -cv train with 256\n",
    "- efficientnet-b3-300 -cv train with 384\n",
    "- efficientnet-b4-380 -cv train with 384\n",
    "- efficientnet-b5-456 -cv train with 512\n",
    "- efficientnet-b6-528 -cv train with 512\n",
    "- efficientnet-b7-600 -cv train with 768\n",
    "\n",
    "Better to train with a larger size and let the model scale down rather than up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "ENV = \"LOCAL\" #or \"KAGGLE\"\n",
    "\n",
    "# DEFAULT TO TPU TO ENSURE KAGGLE TPU COMPATIABILITY\n",
    "# https://www.kaggle.com/docs/tpu\n",
    "DEVICE = \"TPU\" #or \"GPU\"\n",
    "\n",
    "# USE DIFFERENT SEED FOR DIFFERENT STRATIFIED KFOLD\n",
    "SEED = 45\n",
    "\n",
    "# NUMBER OF FOLDS. USE 3, 5, OR 15 \n",
    "FOLDS = 5\n",
    "\n",
    "# WHICH FOLD SET TO PERFORM EXPERIMENTS ON\n",
    "FNUMBER = 5; EXPERIMENTS = 1\n",
    "\n",
    "# # UPSAMPLE MALIGNANT COUNT TIMES\n",
    "# M1 = [0,1,1,1,1] #2020 malig\n",
    "# M2 = [0,0,1,1,1] #ISIC malig\n",
    "# M3 = [0,0,1,1,1] #2019 good malig\n",
    "# M4 = [0,1,1,1,1] #2018 2017 malig\n",
    "\n",
    "# # COARSE DROPOUT\n",
    "# DROP_FREQ = [0,0,0,0.5,0.75] # between 0 and 1\n",
    "# DROP_CT = [0,0,0,4,8] # may slow training if CT>16\n",
    "# DROP_SIZE = [0,0,0,0.1,0.2] # between 0 and 1\n",
    "\n",
    "# UPSAMPLE MALIGNANT COUNT TIMES\n",
    "M1 = [1] #2020 malig\n",
    "M2 = [0] #ISIC malig\n",
    "M3 = [0] #2019 good malig\n",
    "M4 = [1] #2018 2017 malig\n",
    "\n",
    "# COARSE DROPOUT\n",
    "DROP_FREQ = [0] # between 0 and 1\n",
    "DROP_CT = [0] # may slow training if CT>16\n",
    "DROP_SIZE = [0] # between 0 and 1\n",
    "\n",
    "print(\"Check:\", (len(M1)+len(M2)+len(M3)+len(M4)+len(DROP_FREQ)+len(DROP_CT)+len(DROP_SIZE))/7/EXPERIMENTS)\n",
    "\n",
    "# WHICH IMAGE SIZES TO LOAD EACH FOLD\n",
    "# CHOOSE 128, 192, 256, 384, 512, 768 \n",
    "IMG_SIZES = [512]*EXPERIMENTS\n",
    "\n",
    "# META DATA? YES=1 NO=0\n",
    "META = 1\n",
    "\n",
    "# INCLUDE OLD COMP DATA? YES=1 NO=0\n",
    "INC2019 = [0]*EXPERIMENTS\n",
    "INC2018 = [1]*EXPERIMENTS\n",
    "\n",
    "# BATCH SIZE AND EPOCHS\n",
    "# TRY 8, 16, 32, 64, 128, 256. REDUCE IF OOM ERROR, HIGHER FOR TPUS\n",
    "BATCH_SIZES = [2]*EXPERIMENTS\n",
    "EPOCHS = [20]*EXPERIMENTS\n",
    "EARLY_STOPPING = 1 # Yes:1, No:0\n",
    "\n",
    "# WHICH EFFICIENTNET B? TO USE\n",
    "EFF_NETS = [6]*EXPERIMENTS\n",
    "\n",
    "# WEIGHTS FOR FOLD MODELS WHEN PREDICTING TEST\n",
    "WGTS = [1/EXPERIMENTS]*EXPERIMENTS\n",
    "\n",
    "# TEST TIME AUGMENTATION STEPS\n",
    "TTA = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure environment to use TPUs, Multiple GPUs, Single GPU or just CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEVICE == \"TPU\":\n",
    "    print(\"connecting to TPU...\")\n",
    "    try:\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "        print('Running on TPU ', tpu.master())\n",
    "    except ValueError:\n",
    "        print(\"Could not connect to TPU\")\n",
    "        tpu = None\n",
    "\n",
    "    if tpu:\n",
    "        try:\n",
    "            print(\"initializing  TPU ...\")\n",
    "            tf.config.experimental_connect_to_cluster(tpu)\n",
    "            tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "            print(\"TPU initialized\")\n",
    "        except _:\n",
    "            print(\"failed to initialize TPU\")\n",
    "    else:\n",
    "        DEVICE = \"GPU\"\n",
    "\n",
    "if DEVICE != \"TPU\":\n",
    "    print(\"Using default strategy for CPU and GPU\")\n",
    "    \n",
    "\n",
    "if DEVICE == \"GPU\":\n",
    "    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "    if len(tf.config.experimental.list_physical_devices('GPU')) > 1:\n",
    "        strategy = tf.distribute.MirroredStrategy()\n",
    "    else:\n",
    "        strategy = tf.distribute.get_strategy()\n",
    "    \n",
    "\n",
    "AUTO     = tf.data.experimental.AUTOTUNE\n",
    "REPLICAS = strategy.num_replicas_in_sync\n",
    "\n",
    "print(f'REPLICAS: {REPLICAS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Preprocess and file handling\n",
    "Preprocess has already been done and saved to TFRecords. Here we choose which size to load. We can use either 128x128, 192x192, 256x256, 384x384, 512x512, 768x768 by changing the `IMG_SIZES` variable in the preceeding code section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load file locations\n",
    "if ENV == 'KAGGLE':\n",
    "    #Use GCS if running in Kaggle environment\n",
    "    PATH = [None]*EXPERIMENTS; PATH2 = [None]*EXPERIMENTS; PATH3 = [None]*EXPERIMENTS\n",
    "    for i,k in enumerate(IMG_SIZES[:EXPERIMENTS]):\n",
    "        PATH[i] = KaggleDatasets().get_gcs_path('melanoma-%ix%i'%(k,k))\n",
    "        PATH2[i] = KaggleDatasets().get_gcs_path('isic2019-%ix%i'%(k,k))\n",
    "        PATH3[i] = KaggleDatasets().get_gcs_path('malignant-v2-%ix%i'%(k,k))\n",
    "    files_train = np.sort(np.array(tf.io.gfile.glob(PATH[0] + '/train*.tfrec')))\n",
    "    files_test  = np.sort(np.array(tf.io.gfile.glob(PATH[0] + '/test*.tfrec')))\n",
    "       \n",
    "if ENV == 'LOCAL':  \n",
    "    # Use LDS if running in local environment\n",
    "    PATH = [None]*EXPERIMENTS; PATH2 = [None]*EXPERIMENTS; PATH3 = [None]*EXPERIMENTS\n",
    "    for i,k in enumerate(IMG_SIZES[:EXPERIMENTS]):\n",
    "        PATH[i] = f\"./siim-isic-melanoma-classification/tfrecords{k}\"\n",
    "        PATH2[i] = f\"./siim-isic-melanoma-classification/tfrecords{k}Ext\"\n",
    "        PATH3[i] = f\"./siim-isic-melanoma-classification/tfrecords{k}Mal\"\n",
    "    files_train = np.sort(np.array(tf.io.gfile.glob(PATH[0] + '/train*.tfrec')))\n",
    "    files_test  = np.sort(np.array(tf.io.gfile.glob(PATH[0] + '/test*.tfrec')))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save file locations\n",
    "if ENV == 'KAGGLE':\n",
    "    LOG_PATH = ''\n",
    "    CV_OOF_PREDS_PATH = ''\n",
    "    CV_TEST_PREDS_PATH = ''\n",
    "    CV_FOLDS_PATH = ''\n",
    "\n",
    "if ENV == 'LOCAL':\n",
    "    LOG_PATH = './logs/'\n",
    "    CV_OOF_PREDS_PATH = './cv_oof_preds/'\n",
    "    CV_TEST_PREDS_PATH = './cv_test_preds/'\n",
    "    CV_FOLDS_PATH = './cv_folds/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File handling functions\n",
    "def read_labeled_tfrecord(example):\n",
    "    tfrec_format = {\n",
    "        'image'                        : tf.io.FixedLenFeature([], tf.string),\n",
    "        'image_name'                   : tf.io.FixedLenFeature([], tf.string),\n",
    "        'patient_id'                   : tf.io.FixedLenFeature([], tf.int64),\n",
    "        'sex'                          : tf.io.FixedLenFeature([], tf.int64),\n",
    "        'age_approx'                   : tf.io.FixedLenFeature([], tf.int64),\n",
    "        'anatom_site_general_challenge': tf.io.FixedLenFeature([], tf.int64),\n",
    "        #'diagnosis'                    : tf.io.FixedLenFeature([], tf.int64),\n",
    "        'target'                       : tf.io.FixedLenFeature([], tf.int64)\n",
    "    }           \n",
    "    example = tf.io.parse_single_example(example, tfrec_format)\n",
    "    return example['image'], example['target']\n",
    "\n",
    "def read_meta_tfrecord(example):\n",
    "    tfrec_format = {\n",
    "        'image'                        : tf.io.FixedLenFeature([], tf.string),\n",
    "        'image_name'                   : tf.io.FixedLenFeature([], tf.string),\n",
    "        'patient_id'                   : tf.io.FixedLenFeature([], tf.int64),\n",
    "        'sex'                          : tf.io.FixedLenFeature([], tf.int64),\n",
    "        'age_approx'                   : tf.io.FixedLenFeature([], tf.int64),\n",
    "        'anatom_site_general_challenge': tf.io.FixedLenFeature([], tf.int64),\n",
    "        #'diagnosis'                    : tf.io.FixedLenFeature([], tf.int64),\n",
    "        'target'                       : tf.io.FixedLenFeature([], tf.int64)\n",
    "    }           \n",
    "    example = tf.io.parse_single_example(example, tfrec_format)\n",
    "    return example['image_name'], example['sex'], example['age_approx'], example['anatom_site_general_challenge'], example['target']\n",
    "\n",
    "def read_meta_tfrecord_test(example):\n",
    "    tfrec_format = {\n",
    "        'image'                        : tf.io.FixedLenFeature([], tf.string),\n",
    "        'image_name'                   : tf.io.FixedLenFeature([], tf.string),\n",
    "        'patient_id'                   : tf.io.FixedLenFeature([], tf.int64),\n",
    "        'sex'                          : tf.io.FixedLenFeature([], tf.int64),\n",
    "        'age_approx'                   : tf.io.FixedLenFeature([], tf.int64),\n",
    "        'anatom_site_general_challenge': tf.io.FixedLenFeature([], tf.int64),\n",
    "    }           \n",
    "    example = tf.io.parse_single_example(example, tfrec_format)\n",
    "    return example['image_name'], example['sex'], example['age_approx'], example['anatom_site_general_challenge']\n",
    "\n",
    "def read_unlabeled_tfrecord(example, return_image_name):\n",
    "    tfrec_format = {\n",
    "        'image'                        : tf.io.FixedLenFeature([], tf.string),\n",
    "        'image_name'                   : tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, tfrec_format)\n",
    "    return example['image'], example['image_name'] if return_image_name else 0\n",
    "\n",
    "def count_data_items(filenames):\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) \n",
    "         for filename in filenames]\n",
    "    return np.sum(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to stream datasets into model when training, validating and predicting\n",
    "def get_dataset(files, augment = False, shuffle = False, repeat = False, \n",
    "                labeled=True, return_image_names=True, batch_size=16, dim=256,\n",
    "                droprate=0, dropct=0, dropsize=0):\n",
    "    \n",
    "    ds = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO)\n",
    "    ds = ds.cache()\n",
    "    \n",
    "    if repeat:\n",
    "        ds = ds.repeat()\n",
    "    \n",
    "    if shuffle: \n",
    "        ds = ds.shuffle(1024*8)\n",
    "        opt = tf.data.Options()\n",
    "        opt.experimental_deterministic = False\n",
    "        ds = ds.with_options(opt)\n",
    "        \n",
    "    if labeled: \n",
    "        ds = ds.map(read_labeled_tfrecord, num_parallel_calls=AUTO)\n",
    "    else:\n",
    "        ds = ds.map(lambda example: read_unlabeled_tfrecord(example, return_image_names), \n",
    "                    num_parallel_calls=AUTO)      \n",
    "    \n",
    "    ds = ds.map(lambda img, imgname_or_label: (prepare_image(img, augment=augment, dim=dim,\n",
    "                                               droprate=droprate, dropct=dropct, dropsize=dropsize),\n",
    "                                               imgname_or_label), \n",
    "                num_parallel_calls=AUTO)\n",
    "    \n",
    "    ds = ds.batch(batch_size * REPLICAS)\n",
    "    ds = ds.prefetch(AUTO)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to stream datasets into model when training, validating and predicting\n",
    "column_names = ['image_name', 'sex', 'age_approx', 'anatom', 'target']\n",
    "column_names_test = ['image_name', 'sex', 'age_approx', 'anatom']\n",
    "\n",
    "def get_meta(files, batch_size=16, test=0):\n",
    "    ds = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO)\n",
    "    ds = ds.cache()\n",
    "    if test:\n",
    "        ds = ds.map(lambda example: read_meta_tfrecord_test(example), num_parallel_calls=AUTO)\n",
    "    else:\n",
    "        ds = ds.map(lambda example: read_meta_tfrecord(example), num_parallel_calls=AUTO)      \n",
    "    ds = ds.batch(batch_size * REPLICAS)\n",
    "    ds = ds.prefetch(AUTO)\n",
    "        \n",
    "    return ds\n",
    "\n",
    "def meta_unbatch(files, test=0):\n",
    "    if test:\n",
    "        meta_np = np.array([[img_name.numpy().decode(\"utf-8\"),\n",
    "                  sex.numpy(),\n",
    "                  age.numpy(),\n",
    "                  anatomy.numpy()]\n",
    "                for img_name, sex, age, anatomy in iter(files.unbatch())])\n",
    "        meta_df = pd.DataFrame(data = meta_np, columns=column_names_test)\n",
    "\n",
    "    else:        \n",
    "        meta_np = np.array([[img_name.numpy().decode(\"utf-8\"),\n",
    "                  sex.numpy(),\n",
    "                  age.numpy(),\n",
    "                  anatomy.numpy(),\n",
    "                  target.numpy()] \n",
    "                for img_name, sex, age, anatomy, target in iter(files.unbatch())])\n",
    "        \n",
    "        meta_df = pd.DataFrame(data = meta_np, columns=column_names)\n",
    "        meta_df = meta_df.astype({\"target\": int})\n",
    "    return meta_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Data Augmentation\n",
    "This notebook uses rotation, sheer, zoom, shift augmentation. This notebook also uses horizontal flip, saturation, contrast, brightness augmentation similar to last years winner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign variables\n",
    "ROT_ = 180.0\n",
    "SHR_ = 2.0\n",
    "HZOOM_ = 8.0\n",
    "WZOOM_ = 8.0\n",
    "HSHIFT_ = 8.0\n",
    "WSHIFT_ = 8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout(image, DIM=256, PROBABILITY = 0.75, CT = 8, SZ = 0.2):\n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image with CT squares of side size SZ*DIM removed\n",
    "    \n",
    "    # DO DROPOUT WITH PROBABILITY DEFINED ABOVE\n",
    "    P = tf.cast( tf.random.uniform([],0,1)<PROBABILITY, tf.int32)\n",
    "    if (P==0)|(CT==0)|(SZ==0): return image\n",
    "    \n",
    "    for k in range(CT):\n",
    "        # CHOOSE RANDOM LOCATION\n",
    "        x = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n",
    "        y = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n",
    "        # COMPUTE SQUARE \n",
    "        WIDTH = tf.cast( SZ*DIM,tf.int32) * P\n",
    "        ya = tf.math.maximum(0,y-WIDTH//2)\n",
    "        yb = tf.math.minimum(DIM,y+WIDTH//2)\n",
    "        xa = tf.math.maximum(0,x-WIDTH//2)\n",
    "        xb = tf.math.minimum(DIM,x+WIDTH//2)\n",
    "        # DROPOUT IMAGE\n",
    "        one = image[ya:yb,0:xa,:]\n",
    "        two = tf.zeros([yb-ya,xb-xa,3]) \n",
    "        three = image[ya:yb,xb:DIM,:]\n",
    "        middle = tf.concat([one,two,three],axis=1)\n",
    "        image = tf.concat([image[0:ya,:,:],middle,image[yb:DIM,:,:]],axis=0)\n",
    "            \n",
    "    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR \n",
    "    image = tf.reshape(image,[DIM,DIM,3])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n",
    "    # returns 3x3 transformmatrix which transforms indicies\n",
    "        \n",
    "    # CONVERT DEGREES TO RADIANS\n",
    "    rotation = math.pi * rotation / 180.\n",
    "    shear    = math.pi * shear    / 180.\n",
    "\n",
    "    def get_3x3_mat(lst):\n",
    "        return tf.reshape(tf.concat([lst],axis=0), [3,3])\n",
    "    \n",
    "    # ROTATION MATRIX\n",
    "    c1   = tf.math.cos(rotation)\n",
    "    s1   = tf.math.sin(rotation)\n",
    "    one  = tf.constant([1],dtype='float32')\n",
    "    zero = tf.constant([0],dtype='float32')\n",
    "    \n",
    "    rotation_matrix = get_3x3_mat([c1,   s1,   zero, \n",
    "                                   -s1,  c1,   zero, \n",
    "                                   zero, zero, one])    \n",
    "    # SHEAR MATRIX\n",
    "    c2 = tf.math.cos(shear)\n",
    "    s2 = tf.math.sin(shear)    \n",
    "    \n",
    "    shear_matrix = get_3x3_mat([one,  s2,   zero, \n",
    "                                zero, c2,   zero, \n",
    "                                zero, zero, one])        \n",
    "    # ZOOM MATRIX\n",
    "    zoom_matrix = get_3x3_mat([one/height_zoom, zero,           zero, \n",
    "                               zero,            one/width_zoom, zero, \n",
    "                               zero,            zero,           one])    \n",
    "    # SHIFT MATRIX\n",
    "    shift_matrix = get_3x3_mat([one,  zero, height_shift, \n",
    "                                zero, one,  width_shift, \n",
    "                                zero, zero, one])\n",
    "    \n",
    "    return K.dot(K.dot(rotation_matrix, shear_matrix), \n",
    "                 K.dot(zoom_matrix,     shift_matrix))\n",
    "\n",
    "\n",
    "def transform(image, DIM=256):    \n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image randomly rotated, sheared, zoomed, and shifted\n",
    "    XDIM = DIM%2 #fix for size 331\n",
    "    \n",
    "    rot = ROT_ * tf.random.normal([1], dtype='float32')\n",
    "    shr = SHR_ * tf.random.normal([1], dtype='float32') \n",
    "    h_zoom = 1.0 + tf.random.normal([1], dtype='float32') / HZOOM_\n",
    "    w_zoom = 1.0 + tf.random.normal([1], dtype='float32') / WZOOM_\n",
    "    h_shift = HSHIFT_ * tf.random.normal([1], dtype='float32') \n",
    "    w_shift = WSHIFT_ * tf.random.normal([1], dtype='float32') \n",
    "\n",
    "    # GET TRANSFORMATION MATRIX\n",
    "    m = get_mat(rot,shr,h_zoom,w_zoom,h_shift,w_shift) \n",
    "\n",
    "    # LIST DESTINATION PIXEL INDICES\n",
    "    x   = tf.repeat(tf.range(DIM//2, -DIM//2,-1), DIM)\n",
    "    y   = tf.tile(tf.range(-DIM//2, DIM//2), [DIM])\n",
    "    z   = tf.ones([DIM*DIM], dtype='int32')\n",
    "    idx = tf.stack( [x,y,z] )\n",
    "    \n",
    "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
    "    idx2 = K.dot(m, tf.cast(idx, dtype='float32'))\n",
    "    idx2 = K.cast(idx2, dtype='int32')\n",
    "    idx2 = K.clip(idx2, -DIM//2+XDIM+1, DIM//2)\n",
    "    \n",
    "    # FIND ORIGIN PIXEL VALUES           \n",
    "    idx3 = tf.stack([DIM//2-idx2[0,], DIM//2-1+idx2[1,]])\n",
    "    d    = tf.gather_nd(image, tf.transpose(idx3))\n",
    "        \n",
    "    return tf.reshape(d,[DIM, DIM,3])\n",
    "\n",
    "def prepare_image(img, augment=True, dim=256, droprate=0, dropct=0, dropsize=0):    \n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    \n",
    "    if augment:\n",
    "        img = transform(img,DIM=dim)\n",
    "        if (droprate!=0)&(dropct!=0)&(dropsize!=0): \n",
    "            img = dropout(img, DIM=dim, PROBABILITY=droprate, CT=dropct, SZ=dropsize)\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "        #img = tf.image.random_hue(img, 0.01)\n",
    "        img = tf.image.random_saturation(img, 0.7, 1.3)\n",
    "        img = tf.image.random_contrast(img, 0.8, 1.2)\n",
    "        img = tf.image.random_brightness(img, 0.1)\n",
    "                      \n",
    "    img = tf.reshape(img, [dim,dim, 3])\n",
    "            \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Build Model\n",
    "This is a common model architecute. Consider experimenting with different backbones, custom heads, losses, and optimizers. Also consider inputing meta features into your CNN. Also consider different models to provide diversity of predictions which may benefit the final ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EFNS = [efn.EfficientNetB0, efn.EfficientNetB1, efn.EfficientNetB2, efn.EfficientNetB3, \n",
    "        efn.EfficientNetB4, efn.EfficientNetB5, efn.EfficientNetB6, efn.EfficientNetB7]\n",
    "\n",
    "def build_model(dim=128, ef=0, v=0):\n",
    "    inputs = tf.keras.layers.Input(shape=(dim,dim,3))\n",
    "    \n",
    "    base = EFNS[ef](input_shape=(dim,dim,3),weights='noisy-student',include_top=False)\n",
    "    \n",
    "    x = base(inputs)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs,outputs=x)\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=0.05) \n",
    "    \n",
    "    model.compile(optimizer=opt,loss=loss,metrics=['AUC'])\n",
    "    \n",
    "    if v:\n",
    "        model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Visualise model in use\n",
    "build_model(dim=IMG_SIZES[0],ef=EFF_NETS[0],v=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# META DATA FUNCTION\n",
    "\n",
    "# Function to get meta data\n",
    "def meta_model(meta_train, meta_val):\n",
    "    L = 15\n",
    "    feat = ['sex','age_approx','anatom']\n",
    "    M = meta_train.target.mean()\n",
    "    te = meta_train.groupby(feat)['target'].agg(['mean','count']).reset_index()\n",
    "    te['ll'] = ((te['mean']*te['count'])+(M*L))/(te['count']+L)\n",
    "    del te['mean'], te['count']\n",
    "    meta_val = meta_val.merge( te, on=feat, how='left' )\n",
    "    meta_val['ll'] = meta_val['ll'].fillna(M)\n",
    "    return meta_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Training and Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Schedule\n",
    "Thism is a common train schedule for transfer learning. The learning rate starts near zero, then increases to a maximum, then decays over time. Consider changing the schedule and/or learning rates. Note how the learning rate max is larger with larger batches sizes. This is a good practice to follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TS_CFG = dict(\n",
    "    lr_start   = 0.000006, \n",
    "    lr_max     = 0.00000145 * REPLICAS * BATCH_SIZES[0],\n",
    "    lr_min     = 0.000001,\n",
    "    lr_ramp_ep = 5,\n",
    "    lr_sus_ep  = 0,\n",
    "    lr_decay   = 0.85\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_callback(ts_cfg, batch_size=8):\n",
    "    lr_start   = ts_cfg['lr_start']\n",
    "    lr_max     = ts_cfg['lr_max']\n",
    "    lr_min     = ts_cfg['lr_min']\n",
    "    lr_ramp_ep = ts_cfg['lr_ramp_ep']\n",
    "    lr_sus_ep  = ts_cfg['lr_sus_ep']\n",
    "    lr_decay   = ts_cfg['lr_decay']\n",
    "   \n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_ramp_ep:\n",
    "            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "            \n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep:\n",
    "            lr = lr_max\n",
    "            \n",
    "        else:\n",
    "            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "            \n",
    "        return lr\n",
    "\n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n",
    "    \n",
    "    return lr_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise Training Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test and visualisation of learning rate schedule\n",
    "# Important not to have a high learning rate which would destroy the pre-trained parameters\n",
    "lr_start   = TS_CFG['lr_start']\n",
    "lr_max     = TS_CFG['lr_max']\n",
    "lr_min     = TS_CFG['lr_min']\n",
    "lr_ramp_ep = TS_CFG['lr_ramp_ep']\n",
    "lr_sus_ep  = TS_CFG['lr_sus_ep']\n",
    "lr_decay   = TS_CFG['lr_decay']\n",
    "\n",
    "def lrfn_sched(epoch):\n",
    "    if epoch < lr_ramp_ep:\n",
    "        lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "\n",
    "    elif epoch < lr_ramp_ep + lr_sus_ep:\n",
    "        lr = lr_max\n",
    "\n",
    "    else:\n",
    "        lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "\n",
    "    return lr\n",
    "\n",
    "# Visualise learning rate schedule\n",
    "rng = [i for i in range(40)]\n",
    "y = [lrfn_sched(x) for x in rng]\n",
    "plt.plot(rng, y)\n",
    "plt.xlabel('epoch', size=14); plt.ylabel('learning rate', size=14)\n",
    "plt.title('Training Schedule', size=16); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Imbalance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze class imbalance in the targets\n",
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "weight_for_0 = (1 / (33126-470))*(33126)/2.0 \n",
    "weight_for_1 = (1 / 470)*(33126)/2.0\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model\n",
    "Our model will be trained for the number of FOLDS and EPOCHS you chose in the configuration above. Each fold the model with lowest validation loss will be saved and used to predict OOF and test. Adjust the variables `VERBOSE` and `DISPLOY_PLOT` below to determine what output you want displayed. The variable `VERBOSE=1 or 2` will display the training and validation loss and auc for each epoch as text. The variable `DISPLAY_PLOT` shows this information as a plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = KFold(n_splits=FOLDS,shuffle=True,random_state=SEED)\n",
    "for fold,(idxT,idxV) in enumerate(skf.split(np.arange(15))):\n",
    "    if fold==(FNUMBER-1):\n",
    "        idxTT = idxT; idxVV = idxV\n",
    "        print('### Using fold',fold,'for experiments')\n",
    "    print('Fold',fold,'has TRAIN:',idxT,'VALID:',idxV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# USE VERBOSE=0 for silent, VERBOSE=1 for interactive, VERBOSE=2 for commit\n",
    "VERBOSE = 1\n",
    "DISPLAY_PLOT = True\n",
    "\n",
    "oof_pred = []\n",
    "oof_tar = []\n",
    "oof_val = []\n",
    "oof_names = []\n",
    "oof_folds = [] \n",
    "preds = np.zeros((count_data_items(files_test),1))\n",
    "preds_meta_ls = np.zeros((count_data_items(files_test),1))\n",
    "\n",
    "best_val_auc_ls = []\n",
    "best_epoch_val_auc_ls = []\n",
    "\n",
    "best_val_loss_ls = []\n",
    "best_epoch_val_loss_ls = []\n",
    "\n",
    "best_meta_wgts = []\n",
    "\n",
    "#TESTING ONLY\n",
    "loops = 0\n",
    "max_loops = EXPERIMENTS #Use EXPERIMENTS or a number less than FOLDS if testing\n",
    "\n",
    "for fold in range(EXPERIMENTS):\n",
    "    # REPEAT SAME FOLD OVER AND OVER\n",
    "    idxT = idxTT\n",
    "    idxV = idxVV\n",
    "    \n",
    "    # DISPLAY FOLD INFO\n",
    "    if DEVICE=='TPU':\n",
    "        if tpu: tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    print('#'*25)\n",
    "    print('#### EXPERIMENT',fold+1)\n",
    "    print('#'*25)\n",
    "    print('#### Using the following TFRecords:')\n",
    "    print(idxT,idxV)\n",
    "    print(f'#### Image Size {IMG_SIZES[fold]} with EfficientNet B{EFF_NETS[fold]} and batch_size {BATCH_SIZES[fold]*REPLICAS}')\n",
    "    print(f'#### DropoutFreq {DROP_FREQ[fold]} Count{DROP_CT[fold]} Size {DROP_SIZE[fold]}')\n",
    "    \n",
    "    # CREATE TRAIN AND VALIDATION SUBSETS\n",
    "    files_train = tf.io.gfile.glob([PATH[fold] + '/train%.2i*.tfrec'%x for x in idxT])\n",
    "    if INC2019[fold]:\n",
    "        files_train += tf.io.gfile.glob([PATH2[fold] + '/train%.2i*.tfrec'%x for x in idxT*2+1])\n",
    "        print('#### Using 2019 external data')\n",
    "    if INC2018[fold]:\n",
    "        files_train += tf.io.gfile.glob([PATH2[fold] + '/train%.2i*.tfrec'%x for x in idxT*2])\n",
    "        print('#### Using 2018+2017 external data')\n",
    "    for k in range(M1[fold]):\n",
    "        files_train += tf.io.gfile.glob([PATH3[fold] + '/train%.2i*.tfrec'%x for x in idxT])\n",
    "        print('#### Upsample MALIG-1 data (2020 comp)')\n",
    "    for k in range(M2[fold]):\n",
    "        files_train += tf.io.gfile.glob([PATH3[fold] + '/train%.2i*.tfrec'%x for x in idxT+15])\n",
    "        print('#### Upsample MALIG-2 data (ISIC website)')\n",
    "    for k in range(M3[fold]):\n",
    "        files_train += tf.io.gfile.glob([PATH3[fold] + '/train%.2i*.tfrec'%x for x in idxT*2+1+30])\n",
    "        print('#### Upsample MALIG-3 data (2019 comp)')\n",
    "    for k in range(M4[fold]):\n",
    "        files_train += tf.io.gfile.glob([PATH3[fold] + '/train%.2i*.tfrec'%x for x in idxT*2+30])\n",
    "        print('#### Upsample MALIG-4 data (2018 2017 comp)')\n",
    "    np.random.shuffle(files_train); print('#'*25)\n",
    "    files_valid = tf.io.gfile.glob([PATH[fold] + '/train%.2i*.tfrec'%x for x in idxV])\n",
    "    files_test = np.sort(np.array(tf.io.gfile.glob(PATH[fold] + '/test*.tfrec')))\n",
    "    \n",
    "    # DETERMINE CLASS WEIGHTS FROM TRAINING DATASET\n",
    "    # Analyze class imbalance in the targets\n",
    "    # Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "    # The sum of the weights of all examples stays the same.\n",
    "    ft = get_dataset(files_train, augment=False, repeat=False, dim=IMG_SIZES[fold],\n",
    "            labeled=True, return_image_names=True)\n",
    "    ott = np.array([target.numpy() for img, target in iter(ft.unbatch())])\n",
    "    tot = len(ott)\n",
    "    counts = np.bincount(ott[:])\n",
    "    \n",
    "    weight_for_0 = (1 / counts[0])*(tot)/2.0 \n",
    "    weight_for_1 = (1 / counts[1])*(tot)/2.0\n",
    "    class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "    print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "    print('Weight for class 1: {:.2f}'.format(weight_for_1))\n",
    "    \n",
    "    # BUILD MODEL\n",
    "    K.clear_session()\n",
    "    with strategy.scope():\n",
    "        model = build_model(dim=IMG_SIZES[fold],ef=EFF_NETS[fold],v=0)\n",
    "        \n",
    "    # CALLBACKS - SAVE BEST MODEL EACH FOLD ALSO UTILISE EARLY STOPPING TO ALLOW MORE EPOCHS\n",
    "    svl = tf.keras.callbacks.ModelCheckpoint(\n",
    "        f'{CV_FOLDS_PATH}EB{EFF_NETS[0]}-{IMG_SIZES[0]}-fold-{fold}-EXP-loss.h5', monitor='val_loss', verbose=1, save_best_only=True,\n",
    "        save_weights_only=True, mode='min', save_freq='epoch')\n",
    "    sva = tf.keras.callbacks.ModelCheckpoint(\n",
    "        f'{CV_FOLDS_PATH}EB{EFF_NETS[0]}-{IMG_SIZES[0]}-fold-{fold}-EXP-auc.h5', monitor='val_auc', verbose=1, save_best_only=True,\n",
    "        save_weights_only=True, mode='max', save_freq='epoch')\n",
    "    \n",
    "    if EARLY_STOPPING:\n",
    "        es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, verbose=VERBOSE, mode='auto')\n",
    "        callback_list = [svl, sva, es, get_lr_callback(TS_CFG, BATCH_SIZES[fold])]\n",
    "    else:\n",
    "        callback_list = [svl, sva, get_lr_callback(TS_CFG, BATCH_SIZES[fold])]\n",
    "   \n",
    "    # TRAIN\n",
    "    print('Training and Validation, No Dropout on Validation...')\n",
    "    history = model.fit(\n",
    "        get_dataset(files_train, augment=True, shuffle=True, repeat=True,\n",
    "                    dim=IMG_SIZES[fold], batch_size = BATCH_SIZES[fold],\n",
    "                    droprate=DROP_FREQ[fold], dropct=DROP_CT[fold], dropsize=DROP_SIZE[fold]), \n",
    "        epochs=EPOCHS[fold],\n",
    "        callbacks = callback_list, \n",
    "        steps_per_epoch=count_data_items(files_train)/BATCH_SIZES[fold]//REPLICAS,\n",
    "        validation_data=get_dataset(files_valid,augment=True,shuffle=False,\n",
    "                                    repeat=False,dim=IMG_SIZES[fold],\n",
    "                                    droprate=DROP_FREQ[fold], dropct=DROP_CT[fold], dropsize=DROP_SIZE[fold]),\n",
    "        class_weight = class_weight,\n",
    "        verbose=VERBOSE\n",
    "    )\n",
    "    \n",
    "    # DETERMINE BEST SCORES AND EPOCHS\n",
    "    val_auc_ls = history.history['val_auc']\n",
    "    val_loss_ls = history.history['val_loss']\n",
    "    \n",
    "    best_val_auc = max(val_auc_ls)\n",
    "    best_val_loss = min(val_loss_ls)\n",
    "    best_val_auc_ls.append(best_val_auc)\n",
    "    best_val_loss_ls.append(best_val_loss)\n",
    "    \n",
    "    opt_epoch_auc = val_auc_ls.index(best_val_auc)\n",
    "    opt_epoch_loss = val_loss_ls.index(best_val_loss)\n",
    "    best_epoch_val_auc_ls.append(opt_epoch_auc)\n",
    "    best_epoch_val_loss_ls.append(opt_epoch_loss)\n",
    "    \n",
    "    #RELOAD BEST WEIGHTS AT BEST EPOCH\n",
    "    print('Loading best model...')\n",
    "    model.load_weights(f'{CV_FOLDS_PATH}EB{EFF_NETS[0]}-{IMG_SIZES[0]}-fold-{fold}-EXP-auc.h5')\n",
    "    \n",
    "    # PREDICT OOF USING TTA\n",
    "    print('Predicting OOF with TTA No Dropout...')\n",
    "    ds_valid = get_dataset(files_valid,labeled=False,return_image_names=False,augment=True,\n",
    "                          repeat=True,shuffle=False,dim=IMG_SIZES[fold],batch_size=BATCH_SIZES[fold]*2,\n",
    "                          droprate=DROP_FREQ[fold], dropct=DROP_CT[fold], dropsize=DROP_SIZE[fold])\n",
    "    \n",
    "    ct_valid = count_data_items(files_valid); STEPS = TTA * ct_valid/BATCH_SIZES[fold]/2/REPLICAS\n",
    "    pred = model.predict(ds_valid,steps=STEPS,verbose=VERBOSE)[:TTA*ct_valid,] \n",
    "    oof_pred.append( np.mean(pred.reshape((ct_valid,TTA),order='F'),axis=1) )                 \n",
    "    \n",
    "    # GET OOF TARGETS AND NAMES\n",
    "    ds_valid = get_dataset(files_valid, augment=False, repeat=False, dim=IMG_SIZES[fold],\n",
    "            labeled=True, return_image_names=True)\n",
    "    oof_tar.append( np.array([target.numpy() for img, target in iter(ds_valid.unbatch())]) )\n",
    "    oof_folds.append( np.ones_like(oof_tar[-1],dtype='int8')*fold )\n",
    "    ds = get_dataset(files_valid, augment=False, repeat=False, dim=IMG_SIZES[fold],\n",
    "                labeled=False, return_image_names=True)\n",
    "    oof_names.append( np.array([img_name.numpy().decode(\"utf-8\") for img, img_name in iter(ds.unbatch())]))\n",
    "\n",
    "    # INCLUDING ENSEMBLE OF META DATA\n",
    "    meta_wgt_auc = []\n",
    "\n",
    "    dsp_ft = get_meta(files_train)\n",
    "    dsp_fv = get_meta(files_valid)\n",
    "    meta_train = meta_unbatch(dsp_ft)\n",
    "    meta_val = meta_unbatch(dsp_fv)\n",
    "    meta_pred = meta_model(meta_train, meta_val)\n",
    "    meta_pred['oof'] = oof_pred[-1]\n",
    "    meta_auc = roc_auc_score(meta_pred['target'],meta_pred['ll'])    \n",
    "\n",
    "    for wgt in range(0, 31, 1):\n",
    "        wgt = wgt/100\n",
    "        meta_pred['ens'] = ((1-wgt)*meta_pred.oof + wgt*meta_pred.ll)\n",
    "        meta_auc = roc_auc_score(meta_pred['target'],meta_pred['ll'])\n",
    "        meta_ens_auc = roc_auc_score(meta_pred['target'],meta_pred['ens'])    \n",
    "        meta_wgt_auc.append([wgt, meta_ens_auc])\n",
    "        #print(f\"With Meta Weight {wgt}, Meta and OOF AUC with TTA:\", meta_ens_auc)\n",
    "    best_meta_wgts.append(max(meta_wgt_auc, key=lambda item: item[1]))    \n",
    "    \n",
    "    # PREDICT TEST USING TTA\n",
    "    print('Predicting Test with TTA, No Dropout...')\n",
    "    ds_test = get_dataset(files_test,labeled=False,return_image_names=False,augment=True,\n",
    "                         repeat=True,shuffle=False,dim=IMG_SIZES[fold],batch_size=BATCH_SIZES[fold]*4,\n",
    "                         droprate=DROP_FREQ[fold], dropct=DROP_CT[fold], dropsize=DROP_SIZE[fold])\n",
    "    \n",
    "    ct_test = count_data_items(files_test); STEPS = TTA * ct_test/BATCH_SIZES[fold]/4/REPLICAS\n",
    "    pred = model.predict(ds_test,steps=STEPS,verbose=VERBOSE)[:TTA*ct_test,]\n",
    "    pred = np.mean(pred.reshape((ct_test,TTA),order='F'),axis=1)\n",
    "    preds[:,0] += pred * WGTS[fold]\n",
    "    \n",
    "    dsp_test = get_meta(files_test, BATCH_SIZES[0], test=1)\n",
    "    meta_test = meta_unbatch(dsp_test, test=1)\n",
    "    meta_test = meta_model(meta_train, meta_test)\n",
    "    meta_test['preds'] = pred\n",
    "    meta_test['preds_meta'] = best_meta_wgts[-1][0]*meta_test.ll + (1-best_meta_wgts[-1][0])*meta_test.preds\n",
    "    preds_meta = np.array([meta_test.preds_meta]).T\n",
    "    preds_meta_ls += preds_meta * WGTS[fold]\n",
    "\n",
    "    # REPORT RESULTS\n",
    "    auc = roc_auc_score(oof_tar[-1],oof_pred[-1])\n",
    "    oof_val.append(np.max( history.history['val_auc'] ))\n",
    "    print(f'#### FOLD {fold+1} OOF AUC without TTA = {oof_val[-1]:.3f}, with TTA = {auc:.3f}')\n",
    "    print(\"Meta only AUC:\", meta_auc) \n",
    "    print(f\"The best weight is {best_meta_wgts[-1][0]}, Meta and OOF AUC with TTA: {best_meta_wgts[-1][1]:.3f}\")\n",
    "    \n",
    "    COMPLETED_EPOCHS = len(history.history['loss'])\n",
    "    \n",
    "    # PLOT TRAINING\n",
    "    if DISPLAY_PLOT:\n",
    "        plt.figure(figsize=(15,5))\n",
    "        plt.plot(np.arange(EPOCHS[fold]),history.history['auc'],'-o',label='Train AUC',color='#ff7f0e')\n",
    "        plt.plot(np.arange(EPOCHS[fold]),history.history['val_auc'],'-o',label='Val AUC',color='#1f77b4')\n",
    "        x = np.argmax( history.history['val_auc'] )\n",
    "        y = np.max( history.history['val_auc'] )\n",
    "        xdist = plt.xlim()[1] - plt.xlim()[0]\n",
    "        ydist = plt.ylim()[1] - plt.ylim()[0]\n",
    "        plt.scatter(x,y,s=200,color='#1f77b4')\n",
    "        plt.text(x-0.03*xdist,y-0.13*ydist,'max auc\\n%.2f'%y,size=14)\n",
    "        plt.ylabel('AUC',size=14); plt.xlabel('Epoch',size=14)\n",
    "        plt.legend(loc=2)\n",
    "        plt2 = plt.gca().twinx()\n",
    "        plt2.plot(np.arange(EPOCHS[fold]),history.history['loss'],'-o',label='Train Loss',color='#2ca02c')\n",
    "        plt2.plot(np.arange(EPOCHS[fold]),history.history['val_loss'],'-o',label='Val Loss',color='#d62728')\n",
    "        x = np.argmin( history.history['val_loss'] )\n",
    "        y = np.min( history.history['val_loss'] )\n",
    "        ydist = plt.ylim()[1] - plt.ylim()[0]\n",
    "        plt.scatter(x,y,s=200,color='#d62728')\n",
    "        plt.text(x-0.03*xdist,y+0.05*ydist,'min loss',size=14)\n",
    "        plt.ylabel('Loss',size=14)\n",
    "        plt.title('EXPERIMENT %i - Image Size %i, EfficientNet B%i, inc2019=%i, inc2018=%i, M1=%i, M2=%i, M3=%i, M4=%i\\n\\\n",
    "        batch_size %i, dropout_freq=%.2f count=%i size=%.3f'%\n",
    "                (fold+1,IMG_SIZES[fold],EFF_NETS[fold],INC2019[fold],INC2018[fold],M1[fold],M2[fold],M3[fold],\n",
    "                 M4[fold],BATCH_SIZES[fold]*REPLICAS,DROP_FREQ[fold],DROP_CT[fold],DROP_SIZE[fold]),size=18)\n",
    "        plt.legend(loc=3)\n",
    "        plt.show()  \n",
    "        \n",
    "        # TESTING ONLY\n",
    "        loops+=1\n",
    "        if loops == max_loops:\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        del model; z = gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the optimal characteristics from CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch_val_auc_mean = np.mean(np.array(best_epoch_val_auc_ls), axis=0)\n",
    "best_epoch_val_loss_mean = np.mean(np.array(best_epoch_val_loss_ls), axis=0)\n",
    "\n",
    "print(\"The best epoch value for AUC over the cv is: \",best_epoch_val_auc_mean)\n",
    "print(\"The best epoch value for loss over the cv is: \",best_epoch_val_loss_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_val_auc_mean = np.mean(np.array(best_val_auc_ls), axis=0)\n",
    "cv_val_auc_std = np.std(np.array(best_val_auc_ls), axis=0)\n",
    "cv_val_loss_mean = np.mean(np.array(best_val_loss_ls), axis=0)\n",
    "\n",
    "print(f\"The mean AUC score across CV folds is {cv_val_auc_mean:.2f} and the standard deviation is {cv_val_auc_std:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate OOF AUC\n",
    "The OOF (out of fold) predictions are saved to disk. If you wish to ensemble multiple models, use the OOF to determine what are the best weights to blend your models with. Choose weights that maximize OOF CV score when used to blend OOF. Then use those same weights to blend your test predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPUTE OVERALL OOF AUC\n",
    "oof = np.concatenate(oof_pred)\n",
    "true = np.concatenate(oof_tar);\n",
    "names = np.concatenate(oof_names)\n",
    "folds = np.concatenate(oof_folds)\n",
    "auc = roc_auc_score(true,oof)\n",
    "print('Overall OOF AUC with TTA = %.3f'%auc)\n",
    "\n",
    "# SAVE OOF TO DISK\n",
    "df_oof = pd.DataFrame(dict(\n",
    "    image_name = names, target=true, pred = oof, fold=folds))\n",
    "df_oof.to_csv(f'{CV_OOF_PREDS_PATH}EB{EFF_NETS[0]}-{IMG_SIZES[0]}-oof-EXP.csv',index=False)\n",
    "df_oof.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate OOF AUC with Tabular Data\n",
    "Utilising a simple prediction model on the tabular data should add additional information when blending. This can be tested with the OOF data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_wgt = []\n",
    "best_auc = []\n",
    "for best in best_meta_wgts:\n",
    "    best_wgt.append(best[0])\n",
    "    best_auc.append(best[1])\n",
    "avg_wgt = sum(best_wgt)/len(best_wgt)\n",
    "avg_auc = sum(best_auc)/len(best_auc)\n",
    "print(f\"Average of best meta weights = {avg_wgt:.2f}\")\n",
    "print(f\"Overall OOF and Meta AUC with TTA = {avg_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Post process\n",
    "There are ways to modify predictions based on patient information to increase CV LB. You can experiment with that here on your OOF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log values from the cross validation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENV == 'LOCAL':\n",
    "    log_df = pd.read_csv('./logs/experiment_log.csv')\n",
    "    headers = list(log_df.columns.values)\n",
    "    \n",
    "if ENV == 'KAGGLE':\n",
    "    headers = ['Image Size',\n",
    "             'Model',\n",
    "             '2018 Data',\n",
    "             'Batch Size',\n",
    "             'Replicas',\n",
    "             'Total Batch Size',\n",
    "             'TTA Loops',\n",
    "             'CV Folds',\n",
    "             'Mean CV AUC',\n",
    "             'Std CV AUC',\n",
    "             'OOF AUC with TTA',\n",
    "             'OOF AUC and Meta with TTA'\n",
    "             'Best average Meta weighting'  \n",
    "             'Mean CV Loss',\n",
    "             'Total Epochs',\n",
    "             'Early Stop',\n",
    "             'Best AUC Epoch',\n",
    "             'Best Loss Epoch',\n",
    "             'Kaggle LB AUC',\n",
    "             'Kaggle LB AUC w Meta']\n",
    "    log_df = pd.DataFrame(columns = headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_items = [IMG_SIZES[0],\n",
    "            str(f\"EFNB{EFF_NETS[0]}EXP\"),\n",
    "            INC2018[0],\n",
    "            BATCH_SIZES[0],\n",
    "            REPLICAS,\n",
    "            BATCH_SIZES[0] * REPLICAS,\n",
    "            TTA,\n",
    "            FOLDS,\n",
    "            cv_val_auc_mean,\n",
    "            cv_val_auc_std, \n",
    "            auc,\n",
    "            avg_auc,\n",
    "            avg_wgt,\n",
    "            cv_val_loss_mean,\n",
    "            EPOCHS[0],\n",
    "            EARLY_STOPPING,\n",
    "            best_epoch_val_auc_mean,\n",
    "            best_epoch_val_loss_mean,\n",
    "            0.00,\n",
    "            0.00]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(len(headers)):\n",
    "    print(headers[n]+\":\", log_items[n])\n",
    "    \n",
    "log_data = pd.DataFrame([log_items], columns=headers)\n",
    "log_df = log_df.append(log_data)\n",
    "log_df.sort_values(by=['Model','Image Size'], inplace=True)\n",
    "log_df.to_csv(f'{LOG_PATH}experiment_log.csv', index=False)\n",
    "log_df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Kaggle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = get_dataset(files_test, augment=False, repeat=False, dim=IMG_SIZES[fold],\n",
    "                 labeled=False, return_image_names=True)\n",
    "\n",
    "image_names = np.array([img_name.numpy().decode(\"utf-8\") \n",
    "                        for img, img_name in iter(ds.unbatch())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(dict(image_name=image_names, target=preds[:,0]))\n",
    "submission = submission.sort_values('image_name') \n",
    "submission.to_csv(f'{CV_TEST_PREDS_PATH}EB{EFF_NETS[0]}-{IMG_SIZES[0]}-{FOLDS}F-EXP-submission.csv', index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_meta = pd.DataFrame(dict(image_name=image_names, target=preds_meta_ls[:,0]))\n",
    "submission_meta = submission_meta.sort_values('image_name') \n",
    "submission_meta.to_csv(f'{CV_TEST_PREDS_PATH}EB{EFF_NETS[0]}-{IMG_SIZES[0]}-{FOLDS}F-EXP-META-submission.csv', index=False)\n",
    "submission_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(submission.target,bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(submission_meta.target,bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
