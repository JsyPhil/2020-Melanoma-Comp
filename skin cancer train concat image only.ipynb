{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pylab as pltlab\n",
    "import pydicom\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load CSV's\n",
    "csv_train_file = pd.read_csv('/home/malmason/datasets/siim-isic-melanoma-classification/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_train_file = csv_train_file.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point to image folders\n",
    "img_train_folder = '/home/malmason/datasets/siim-isic-melanoma-classification/ycbcr/norm/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for looping through image columns\n",
    "X_train_img = csv_train_file['image_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general_challenge</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>benign_malignant</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_4086048</td>\n",
       "      <td>IP_8313778</td>\n",
       "      <td>male</td>\n",
       "      <td>45.0</td>\n",
       "      <td>torso</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_9457506</td>\n",
       "      <td>IP_6808872</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name  patient_id   sex  age_approx anatom_site_general_challenge  \\\n",
       "0  ISIC_4086048  IP_8313778  male        45.0                         torso   \n",
       "1  ISIC_9457506  IP_6808872  male        30.0                     head/neck   \n",
       "\n",
       "  diagnosis benign_malignant  target  \n",
       "0   unknown           benign       0  \n",
       "1   unknown           benign       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_train_file.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 33126, \tUnique patients: 2056\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train set size: {len(csv_train_file)}, \\tUnique patients: {len(csv_train_file['patient_id'].value_counts())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values\n",
    "csv_train_file[\"anatom_site_general_challenge\"].fillna(\"Unknown\", inplace = True)\n",
    "csv_train_file[\"sex\"].fillna(\"Unknown\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total train set: 33126\tNormal: 32542\tMelanoma: 584\tPercent: 1.79%\n",
      "\n",
      "Train set breakdown\n",
      "-------------------\n",
      "Head neck melanoma\tTotal: 1855\tNormal: 1781\tMelanoma: 74\tPercent: 4.15%\n",
      "lower_extremity   \tTotal: 8417\tNormal: 8293\tMelanoma: 124\tPercent: 1.5%\n",
      "oral_genital      \tTotal: 124\tNormal: 120\tMelanoma: 4\tPercent: 3.33%\n",
      "palms_soles       \tTotal: 375\tNormal: 370\tMelanoma: 5\tPercent: 1.35%\n",
      "torso             \tTotal: 16845\tNormal: 16588\tMelanoma: 257\tPercent: 1.55%\n",
      "upper_extremity   \tTotal: 4983\tNormal: 4872\tMelanoma: 111\tPercent: 2.28%\n",
      "Unknown           \tTotal: 527\tNormal: 518\tMelanoma: 9\tPercent: 1.74%\n",
      "\n",
      "Null values for location: 0\n"
     ]
    }
   ],
   "source": [
    "head_neck = csv_train_file.loc[csv_train_file['anatom_site_general_challenge'] == 'head/neck']\n",
    "upper_extremity = csv_train_file.loc[csv_train_file['anatom_site_general_challenge'] == 'upper extremity']\n",
    "lower_extremity = csv_train_file.loc[csv_train_file['anatom_site_general_challenge'] == 'lower extremity']\n",
    "oral_genital = csv_train_file.loc[csv_train_file['anatom_site_general_challenge'] == 'oral/genital']\n",
    "palms_soles = csv_train_file.loc[csv_train_file['anatom_site_general_challenge'] == 'palms/soles']\n",
    "torso = csv_train_file.loc[csv_train_file['anatom_site_general_challenge'] == 'torso']\n",
    "none = csv_train_file.loc[csv_train_file['anatom_site_general_challenge'] == 'Unknown']\n",
    "\n",
    "zero, one = csv_train_file['target'].value_counts()\n",
    "print(f'\\nTotal train set: {zero+one}\\tNormal: {zero}\\tMelanoma: {one}\\tPercent: {np.round(one / zero,4)*100}%')\n",
    "\n",
    "print(\"\\nTrain set breakdown\\n-------------------\")\n",
    "zero , one = head_neck.groupby('target').target.count()\n",
    "print(f\"Head neck melanoma\\tTotal: {zero+one}\\tNormal: {zero}\\tMelanoma: {one}\\tPercent: {np.round(100*(one / zero),2)}%\")\n",
    "zero , one = lower_extremity.groupby('target').target.count()\n",
    "print(f\"lower_extremity   \\tTotal: {zero+one}\\tNormal: {zero}\\tMelanoma: {one}\\tPercent: {np.round(100*(one / zero),2)}%\")\n",
    "zero , one = oral_genital.groupby('target').target.count()\n",
    "print(f\"oral_genital      \\tTotal: {zero+one}\\tNormal: {zero}\\tMelanoma: {one}\\tPercent: {np.round(100*(one / zero),2)}%\")\n",
    "zero , one = palms_soles.groupby('target').target.count()\n",
    "print(f\"palms_soles       \\tTotal: {zero+one}\\tNormal: {zero}\\tMelanoma: {one}\\tPercent: {np.round(100*(one / zero),2)}%\")\n",
    "zero , one = torso.groupby('target').target.count()\n",
    "print(f\"torso             \\tTotal: {zero+one}\\tNormal: {zero}\\tMelanoma: {one}\\tPercent: {np.round(100*(one / zero),2)}%\")\n",
    "zero , one = upper_extremity.groupby('target').target.count()\n",
    "print(f\"upper_extremity   \\tTotal: {zero+one}\\tNormal: {zero}\\tMelanoma: {one}\\tPercent: {np.round(100*(one / zero),2)}%\")\n",
    "zero , one =  none.groupby('target').target.count()\n",
    "print(f\"Unknown           \\tTotal: {zero+one}\\tNormal: {zero}\\tMelanoma: {one}\\tPercent: {np.round(100*(one / zero),2)}%\")\n",
    "print(f\"\\nNull values for location: {csv_train_file['anatom_site_general_challenge'].isnull().sum()}\")\n",
    "\n",
    "# User to order 0 to 1 for anatom_site_general_challenge categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 is missing either 0 or 1\n",
      "10.0 is missing either 0 or 1\n",
      "Age approx:  15.0\tNormal: 130\tMelanoma: 2\tPercent: 1.54%\n",
      "Age approx:  20.0\tNormal: 649\tMelanoma: 6\tPercent: 0.92%\n",
      "Age approx:  25.0\tNormal: 1528\tMelanoma: 16\tPercent: 1.05%\n",
      "Age approx:  30.0\tNormal: 2334\tMelanoma: 24\tPercent: 1.03%\n",
      "Age approx:  35.0\tNormal: 2825\tMelanoma: 25\tPercent: 0.88%\n",
      "Age approx:  40.0\tNormal: 3552\tMelanoma: 24\tPercent: 0.68%\n",
      "Age approx:  45.0\tNormal: 4412\tMelanoma: 54\tPercent: 1.22%\n",
      "Age approx:  50.0\tNormal: 4217\tMelanoma: 53\tPercent: 1.26%\n",
      "Age approx:  55.0\tNormal: 3760\tMelanoma: 64\tPercent: 1.7%\n",
      "Age approx:  60.0\tNormal: 3175\tMelanoma: 65\tPercent: 2.05%\n",
      "Age approx:  65.0\tNormal: 2457\tMelanoma: 70\tPercent: 2.85%\n",
      "Age approx:  70.0\tNormal: 1910\tMelanoma: 58\tPercent: 3.04%\n",
      "Age approx:  75.0\tNormal: 919\tMelanoma: 62\tPercent: 6.75%\n",
      "Age approx:  80.0\tNormal: 383\tMelanoma: 36\tPercent: 9.4%\n",
      "Age approx:  85.0\tNormal: 140\tMelanoma: 9\tPercent: 6.43%\n",
      "Age approx:  90.0\tNormal: 64\tMelanoma: 16\tPercent: 25.0%\n"
     ]
    }
   ],
   "source": [
    "age_range = csv_train_file['age_approx'].dropna().unique()\n",
    "age_range.sort()\n",
    "for some_var in age_range:\n",
    "    age = csv_train_file.loc[csv_train_file['age_approx'] == some_var]\n",
    "    try:\n",
    "        zero , one =  age.groupby('target').target.count()\n",
    "        print(f\"Age approx:  {some_var}\\tNormal: {zero}\\tMelanoma: {one}\\tPercent: {np.round(100*(one / zero),2)}%\")\n",
    "    except:\n",
    "        print(f'{some_var} is missing either 0 or 1')\n",
    "# Ages classified 0 to 1 in order of age, as older more likely to gain skin cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male     \tTotal: 17080\tNormal: 16716\tMelanoma: 364\tPercent: 2.18%\n",
      "female   \tTotal: 15981\tNormal: 15761\tMelanoma: 220\tPercent: 1.4%\n",
      "missing either 0 or 1\n"
     ]
    }
   ],
   "source": [
    "male = csv_train_file.loc[csv_train_file['sex'] == 'male']\n",
    "female = csv_train_file.loc[csv_train_file['sex'] == 'female']\n",
    "unknown = csv_train_file.loc[csv_train_file['sex'] == 'Unknown']\n",
    "zero , one = male.groupby('target').target.count()\n",
    "print(f\"male     \\tTotal: {zero+one}\\tNormal: {zero}\\tMelanoma: {one}\\tPercent: {np.round(100*(one / zero),2)}%\")\n",
    "zero , one = female.groupby('target').target.count()\n",
    "print(f\"female   \\tTotal: {zero+one}\\tNormal: {zero}\\tMelanoma: {one}\\tPercent: {np.round(100*(one / zero),2)}%\")\n",
    "\n",
    "try:\n",
    "    zero , one =  unknown.groupby('target').target.count()\n",
    "    print(f\"unknown:  \\tTotal: {zero+one}\\tNormal: {zero}\\tMelanoma: {one}\\tPercent: {np.round(100*(one / zero),2)}%\")\n",
    "except:\n",
    "    print(f'missing either 0 or 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grfeater risk has higher value\n",
    "malignent_cat = {'benign':0, 'melanoma':1}\n",
    "sex_cat = {'female':0, 'male':1, 'unknown':2}\n",
    "localization_cat = {'palms/soles':0, 'lower extremity':1, 'torso':2, 'Unknown':3, 'upper extremity':4, 'oral/genital':5, 'head/neck':6}\n",
    "\n",
    "age_cat = {0.0:0, 10.0:1, 40.0:2, 35.0:3, 20:4, 30.0:5, 25.0:6, 45.0:7, 50.0:8, 15.0:9, 55.0:10,\n",
    "                            60.0:11, 65.0:12, 70.0:13, 85.0:14, 75.0:15, 80.0:16, 90.0:17}\n",
    "\n",
    "csv_train_file.benign_malignant = csv_train_file.benign_malignant.map(malignent_cat).astype(float)\n",
    "csv_train_file.sex = csv_train_file.sex.map(sex_cat).astype(float)\n",
    "csv_train_file.age_approx = csv_train_file.age_approx.map(age_cat).astype(float)\n",
    "csv_train_file.anatom_site_general_challenge = csv_train_file.anatom_site_general_challenge.map(localization_cat).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general_challenge</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>benign_malignant</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_4086048</td>\n",
       "      <td>IP_8313778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_9457506</td>\n",
       "      <td>IP_6808872</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_1510160</td>\n",
       "      <td>IP_4722284</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nevus</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_5343424</td>\n",
       "      <td>IP_4030600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0210830</td>\n",
       "      <td>IP_6939959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name  patient_id  sex  age_approx  anatom_site_general_challenge  \\\n",
       "0  ISIC_4086048  IP_8313778  1.0         7.0                            2.0   \n",
       "1  ISIC_9457506  IP_6808872  1.0         5.0                            6.0   \n",
       "2  ISIC_1510160  IP_4722284  1.0        13.0                            1.0   \n",
       "3  ISIC_5343424  IP_4030600  0.0        10.0                            1.0   \n",
       "4  ISIC_0210830  IP_6939959  0.0        12.0                            2.0   \n",
       "\n",
       "  diagnosis  benign_malignant  target  \n",
       "0   unknown               0.0       0  \n",
       "1   unknown               0.0       0  \n",
       "2     nevus               0.0       0  \n",
       "3   unknown               0.0       0  \n",
       "4   unknown               0.0       0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_train_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_train_file = csv_train_file.sort_values('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero and one train: (26033, 467), Zero and one val: (6509, 117)\n"
     ]
    }
   ],
   "source": [
    "zer_value, one_value = csv_train_file.target.value_counts()\n",
    "\n",
    "zer_value_num = int(zer_value*.8)\n",
    "one_value_num = int(one_value*.8)\n",
    "tot_value = len(csv_train_file)\n",
    "\n",
    "csv_train_file_train = csv_train_file[:zer_value_num]\n",
    "csv_train_file_train = csv_train_file_train.append(csv_train_file[zer_value:zer_value+one_value_num])\n",
    "\n",
    "csv_train_file_val = csv_train_file[zer_value_num:zer_value]\n",
    "csv_train_file_val = csv_train_file_val.append(csv_train_file[zer_value+one_value_num:])\n",
    "\n",
    "zer_value_tr, one_value_tr = csv_train_file_train.target.value_counts()\n",
    "zer_value_va, one_value_va = csv_train_file_val.target.value_counts()\n",
    "print(f'Zero and one train: {zer_value_tr, one_value_tr}, Zero and one val: {zer_value_va, one_value_va}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncsv_train_file_train = csv_train_file_train.append(csv_train_file_train.loc[csv_train_file_train['target'] == 1])\\ncsv_train_file_train = csv_train_file_train.append(csv_train_file_train.loc[csv_train_file_train['target'] == 1])\\ncsv_train_file_train = csv_train_file_train.append(csv_train_file_train.loc[csv_train_file_train['target'] == 1])\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_train_file_train = csv_train_file_train.append(csv_train_file_train.loc[csv_train_file_train['target'] == 1])\n",
    "csv_train_file_train = csv_train_file_train.append(csv_train_file_train.loc[csv_train_file_train['target'] == 1])\n",
    "csv_train_file_train = csv_train_file_train.append(csv_train_file_train.loc[csv_train_file_train['target'] == 1])\n",
    "'''\n",
    "csv_train_file_train = csv_train_file_train.append(csv_train_file_train.loc[csv_train_file_train['target'] == 1])\n",
    "csv_train_file_train = csv_train_file_train.append(csv_train_file_train.loc[csv_train_file_train['target'] == 1])\n",
    "csv_train_file_train = csv_train_file_train.append(csv_train_file_train.loc[csv_train_file_train['target'] == 1])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero and one train: (26033, 3736), Zero and one val: (6509, 117)\n"
     ]
    }
   ],
   "source": [
    "zer_value_tr, one_value_tr = csv_train_file_train.target.value_counts()\n",
    "zer_value_va, one_value_va = csv_train_file_val.target.value_counts()\n",
    "print(f'Zero and one train: {zer_value_tr, one_value_tr}, Zero and one val: {zer_value_va, one_value_va}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_train_file_train = csv_train_file_train.sample(frac=1).reset_index(drop=True)\n",
    "csv_train_file_val = csv_train_file_val.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_data = csv_train_file_train.drop(['image_name', 'patient_id', 'diagnosis', 'benign_malignant', 'target'], axis=1)\n",
    "X_val_data = csv_train_file_val.drop(['image_name', 'patient_id', 'diagnosis', 'benign_malignant', 'target'], axis=1)\n",
    "Y_train = csv_train_file_train['target']\n",
    "Y_val = csv_train_file_val['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29769, 3) (29769,) (6626, 3) (6626,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_data.shape, Y_train.shape, X_val_data.shape, Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = X_train_data.mean(axis=0)\n",
    "X_train_data -= mean\n",
    "std = X_train_data.std(axis=0)\n",
    "X_train_data /= std\n",
    "\n",
    "mean = X_val_data.mean(axis=0)\n",
    "X_val_data -= mean\n",
    "std = X_val_data.std(axis=0)\n",
    "X_val_data /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_img = csv_train_file_train['image_name']\n",
    "X_val_img = csv_train_file_val['image_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8192\n"
     ]
    }
   ],
   "source": [
    "sizing = 224 - 2            # conv1\n",
    "sizing = (sizing - 2) / 2   # conv2  \n",
    "sizing = (sizing - 2)       # conv3\n",
    "sizing = (sizing - 2) / 2   # conv4\n",
    "sizing = (sizing - 2)       # conv5\n",
    "sizing = (sizing - 2) / 2   # conv6\n",
    "sizing = (sizing - 2)       # conv7\n",
    "sizing = (sizing - 2) / 2   # conv8\n",
    "sizing = (sizing - 2) /2    # conv9\n",
    "print(512*(int(sizing)*int(sizing)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4608\n"
     ]
    }
   ],
   "source": [
    "sizing = 224 - 4            # conv1\n",
    "sizing = (sizing - 4) / 2   # conv2  \n",
    "sizing = (sizing - 4) / 2   # conv4\n",
    "sizing = (sizing - 4) / 2   # conv6\n",
    "sizing = (sizing - 4) / 2   # conv8\n",
    "sizing = (sizing - 4) / 2   # conv9\n",
    "print(512*(int(sizing)*int(sizing)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "  def __init__(self, n_output_neurons):\n",
    "    super(CNN, self).__init__()\n",
    "\n",
    "    self.conv1 = nn.Conv2d(3 , 32,   kernel_size=3, stride=1)\n",
    "    self.conv2 = nn.Conv2d(32, 32,   kernel_size=3, stride=1)\n",
    "    self.bn1   = nn.BatchNorm2d(32)\n",
    "    self.conv3 = nn.Conv2d(32 , 64,  kernel_size=3, stride=1)\n",
    "    self.conv4 = nn.Conv2d(64 , 64,  kernel_size=3, stride=1)\n",
    "    self.bn2   = nn.BatchNorm2d(64)\n",
    "    self.conv5 = nn.Conv2d(64 , 128, kernel_size=3, stride=1)\n",
    "    self.conv6 = nn.Conv2d(128 ,128, kernel_size=3, stride=1)\n",
    "    self.bn3   = nn.BatchNorm2d(128)\n",
    "    self.conv7 = nn.Conv2d(128, 256, kernel_size=3, stride=1)\n",
    "    self.conv8 = nn.Conv2d(256 ,256, kernel_size=3, stride=1)\n",
    "    self.bn4   = nn.BatchNorm2d(256)\n",
    "    self.conv9 = nn.Conv2d(256, 512, kernel_size=3, stride=1)\n",
    "    self.bn5   = nn.BatchNorm2d(512)\n",
    "\n",
    "    self.conv11 = nn.Conv2d(3 , 32,   kernel_size=5, stride=1)\n",
    "    self.bn11   = nn.BatchNorm2d(32)\n",
    "    self.conv21 = nn.Conv2d(32 , 64,  kernel_size=5, stride=1)\n",
    "    self.bn21   = nn.BatchNorm2d(64)\n",
    "    self.conv31 = nn.Conv2d(64 , 128, kernel_size=5, stride=1)\n",
    "    self.bn31   = nn.BatchNorm2d(128)\n",
    "    self.conv41 = nn.Conv2d(128, 256, kernel_size=5, stride=1)\n",
    "    self.bn41   = nn.BatchNorm2d(256)\n",
    "    self.conv51 = nn.Conv2d(256, 512, kernel_size=5, stride=1)\n",
    "    \n",
    "    self.fc1   = nn.Linear(8192+4608,128)\n",
    "    self.fc2   = nn.Linear(128,16)\n",
    "    self.fc3   = nn.Linear(16, n_output_neurons)\n",
    "\n",
    "  def forward(self, x):\n",
    "    xa = F.relu(self.conv1(x),2)\n",
    "    xa = F.relu(F.max_pool2d(self.conv2(xa),2))\n",
    "    xa = self.bn1(xa)\n",
    "    xa = F.relu(self.conv3(xa),2)\n",
    "    xa = F.relu(F.max_pool2d(self.conv4(xa),2))\n",
    "    xa = self.bn2(xa)\n",
    "    xa = F.relu(self.conv5(xa),2)\n",
    "    xa = F.relu(F.max_pool2d(self.conv6(xa),2))\n",
    "    xa = self.bn3(xa)\n",
    "    xa = F.relu(self.conv7(xa),2)\n",
    "    xa = F.relu(F.max_pool2d(self.conv8(xa),2))\n",
    "    xa = self.bn4(xa)\n",
    "    xa = F.relu(F.max_pool2d(self.conv9(xa),2))\n",
    "    xa = self.bn5(xa)\n",
    "\n",
    "    xb = F.relu(F.max_pool2d(self.conv11(x),2))\n",
    "    xb = self.bn11(xb)\n",
    "    xb = F.relu(F.max_pool2d(self.conv21(xb),2))\n",
    "    xb = self.bn21(xb)\n",
    "    xb = F.relu(F.max_pool2d(self.conv31(xb),2))\n",
    "    xb = self.bn31(xb)\n",
    "    xb = F.relu(F.max_pool2d(self.conv41(xb),2))\n",
    "    xb = self.bn41(xb)\n",
    "    xb = F.relu(F.max_pool2d(self.conv51(xb),2))\n",
    "    xb = self.bn5(xb)\n",
    "    \n",
    "    xa = xa.view(xa.size(0), -1)\n",
    "    xb = xb.view(xb.size(0), -1)\n",
    "    \n",
    "    x = torch.cat((xa, xb), dim=1)\n",
    "    \n",
    "    \n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.dropout(x, p=0.3)\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = F.dropout(x, p=0.2)\n",
    "    x = self.fc3(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = 3\n",
    "n_output_neurons = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(n_output_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv9): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv11): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn11): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv21): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn21): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv31): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn31): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv41): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn41): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv51): Conv2d(256, 512, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=12800, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=16, bias=True)\n",
       "  (fc3): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general_challenge</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>benign_malignant</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_4086048</td>\n",
       "      <td>IP_8313778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22003</th>\n",
       "      <td>ISIC_9390275</td>\n",
       "      <td>IP_8277853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_name  patient_id  sex  age_approx  \\\n",
       "0      ISIC_4086048  IP_8313778  1.0         7.0   \n",
       "22003  ISIC_9390275  IP_8277853  0.0         8.0   \n",
       "\n",
       "       anatom_site_general_challenge diagnosis  benign_malignant  target  \n",
       "0                                2.0   unknown               0.0       0  \n",
       "22003                            2.0   unknown               0.0       0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_train_file.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_image = []\n",
    "for image_get in X_train_img:\n",
    "    img_train = cv2.imread(img_train_folder + '{}.jpg'.format(image_get))\n",
    "    '''\n",
    "    rand_num = np.random.uniform(low=1, high=1.2)\n",
    "    M = cv2.resize(img_train, None, fx= rand_num, fy= rand_num, interpolation= cv2.INTER_LINEAR)\n",
    "    \n",
    "    H_crop = ((224*rand_num)-224)/2\n",
    "    V_crop = ((224*rand_num)-224)/2\n",
    "    \n",
    "    C = M[np.int(H_crop):np.int(M.shape[0]-H_crop),np.int(V_crop):np.int(M.shape[1]-np.int(V_crop))]\n",
    "    img_train= cv2.resize(C,(224,224))\n",
    "    '''\n",
    "    X_train_image.append(img_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_image = []\n",
    "for image_get in X_val_img:\n",
    "    img_val = cv2.imread(img_train_folder + '{}.jpg'.format(image_get))\n",
    "    \n",
    "    X_val_image.append(img_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_image = np.array(X_train_image)\n",
    "X_train_image = X_train_image.astype(np.float32)\n",
    "X_val_image = np.array(X_val_image)\n",
    "X_val_image = X_val_image.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.array(Y_train)\n",
    "Y_val = np.array(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_image = X_train_image / 255\n",
    "X_val_image = X_val_image / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (29769, 224, 224, 3), Vl shape: (6626, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f'Train shape: {X_train_image.shape}, Vl shape: {X_val_image.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.000005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_image_t = np.transpose(X_train_image, (0,3,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train = torch.from_numpy(X_train_image_t)\n",
    "target_train = torch.from_numpy(Y_train).reshape(-1,1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_image_t = np.transpose(X_val_image, (0,3,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_val = torch.from_numpy(X_val_image_t)\n",
    "target_val = torch.from_numpy(Y_val).reshape(-1,1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_data_np = X_train_data.values\n",
    "X_train_data_np = X_train_data_np.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train_data = torch.from_numpy(X_train_data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_data_np = X_val_data.values\n",
    "X_val_data_np = X_val_data_np.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_val_data = torch.from_numpy(X_val_data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "training_set = torch.utils.data.TensorDataset(input_train, target_train)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=training_set, \n",
    "                                           batch_size=batch_size,\n",
    "                                           num_workers=2,\n",
    "                                           shuffle=True)\n",
    "val_set = torch.utils.data.TensorDataset(input_val, target_val)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_set, \n",
    "                                           batch_size=batch_size,\n",
    "                                         num_workers=2,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(output_pred, target):\n",
    "    output_pred_tag = torch.round(torch.sigmoid(output_pred))\n",
    "\n",
    "    correct_results_sum = (output_pred_tag == target).sum().float()\n",
    "    acc = correct_results_sum/target.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gd(model, criterion, optimizer, train_loader, val_loader, n_epochs):\n",
    "    train_losses = np.zeros(n_epochs)\n",
    "    val_losses = np.zeros(n_epochs)\n",
    "    train_accuracy = np.zeros(n_epochs)\n",
    "    val_accuracy = np.zeros(n_epochs)\n",
    "    \n",
    "    \n",
    "    for it in range(n_epochs):\n",
    "        t0 = datetime.now()\n",
    "        \n",
    "        train_loss = []\n",
    "        train_acc = []\n",
    "        \n",
    "        for inputs, targets in tqdm(train_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            #outputs = torch.sigmoid(outputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            acc = binary_acc(outputs, targets)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "            train_acc.append(acc.item())\n",
    "            \n",
    "        train_loss = np.mean(train_loss)\n",
    "        train_acc = np.mean(train_acc)\n",
    "        \n",
    "        val_loss = []\n",
    "        val_acc = []\n",
    "        \n",
    "        for inputs, targets in tqdm(val_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            #outputs = torch.sigmoid(outputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            acc = binary_acc(outputs, targets)\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "            val_acc.append(acc.item())\n",
    "\n",
    "            \n",
    "        val_loss = np.mean(val_loss)\n",
    "        val_acc = np.mean(val_acc)\n",
    "        \n",
    "        train_losses[it] = train_loss\n",
    "        val_losses[it] = val_loss\n",
    "        train_accuracy[it] = train_acc\n",
    "        val_accuracy[it] = val_acc\n",
    "\n",
    "        dt = datetime.now() -t0\n",
    "\n",
    "        print(f'Epoch {it+1}/{n_epochs}, Time: {dt}, Train Loss: {train_loss:.4f}, Train_acc: {acc}, Val Loss: {val_loss:.4f}, Val acc: {val_acc}')\n",
    "    \n",
    "    return train_losses, val_losses, train_accuracy, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 328/466 [01:23<00:35,  3.91it/s]"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses, train_accuracy, val_accuracy = batch_gd(\n",
    "    model, criterion, optimizer, train_loader, val_loader, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(val_losses, label='val loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_accuracy, label='train accuracy')\n",
    "plt.plot(val_accuracy, label='val accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_correct_train = 0.\n",
    "n_total_train = 0.\n",
    "train_predictions_all = []\n",
    "train_predictions_all_value = []\n",
    "#train_predictions_all_sm = []\n",
    "train_targets_all = []\n",
    "#train_targets_all_sm = []\n",
    "\n",
    "for inputs, targets in train_loader:\n",
    "    \n",
    "    train_targets_np = targets.numpy()\n",
    "    train_targets_all.append(train_targets_np)\n",
    "    \n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    train_outputs = model(inputs)\n",
    "    train_outputs = torch.sigmoid(train_outputs)\n",
    "    \n",
    "    #sm_train = torch.nn.Softmax()\n",
    "    #train_outputs_sm = sm_train(train_outputs)\n",
    "    _, train_predictions = torch.max(train_outputs, 1)\n",
    "    train_predictions_np = train_predictions.cpu().numpy()\n",
    "    train_predictions_all.append(train_predictions_np)\n",
    "    \n",
    "    train_predictions_np_value = train_outputs.cpu().detach().numpy()\n",
    "    train_predictions_all_value.append(train_predictions_np_value)\n",
    "    \n",
    "    #train_predictions_np_sm = train_outputs_sm.cpu().detach().numpy()\n",
    "    #train_predictions_all_sm.append(train_predictions_np_sm)\n",
    "\n",
    "train_predictions_np_out = []\n",
    "train_predictions_np_out_value = []\n",
    "train_targets_np_out = []\n",
    "#train_predictions_np_out_sm = []\n",
    "#train_targets_np_out_sm = []\n",
    "\n",
    "train_count = len(train_predictions_all)\n",
    "\n",
    "for z in range(train_count):\n",
    "    \n",
    "    for a in train_predictions_all[z]:\n",
    "        train_predictions_np_out.append(a)\n",
    "\n",
    "    for a in train_predictions_all_value[z]:\n",
    "        train_predictions_np_out_value.append(a)\n",
    "        \n",
    "    for a in train_targets_all[z]:\n",
    "        train_targets_np_out.append(a)    \n",
    "'''\n",
    "for z in range(train_count):\n",
    "    \n",
    "    for a in train_predictions_all_sm[z]:\n",
    "        train_predictions_np_out_sm.append(a)\n",
    "        \n",
    "    for a in train_targets_all_sm[z]:\n",
    "        train_targets_np_out_sm.append(a)  \n",
    "'''        \n",
    "train_predictions_np_out = np.asarray(train_predictions_np_out)\n",
    "train_predictions_np_out_value = np.asarray(train_predictions_np_out_value)\n",
    "train_targets_np_out = np.asarray(train_targets_np_out)\n",
    "\n",
    "#train_predictions_np_out_sm = np.asarray(train_predictions_np_out_sm)\n",
    "#train_targets_np_out_sm = np.asarray(train_targets_np_out_sm)\n",
    "\n",
    "train_count = len(train_predictions_np_out)\n",
    "\n",
    "for z in range(train_count):\n",
    "    if train_predictions_np_out[z] == np.int(train_targets_np_out[z]):\n",
    "        n_correct_train += 1\n",
    "\n",
    "train_acc = n_correct_train / train_count\n",
    "# --------------------------------------------------------------------------------        \n",
    "n_correct_val = 0.\n",
    "n_total_val = 0.\n",
    "val_predictions_all = []\n",
    "val_predictions_all_value = []\n",
    "#val_predictions_all_sm = []\n",
    "val_targets_all = []\n",
    "                    \n",
    "for inputs, targets in val_loader:\n",
    "    \n",
    "    val_targets_np = targets.numpy()\n",
    "    val_targets_all.append(val_targets_np)\n",
    "    \n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    val_outputs = model(inputs)\n",
    "    val_outputs = torch.sigmoid(val_outputs)\n",
    "    #sm_val = torch.nn.Softmax()\n",
    "    #val_outputs_sm = sm_val(val_outputs)\n",
    "    _, val_predictions = torch.max(val_outputs, 1)\n",
    "    val_predictions_np = val_predictions.cpu().numpy()\n",
    "    val_predictions_all.append(val_predictions_np)\n",
    "\n",
    "    val_predictions_np_value = val_outputs.cpu().detach().numpy()\n",
    "    val_predictions_all_value.append(val_predictions_np_value)\n",
    "    #val_predictions_np_sm = val_outputs_sm.cpu().detach().numpy()\n",
    "    #val_predictions_all_sm.append(val_predictions_np_sm)\n",
    " \n",
    "val_predictions_np_out = []\n",
    "val_predictions_np_out_value = []\n",
    "val_targets_np_out = []\n",
    "val_count = len(val_predictions_all)\n",
    "\n",
    "for z in range(val_count):\n",
    "    \n",
    "    for a in val_predictions_all[z]:\n",
    "        val_predictions_np_out.append(a)\n",
    "\n",
    "    for a in val_predictions_all_value[z]:\n",
    "        val_predictions_np_out_value.append(a)\n",
    "        \n",
    "    for a in val_targets_all[z]:\n",
    "        val_targets_np_out.append(a)\n",
    "\n",
    "val_predictions_np_out = np.asarray(val_predictions_np_out)\n",
    "train_predictions_np_out_value = np.asarray(train_predictions_np_out_value)\n",
    "val_targets_np_out = np.asarray(val_targets_np_out)\n",
    "\n",
    "val_count = len(val_predictions_np_out)\n",
    "\n",
    "for z in range(val_count):\n",
    "    if val_predictions_np_out[z] == np.int(val_targets_np_out[z]):\n",
    "        n_correct_val += 1\n",
    "\n",
    "val_acc = n_correct_val / val_count\n",
    "      \n",
    "print(f\"Train acc: {train_acc:.4f}, Val acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_train, tpr_train, _ = roc_curve(train_targets_np_out, train_predictions_np_out_value)\n",
    "fpr_val, tpr_val, _ = roc_curve(val_targets_np_out, val_predictions_np_out_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_pred_train = auc(fpr_train, tpr_train) \n",
    "auc_pred_val = auc(fpr_val, tpr_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr_train, tpr_train, label = auc_pred_train)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr_val, tpr_val, label = auc_pred_val)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(train_predictions_np_out, train_targets_np_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(val_predictions_np_out, val_targets_np_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(val_targets_np_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_test_file = pd.read_csv('/home/malmason/datasets/siim-isic-melanoma-classification/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_test_folder = '/home/malmason/datasets/siim-isic-melanoma-classification/ycbcr/norm/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_img = csv_test_file['image_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_test_file[\"anatom_site_general_challenge\"].fillna(\"Unknown\", inplace = True)\n",
    "csv_test_file[\"sex\"].fillna(\"Unknown\", inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_test_file.sex = csv_test_file.sex.map(sex_cat).astype(float)\n",
    "csv_test_file.age_approx = csv_test_file.age_approx.map(age_cat).astype(float)\n",
    "csv_test_file.anatom_site_general_challenge = csv_test_file.anatom_site_general_challenge.map(localization_cat).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_data = csv_train_file.drop(['image_name', 'patient_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_img = csv_test_file['image_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_test_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_image = []\n",
    "for image_get in X_test_img:\n",
    "    img_test = cv2.imread(img_test_folder + '{}.jpg'.format(image_get))\n",
    "    X_test_image.append(img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_image = np.array(X_test_image.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_image = X_test_image / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
